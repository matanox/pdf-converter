1. INTRODUCTION Linear equality and inequality constraints arise naturally in specifying many aspects of user interfaces especially layout and other geometric relations. 
Inequality constraints, in particular, are neededto express relationships such as “inside,” “above,” “below,” “left-of,” “right-of,” and “overlaps.” For example, if we are designing a web document, we can exAuthors’ addresses: Greg Badros and Alan Borning, Dept. 
of Computer Science & Engineering, University of Washington, Box 352350, Seattle, WA 98195-2350, USA,badros,borning @cs.washington.edu; Peter Stuckey, Dept. 
of Computer Science and Software Engineering, University of Melbourne, Parkville, Victoria 3052, Australia, pjs@cs.mu.oz.au This research has been funded in part by a NSF Graduate Research Fellowship and a UW CSE Wilma Bradley Fellowship for Greg Badros, in part by NSF Grant No. IIS-9975990, and in part by the Australian-American Educational Foundation (Fulbright Commission). 
Permission to make digital/hard copy of all or part of this material without fee for personal or classroom use provided that the copies are not made or distributed for profit or commercial advantage, the ACM copyright/server notice, the title of the publication, and its date appear, and notice is given that copying is by permission of the ACM, Inc. 
To copy otherwise, to republish, to post on servers, or to redistribute to lists requires prior specific permission and/or a fee. 
c2002 ACM 0000-0000/2002/0000-0001 $5.00 (a) (b) (c) (d) Fig. 1. Demonstrating a theorem about quadrilaterals press the requirementthat figure1 be to theleft of figure2 as theconstraint figure1.rightSide figure2.leftSide. 
It is important to be able to express preferences as well as requirements in a constraint system used for graphical layout. 
For example, we must be able to express a desire for stability whenmoving parts of an image: things should stay where they were unless there is some reason for them to move. 
A second use for preferred constraints is to cope gracefully with invalid user inputs. 
For example, if the user tries to move a figure outside of its bounding window, it is reasonable for the figure just to bump up against the side of the window and stop, rather than causing an exception. 
A third use of non-requiredconstraints is to balance conflicting desires, for example in laying out a graph. 
In this paper we describe Cassowary, an incremental constraint satisfaction algorithm, that can solve such systems of constraints efficiently. 
A traditional demonstration of constraint-based graphics is the Quadrilateral Theorem. 
Figure 1 shows four screen shots from our Smalltalk implementation of Cassowary. 
In the demonstration, each side of the quadrilateral is bisected, and lines are drawn between the midpoints. 
(These inner lines always form a parallelogram.) This is expressed as constraints that each midpoint lie halfway between the endpoints of its line. 
In addition, all points are constrained to be at least 10 pixels from the sides of the window—these additional inequality constraints make this collection of constraints beyond the scope of most interactive solvers. 
In Figure 1a we have picked up one of the midpoints with the mouse and begun to move it by temporarily adding an edit constraint equating the position of the midpoint and the mouse. 
This constraint is strongly preferred but not required—we will violate it if necessary. 
The remaining points are weakly constrained to stay where they are by stay constraints. 
In Figure 1b the mouse has been moved to the right, and to keep the midpoint constraint satisfied the right-most vertex has moved as well. 
We continue moving to the right. 
In Figure 1c the right-most vertex has run into the imaginary wall resulting from the constraint that it be at least 10 pixels from the window boundary, and can move no further, so the bottom vertex has begun moving. 
Finally, in Figure 1d the mouse has moved beyond the permitted region for the midpoint. 
The midpoint has moved as close to the mouse as possible, thus causing the two endpoints of its line to be pressed against the boundary as well. 
Figure 2 illustrates a more complex application of Cassowary, namely SCWM, the Scheme Constraints Window Manager [Badros et al. 2000]. 
In the screen shot, XTerm A is constrained to be to the left of XTerm B, and above XTerm C. Additionally, XTerm C is required to have a minimum width, and the XEmacs window’s southeast corner is anchored at its current location. 
All of these constraints are maintained as the user manipulates the windows. 
A button bar at the bottom of the screen provides a graphical interface for applyFig. 2. Screen shot from the Scheme Constraints Window Manager ing constraints to windows. 
In addition, we have turned on the “constraint investigator,” which provides a visual representation of the active constraints. 
Efficient techniques are available for solving systems of linear constraints if the constraint network is acyclic. 
However, in trying to apply constraint solvers to real-world problems, we found that the collection of constraints was often cyclic, and included both equalities and inequalities. 
Cycles sometimes arise when the programmer added redundant constraints—the cycles could have been avoided by careful analysis. 
However, the analysis is an added burden on the programmer. 
Further, it is clearly contrary to the spirit of the whole enterprise to require programmers to be constantly on guard to avoid cycles and redundant constraints; after all, one of the goals in providing constraints is to allow programmers to state what relations they want to hold in a declarative fashion, leaving it to the underlying system to enforce these relations. 
For other applications, such as complex layout problems with conflicting goals, cycles seem unavoidable. 
A solver that can handle cycles of both equality and inequality constraints is thus highly desirable. 
1.1 Constraint Hierarchies and Comparators Since we want to be able to express preferences as well as requirements in the constraint system, we need a specification for how conflicting preferences are to be traded off. 
Constraint hierarchies [Borning et al. 1992] provide a general theory for this. 
In a constraint hierarchy each constraint has a strength. 
The required strength is special, in that required constraints must be satisfied. 
The other strengths all label non-required constraints. 
A constraint of a given strength completely dominates any constraint with a weaker strength—the strong constraint must be satisfied as well as possible before the weaker constraint can have any effect on the solution. 
In the theory, a comparator is used to compare different possible solutions to the constraints and select among them. 
Given a constraint hierarchy, ideally we would find one solution that is “better” than all others using this comparator. 
However, in most cases there will be many equally good solutions, and any one of these will be a correct answer. 
A labelled primitive constraint is a primitive constraint labelled with a strength, written, where is a strength and is a primitive constraint. 
Strengths are non-negative integers; for clarity we give them symbolic names. 
Strength 0, with the symbolic name required, is always reserved for required constraints. 
In the examples here, we use three strengths: required, strong, and weak. 
However, the approach permits any finite number of strengths. 
Formally, a constraint hierarchy is a multiset of labelled primitive constraints. 
Given a constraint hierarchy, denotes the multiset of required primitive constraints in , with their labels removed. 
In the same way, we define the multisetsfor strengths. 
A valuation is a mapping of variables to values, writtenwhere are distinct variables and are values (in this paper, real numbers). 
The setof solutions to the hierarchy is defined as follows. 
is the set of valuations such that all theconstraints hold; from this we form by eliminating all potential valuations that are worse than some other potential valuation using the comparator predicate better. 
holds better Within this framework a number of variations are possible. 
One decision is whether we only compare solutions on a constraint-by-constraint basis (a local comparator),or whether we take some aggregate measure of the unsatisfied constraints of a given strength (a global comparator). 
A second choice is whether we are concerned only whether a constraint is satisfied or not (a predicate comparator), or whether we also want to know how nearly satisfied it is (a metric comparator). 
Constraints whose domain is a metric space, such as constraints on the reals, can have an associated metric error function. 
The error in satisfying such a constraint is 0 if and only if the constraint is satisfied, and becomes larger the less nearly satisfied the constraint is. For inequality constraints it is important to use a metric rather than a predicate comparator [Borning et al. 1996]. 
Thus, plausible comparators for use with linear equality and inequality constraintsare locally-error-better, weighted-sum-better, andleast-squaresbetter. 
For a given collection of constraints, Cassowary finds a weighted-sum-better solution. 
(Every weighted-sum-better solution is also a locally-error-better solution.) We assume an error functionthat returns a non-negative real number indicating how nearly the primitive constraintis satisfied for a valuation . 
For a linear equation of the form ( is a linear expression) the error function is , while for a linear inequalityof the form the error function is where otherwise For the weighted-sum-better comparator, a solutioncan be thought of as mapping a constraint hierarchy to a tuple of errors defined by Then one solution is better than another solution if the corresponding tuple of errors is lexicographically smaller. 
For example, consider the constraint hierarchy and consider the two solutions and . 
The corresponding error tuples are and ,so is weighted-sum-better than, since is lexicographically less than . 
In what follows we shall only consider non-requiredconstraints of the form where is a variable and a value. 
Note that we can straightforwardly translate any constraint hierarchy into an equivalent constraint hierarchyin this form by replacing a nonrequired constraintby , and replacing a nonrequired constraintby , , . 
1.2 Adapting the Simplex Algorithm Linear programming is concerned with solving the following problem: Consider a collection ofreal-valued variables , each of which is constrained to be non-negative:for . 
Suppose there are linear equality or inequality constraints over the , each of the form: , ,or . 
Given these constraints, find values for thethat minimize (or maximize) the value of the objective function . 
This problem has been heavily studied for the past fifty years. 
The most commonly used technique for solving it is the simplex algorithm, developed by Dantzig in the 1940s. 
There are now numerous variations of it, but unfortunately existing implementations of the simplex algorithm are not readily usable for user interface applications. 
The principaldifficulty is incrementality. 
For interactive graphical applications, we need to solve similar problems repeatedly, rather than solving a single problem once. 
To achieve interactive response times, fast incremental algorithms that exploit prior computations are needed. 
There are two common cases that algorithmic changes should try to improve. 
First, when moving an object with a mouse or other input device, we typically represent this interaction as a one-way constraint relating the mouse position to the desiredand coordinates of a part of the figure. 
For each screen refresh, we must re-satisfy the same collection of constraints while varying only the mouse location input. 
The second common operation that incremental algorithms can optimize occurs when editing an object in a complex system. 
Ideally, when adding or removing a small number of constraints, we would like to avoid re-solving the entire system. 
Although the performance requirements for this case are less stringent than for the first case, since it is a less frequent operation, we still wish to increase performance by reusing as much of the previous solution as possible. 
Another important issue when applying simplex to user interface applications is defining a suitable objective function. 
We must accommodate non-required constraints of different strengths, which is analogous to multi-objective linear programming problems. 
Also, the objective function in the standard simplex algorithm must be a linear expression; but the objective functions for the locally-error-better, weighted-sum-better, and least-squaresbetter comparators are all non-linear. 
For Cassowary, we avoid the least-squares-better comparator and use a quasi-linearobjective function to implementthe weighted-sum-better comparator (see Section 2.3). 
Finally, a minor issue is accommodating variables that may take on both positive and negative values, which is generally the case in user interface applications. 
(The standard simplex algorithm requires all variables to be non-negative.) Here we adopt efficient techniques developed for implementing constraint logic programming languages (see Section 2.1). 1.3 Implementation Overview The Cassowary algorithm has been implemented in Smalltalk, C++, and Java as part of our Cassowary Constraint Solving Toolkit, and is freely available for download [Badros and Borning 2001]. 
The library performs surprisingly well, and a summary of our performance measurements is given in Section 3. A re-implementation of the algorithm based on this paper is also reasonable, given a knowledge of the simplex algorithm. 
The electronic appendix to this paper, available via the ACM Digital Library, provides additional details regarding our implementations of the Cassowary algorithm. 
1.4 Related Work There is a long history of using constraints in user interfaces and interactive systems, beginning with Ivan Sutherland’s pioneering Sketchpad system [Sutherland 1963]. 
Most of the current systems use one-way constraints (e.g., [Hudson and Smith 1996; Myers 1996]), or local propagation algorithms for acyclic collections of multi-way constraints (e.g., [Sannella et al. 1993; Vander Zanden 1996]). 
Indigo [Borning et al. 1996] handles acyclic collections of inequality constraints, but not cycles (simultaneous equations and inequalities). 
User interface systems that handle simultaneous linear equations includeDETAIL [Hosobe et al. 1996] and Ultraviolet [Borning and Freeman-Benson 1998]. 
A number of researchers (including the second author) have experimented with a straightforward use of a simplex package in a UI constraint solver, but the speed was not satisfactory for interactive use. 
Baraff [1994] describes a quadratic optimization algorithm for solving linear constraints that arise in modeling physical systems. 
Finally, much of the work on constraint solvers has been in the logic programming and constraint logic programming communities. 
Current constraint logic programming languages such as CLP() [Jaffar et al. 1992] include efficient solvers for linear equalities and inequalities. 
(See Marriott and Stuckey [1998] for a survey.) However, these solvers use a refinement model of computation, in which the values determined for variables are successively refined as the computation progresses, but there is no specific notion of state and change. 
As a result, these systems are not especially well suited for building interactive graphical applications. 
An earlier paper [Borning et al. 1997] describes both the original version of Cassowary (in much less detail than in this paper), and also the related QOCA algorithm. 
(QOCA uses much the same solving technique as Cassowary, but implements uses a least-squares-better comparator, which strongly penalizes outlying values when comparing constraints of the same strength.) The incremental constraint deletion procedure is described in Huynh and Marriot [1995]. 
2. INCREMENTAL SIMPLEX As you see, the subject of linear programming is surrounded by notational and terminological thickets. 
Both of these thorny defenses are lovingly cultivated by a coterie of stern acolytes who have devoted themselves to the field. 
Actually, the basic ideas of linear programming are quite simple. 
— Numerical Recipes [Press et al. 1989, page 424]. 
We now describe an incremental version of the simplex algorithm, adapted for our Cassowary algorithm for interactive graphical applications. 
In the descriptionwe use a running example, illustrated by the diagram in Figure 3. Fig. 3. Simple constrained picture The constraints on the variables in Figure 3 are as follows: is constrained to be the midpoint of the line fromto , and is constrained to be at least 10 to the left of . 
All variables must lie in the range -10 to 100. 
(To keep the presentation manageable, we deal only with thecoordinates. 
Adding analogous constraints on the coordinates is straightforward but would double the number of constraints in our example.) Since in any solution, we simplify the problemby removing the redundantbounds constraints. 
However, even with these simplifications the resulting constraintshave a cyclic constraint graph and cannot be handled by methods such as Indigo [Borning et al. 1996]. 
With the simplifications, the constraints are 2.1 Augmented Simplex Form Suppose we wish to minimize the distance betweenand , or in other words, minimize . 
(This simple objective function is just used as an initial example; an objective function for an interactive manipulation problem is described in Section 2.3.) The basic simplex algorithm does not itself handle variables that may take negative values (so-called unrestricted variables). 
It instead imposes an implicit constraint on all variables occurring in its equations. 
Augmented simplex form allows us to handle unrestricted variables efficiently and simply; it was developed for implementing constraint logic programming languages [Marriott and Stuckey 1998], and we have adopted it here. 
Conceptually it uses two tableaux rather than one. 
All of the unrestricted variables from the original constraintswill be placed in , the unrestricted variable tableau. 
, the simplex tableau, contains only variables constrained to be non-negative (the restricted variables). 
Thus, an optimization problem is in augmented simplex form if the constraintshave the formwhere and are conjunctions of linear arithmetic equations, is , and the objective function is a linear expression over variables in. The simplex algorithm is used to determine an optimal solution for the equations in the simplex tableau, ignoring the unrestricted variable tableau during the optimization procedure. 
(need only be considered when finding the feasible region, prior to optimization.) The equations in theare then used to determine values for the unrestricted variables. 
It is not difficult to re-write an arbitrary optimization problem over linear real equations and inequalities into augmented simplex form. 
The first step is to convert inequalities to equations. 
Each inequality of the form, where is a linear real expression, can be replaced withwhere is a newly-introduced non-negative slack variable. 
For example, the constraints for Figure 3 can be rewritten as minimizesubject to We now separate the equalities into and . 
Initially all equations are in .We move the unrestricted variables intousing Gauss-Jordan elimination. 
To do this, we select an equation incontaining an unrestricted variable and remove the equation from. 
We then solve the equation for , yielding a new equation for some linear expression. 
We then substitute for all remaining occurrences of in , , and, and place the equation in . 
The process is repeated until there are no more unrestricted variables in. In our example, can be used to substitute for yielding: minimizesubject to Next, the first equation of can be used to substitute for , giving augmented-simplex-form( , ) := ; := ; for each inequalityin := let be a new slack variable := := endfor while exists variablein let where := replace by in and in := endwhile := return Fig. 4. Take an initial constraint and objective function and return an equivalent augmented simplex form with minimize subject to Now we move to using , giving minimizesubject to The general algorithm is shown in Figure 4. Note that in this and subsequent algorithms we treat constraints modulo logical equivalence, so that for example the constraint is identical to the constraint , and use this implicitly in matching the forms of constraints. 
Hereafter, the labels forand will be omitted: constraints above the horizontalline are in, and constraints below the line are in . 
Also, will be omitted entirely—any variable occurring below the horizontal line is implicitly constrained to be non-negative. 
The simplex method works by taking an optimization problem in “basic feasible solved form” (a type of normal form) and repeatedly applying matrix operations to obtain new basic feasible solved forms. 
Once we have split the equations intoand we can ignorefor purposes of optimization. 
In the implementation, all variables that may be accessed from outside the solver are unrestricted. 
Only error or slack variables are represented as restricted variables, and these variables occur only within the solver. 
(See the Electronic Appendix for further details.) The primary benefit of this simplification is that the programmer using the solver always uses just the one kind of variable. 
A minor benefit is that only the external, unrestricted variables actually store their values as a field in the variable object; the values of restricted variables are just given by the tableau. 
A minor drawback is that the constraintmust be represented explicitly for an external variable. 
(In any case, would need to be represented explicitly for any other constant.) In our running example, the constraints imply thatis non-negative. 
However, since is accessible from outside the solver, we represent it as unrestricted. 
This does not change the solutions found. 
Also, we show the operations as modifyingas well as . 
It would be possible to modify just and leave unchanged, using only to define values for the variables on the left hand side of its equations. 
This would speed up pivoting, but it would make the incremental updates of the constants in edit constraints slower (Section 2.4). 
Because the latter is a much more frequent operation, we do actually modify bothand in the implementation. 
An augmented simplex form optimization problem is in basic feasible solved form if the equations are of the form where the variable does not occur in any other equation or in the objective function. 
If the equation is in, must be non-negative. 
However, there is no such restriction on the constants for the equations in. In either case the variable is said to be basic and the other variables in the equation are parameters. 
A problem in basic feasible solved form defines a basic feasible solution, which is obtained by setting each parametric variable to 0 and each basic variable to the value of the constant in the right-hand side. 
Note that the basic feasible solution may not be an optimal solution. 
For instance, the following constraint is in basic feasible solved form and is equivalent to the problem above. 
minimizesubject to The basic feasible solution corresponding to this basic feasible solved form is The value of the objective function with this solution is . 
2.2 Simplex Optimization We now describe how to find an optimum solution to a constraint in basic feasible solved form. 
Except for the operations on the additional unrestricted variable tableau, the material presented in this subsection is simply Phase II of the standard two-phase simplex algorithm. 
The simplex algorithm finds the optimum by repeatedly looking for an “adjacent” basic feasible solved form whose basic feasible solution decreases the value of the objective function that we are minimizing. 
When no such adjacent basic feasible solved form can be found, we have achieved an optimum. 
The underlying operation is called pivoting and involves exchanging a basic and a parametric variable using matrix operations. 
Thus, by “adjacent” we mean the new basic feasible solved form can be reached by performing a single pivot. 
In our example, increasingfrom will decrease the value of the objective function we are minimizing. 
We must be careful: we cannot increase the value ofindefinitely as this may cause the value of some other basic non-negative variable to become negative. 
We must examine the equations in. The equation allows to take at most a value of, because if becomes larger than this, then would become negative. 
The equations above the horizontal line do not restrict, since whatever value takes the unrestricted variables and can take values to satisfy the equations. 
In general, we choose the most restrictive equation in, and use it to eliminate . 
In the case of ties we arbitrarily break the tie. 
In this example, the most restrictive equation (there is only one) is. Writing as the subject we obtain . 
We replaceeverywhere by and obtain minimizesubject to We have just performed a pivot, having moved out of the set of basic variables and replaced it by movinginto the basis. 
We continue this process. 
Increasing the value ofwould increase the value of the objective function (which we are trying to minimize, so we don’t want to do this). 
Note that decreasingwould decrease the objective function’s value, but as is constrained to be non-negative, it already takes its minimum value ofin the associated basic feasible solution. 
Hence we are at an optimal solution. 
1 In general, the simplex algorithm applied to is described as follows. 
We are given a problem in basic feasible solved form in which the variablesare basic and the variablesare parameters. 
minimizesubject to Select an entry variable such that . 
(An entry variable is one that will enter the basis, i.e., it is currently parametric and we want to make it basic.) Pivoting on such a variable can only decrease the value of the objective function. 
If no such variable exists, the optimum has been reached. 
Now determine the exit variable. 
We must choose this If we had an unrestricted variable in the objective function, the optimization would be unbounded. 
This possibility is not an issue for our algorithm because of the nature of the objective functions that arise from the hierarchical constraints (see Section 2.3). simplex opt( , ) repeat % Choose variableto become basic if for eachthen return (, ) % an optimal solution has been found endif choosesuch that % Choose variable to become non-basic choosesuch that := replace by in for each if then replace by in row endif endfor replace therow by endrepeat Fig. 5. Simplex optimization of a system of equations with objective function in basic-feasible solution form variable so that it maintains basic feasible solved form by ensuring that the new ’s are still positive after pivoting. 
That is, we must choose anso that is a minimum element of the set and If there were no for which then we could stop since the optimization problem would be unbounded and so would not have a minimum: we could chooseto take an arbitrarily large value and thus make the objective function arbitrarily small. 
However, this is not an issue in our context since our optimization problems will always have a lower bound of 0. We proceed to choose, and pivot out and replace it with to obtain the new basic feasible solution. 
We continue this process until an optimum is reached. 
The algorithm is specified in Figure 5 and takes as inputs the simplex tableauand the objective function . 
Finally, we must consider the problem of cycling. 
A basic feasible solution is degenerate if some of the basic variables take the value 0. If this is the case, we could perform a pivot that does not decrease the value of the objective function and that does not change the corresponding basic feasible solution. 
In such a case, there is a danger of pivoting back to the original problem. 
In practice, such cycling does not occur very often, and in any event there are simple methods to avoid it. One of these is Bland’s anti-cycling rule, which we use in our implementations. 
We number the variables (either with their hash code or a unique ID). 
When selecting a variable to enter the basis, we choose the lowest numbered variable. 
(This is done in the line “choosesuch that ” in Figure 5.) Similarly, when selecting a variable to exit the basis, if a tie occurs (next line), we choose the lowest numbered basic variable to break the tie. 
2.3 Handling Non-Required Constraints Suppose the user wishes to editin the diagram and have and weakly stay where they are. 
This adds the non-required constraints edit, stay , and stay . 
Suppose further that we are trying to moveto position 50, and that and are currently at 30 and 60 respectively. 
We are thus imposingthe constraints strong, weak , and weak. 
To form an objective function for the weighted-sum-better comparator,we sum the errors for the each constraint, weighting the errors so that satisfying any strong constraint is always more important than satisfying any combination of weaker constraints. 
To implement this weighting, we might try using large coefficients, e.g. making the errors for strong constraints 1000 times larger than those for weak constraints. 
However, for sufficiently large values for the constrained variables, we might nevertheless end up in a situation in which weak constraints were satisfied in preference to strong ones. 
Instead, to ensure that strong constraints are always satisfied in preference to weak ones, Cassowary uses symbolic weights for the coefficients in the objective function, rather than real numbers. 
These symbolic weights are represented as tuples and ordered lexicographically. 
In the presentation that follows, we will write these symbolic weights as pairs, such as, which represents the symbolic weight consisting of the unit weight for the strong strength plus twice the unit weight for the weak strength. 
For our example, the objective function is where is the weight (in lexicographic numbering) of a strong constraint and is the weight of a weak constraint. 
Due to the absolute value operators, this objective function is not linear, and hence the simplex method is not applicable directly. 
We now show how we can solve the problem using quasi-linear optimization. 
Both the edit and the stay constraints will be represented as equations of the form where and are non-negative variables representing the deviation of from the desired value. 
If the constraint is satisfied both and will be 0. Otherwise will be positive andwill be 0 if is too big, or vice versa if is too small. 
2 Because we wantand to be 0 if possible, we make them part of the objective function, with larger coefficients for the error variables of stronger constraints. 
(We need to use the pair of variables to satisfy simplex’s non-negativity restriction, since these variablesand will be part of the objective function.) Translating the constraints strong, weak , and weak which arise from the edit and stay constraints we obtain: Although the equation may be satisfied with both and non-zero, the simplex optimization itself forces at least one of them to be zero (see Section 2.4). as well as the original constraints: The objective function for our example can now be restated as: minimize An optimal solution of this problem can now be found using the simplex algorithm. 
The only point to notice in using symbolicweights as coefficients is that the comparison choosing an entry variable is a lexicographic comparison. 
The optimization results in a tableau minimizesubject to This corresponds to the solution illustrated in Figure 3. Notice that the weak stay constraint onis not satisfied ( is non-zero, read directly from the second to last line of the above tableau). 
In general the objective function corresponding to a constraint hierarchywill be where is the set of error variables for constraints of strength . 
Note that the minimum of this function is clearly bounded below since all error variables are non-negative. 
2.4 Incrementality: Resolving the Optimization Problem Now suppose the user moves the mouse (which is editing)to . 
We wish to solve a new problem, with constraints strong, and weak and weak (so that and should stay where they are if possible). 
There are two steps. 
First, we modify the tableau to reflect the new constraints we wish to solve. 
Second, we resolve the optimization problem for this modified tableau. 
Let us first examine how to modify the tableau to reflect the new values of the stay constraints. 
This will not require re-optimizing the tableau, since we know that the new stay constraints are satisfied exactly. 
Suppose the previous stay value for variablewas , and in the current solutiontakes value . 
The current tableau contains the information that and we need to modify this so that instead There are two cases to consider: (a) both and are parameters, or (b) one of them is basic. 
In case (a)must take the value in the current solution since both and take the valueand Hence and no changes need to be made. 
In case (b) assume without loss of generality thatis basic. 
Now, in the original equation representing the stay constraint, the coefficient foris the negative of the coefficient for. 
Every constraint in the simplex tableau is simply a linear sum of the original constraints, since the only modifications to the tableau are by pivoting. 
Since theand variables occur in no other constraints, this relation between the coefficients will continue to hold as we perform pivots. 
In other words,and come in pairs: any equation that containswill also contain (with the coefficient negated) and vice versa. 
Since is assumed to be basic, it occurs exactly once in an equation with constant, and further this equation also contains the only occurrence of. In the current solution and since the equation holds, . 
To replace the equation by we simply need to replace the constant in the row for by . 
Since there are no other occurrences ofand we have replaced the old equation with the new. 
For our example, to update the tableau for the new values for the stay constraints on and we simply set the constant of the second to last equation (the equation for )to 0. The tableau is now: minimizesubject to (For completeness we update the constant part of the objective function, as well as its other terms, in our running example. 
However, the constant part of the objective function is irrelevant for the algorithm, and our implementations ignore it.) Now let us consider the edit constraints. 
Suppose the previous edit value forwas , and the new edit value foris . 
The current tableau contains the information that and again we need to modify this so that instead To do so we must replace every occurrence of by taking proper account of the coefficients of and . 
(Again, remember that and come in pairs.) If either ofand is basic, this simply involves appropriately modifying the equation in which they are basic. 
Otherwise, if both are non-basic, then we need to change every equation of the form to Hence modifying the tableau to reflect the new values of edit and stay constraints involves only changing the constantvalues in someequations. 
The modificationsforstay constraints always result in a tableau in basic feasible solved form, since it never makes a constant become negative. 
In contrast the modifications for edit constraints may not. 
To return to our example, suppose we pick upwith the mouse and move it to 60. Then we have thatand , so we need to add 10 times the coefficient of to the constant part of every row. 
The modified tableau, after the updates for both the stays and edits, is minimizesubject to Clearly it is feasible and already in optimal form, and so we have incrementally resolved the problem by simply modifying constants in the tableaux. 
The new tableaux give the solution. 
So sliding the midpoint rightwards has caused the right point to slide rightwards as well, but twice as far. 
The resulting diagram is shown at the top of Figure 6. Suppose we now movefrom 60 to 90. The modified tableau is Fig. 6. Resolving the constraints minimize subject to The tableau is no longer in basic feasible solved form, since the constant of the row for is negative, even though is supposed to be non-negative. 
(In this solution , so that the right endpoint has crashed through thebarrier.) Thus, in general, after updating the constants for the edit constraints, the simplex tableau may no longer be in basic feasible solved form, since some of the constants may be negative. 
However, the tableau is still in basic form, so we can still read a solution directly from it as before. 
Also, because no coefficient has changed (in particular the optimization function is the same), the resulting tableau reflects an optimal but not feasible solution. 
We need to find a feasible and optimal solution. 
We could do so by adding artificial variables (as when adding a constraint—see Section 2.5), optimizing the sum of the artificial variables to find an initial feasible solution, and then re-optimizing the original problem. 
But we can do much better. 
The process of moving from an optimal and infeasible solution to an optimal and feasible solution is exactly the dual of normal simplex algorithm, where we progress from a feasible and non-optimal solution to feasible and optimal solution. 
Hence we can use the dual simplex algorithm to find a feasible solution while staying optimal. Solving the dual optimization problem starts from an infeasible optimal solved form tableau minimizesubject to where some may be negative for rows with non-negative basic variables (accounting for the tableau’s infeasibility) and eachis non-negative (so it is optimal). 
The dual simplex algorithm selects an exit variable by finding a rowwith non-negative basic variableand negative constant . 
The entry variable is the variable such that re optimize( , ) foreach if or is basic in row then := 0 endif endfor foreach let and be the previous and current edit values for let be foreach := endfor endfor repeat % Choose variableto become non-basic choosewhere if there is no such return true endif % Choose variableto become basic if for eachthen return false endif choosesuch that := replace by in for each if then replace by in row endif endfor replace therow by until false Fig. 7. Dual simplex re-optimization of constraints with objective function in infeasible optimal solved form the ratio is theminimum of all where is positive. 
3 This selection criteria ensures that when pivoting we stay at an optimal solution. 
The pivot replacesby and is performed as in the (primal) simplex algorithm. 
The algorithm is shown in Figure 7. Continuing the example above, we select the exit variable—the only non-negative basic variable for a row with negative constant. 
We find thathas the minimum ratio since its coefficient in the optimization function is 0, so it will be the entry variable. 
Replacing everywhere by we obtain the tableau Recall that the will be lexicographic coefficients, so this minimization is with respect to the lexicographic order. 
minimize subject to The tableau is feasible (and of course still optimal) and represents the solution . 
So by sliding the midpoint further right, the rightmost point hits the wall and the left point slides right to satisfy the constraints. 
The resulting diagram is shown at the bottom of Figure 6. To summarize, incrementally finding a new solution for new input variables involves updating the constants in the tableaux to reflect the updated stay constraints, then updating the constants to reflect the updated edit constraints, and finally re-optimizing if needed. 
In an interactive graphical application, this dual optimization method typically requires a pivot only when one part of the figure first hits or first moves away from a barrier. 
The intuition behind this is that when a constraint first becomes unsatisfied, the value of one of its error variables will become non-zero, and hence the variable will have to enter the basis; conversely, when a constraint first becomes satisfied, we can move one of its error variables out of the basis. 
In the example, pivoting occurred when the right pointcame up against a barrier. 
Thus, if we picked up the midpointwith the mouse and smoothly slid it rightwards, 1 pixel every screen refresh, only one pivot would be required in moving from 50 to 95. This behavior is why the dual optimization is well suited to this problem and leads to efficient resolving of the hierarchical constraints. 
2.5 Incrementality: Adding a Constraint We now describe how to add a new constraint incrementally. 
This technique is also used in our implementation to find an initial basic feasible solved form for the original simplex problem, by starting from an empty constraint set and adding the constraints one at a time. 
As an example, suppose we wish to require that the midpoint be centered, i.e. to add a required constraintto the final tableau given in Section 2.2, page 11. For reference, that tableau is: If we substitute for each of the basic variables in (namely ), we obtain the equation. 
In order to add this constraint straightforwardly to the tableau we create a new non-negative variablecalled an artificial variable. 
(This technique is simply an incremental version of the operation used in Phase I of the two-phase simplex algorithm.) We letbe added to the tableau (clearly this gives a tableau in basic feasible solved form) and then minimize the value of.If takes the value then we have obtained a solution to the problem with the added constraint, and we can then eliminate the artificial variable altogether since it is a parameter (and hence takes the value 0). This is the case for our example; the resulting tableau is In general, to add a new constraint to the tableau, if it is an inequality we first convert it to an equation by adding a slack variable. 
Next, we use the current tableau to substitute out all the basic variables. 
This gives an equation, where is a linear expression. 
If the constant part ofis negative, we multiply both sides of the equation by so that the constant becomes non-negative. 
If contains an unrestricted variable we use it to substitute for that variable and add the equation to the tableau above the line (i.e., to). 
Otherwise we create a restricted artificial variable, add the equation to the tableau below the line (i.e., to), and minimize . 
If the resulting minimum is not zero then the constraints are unsatisfiable. 
Otherwiseis either parametric or basic. 
If is parametric, the column for it can be simply removed from the tableau. 
If it is basic, the row must have constant 0 (since we were able to achieve a value of 0 for our objective function, which is equal to). 
If the row is just , it can be removed. 
Otherwise, , where . 
We can then pivot into the basis using this row and remove the column for . 
If the equation being added contains any unrestricted variables after substituting out all the basic variables, as described above we do not need to use an artificial variable. 
Not only that, we could not use an artificial variable, since we cannot put an equation in that contains an unrestricted variable. 
In some other cases we can avoid using an artificial variable for efficiency, even though it would be permissible to use one. 
We can avoid using an artificial variable if we can choose a subject for the equation from among its current variables. 
Here are the rules for choosing a subject. 
(These are to be used after replacing any basic variables with their defining expressions.) We are adding the constraintto the tableau. 
If necessary, normalizeby multiplying by so that its constant part is nonnegative. 
We want to pick a variable into be the subject of an equation, so that we can add the row, where the result of solving for . 
—Ifcontains any unrestricted variables, we must choose an unrestricted variable as the subject. 
—If the subject is new to the solver, we will not have to do any substitutions, so we prefer new variables to ones that are currently noted as parametric. 
—Ifcontains only restricted variables, if there is a variable in that has a negative coefficient and that is new to the solver, we can pickas the subject. 
(Adding the equationthat is the result of solving for will result in a basic feasible solved form, since the constant part ofwill be non-negative.) —Otherwise use an artificial variable. 
A consequence of these rules is that we can always add a non-required constraint to the tableau without using an artificial variable, because the equation will contain a positive and a negative error or slack variable, both of which are new to the solver, and which occur with opposite signs. 
(Constraints that are originally equations will have a positive and a negative error variable, while constraints that are originally inequalities will have one error variable and one slack variable, with opposite signs.) This observation is good news for performance, since adding a non-required edit constraint is a common operation. 
If the subject variable is a new error variable, or an artificial variable, we must reoptimize the resulting system after the addition. 
Also, if the subject is an artificial variable, we must remove it from the tableaubefore re-optimizing. 
(See Marriott and Stuckey [1998, page 70] for details.) 2.6 Incrementality: Removing a Constraint We also want a method for incrementally removing a constraint from the tableaux. 
After a series of pivots have been performed, the information represented by the constraint may not be contained in a single row, so we need a way to identify the constraint’s influence in the tableaux. 
To do this, we use a “marker” variable that is originally present only in the equation representing the constraint. 
We can then identify the constraint’s effect on the tableaux by looking for occurrences of that marker variable. 
For inequality constraints, the slack variablethat we added to make it an equality serves as the marker (because will originally occur only in that equation). 
For non-required equality constraints, either of its two error variables can serve as a marker—see Section 2.3. 
For required equality constraints, we add a “dummy” restricted variable to the original equation to serve as a marker, which we never allow to enter the basis (so that it always has value 0). In our running example, then, to allow the constraintto be deleted incrementally we would have added a dummy variable, resulting in . 
The simplex optimization routine checks for these dummy variables in choosing an entry variable and does not allow one to be selected. 
These dummy variables must be restricted, not unrestricted, because we might need to have some of them in the equations for restricted basic variables. 
(We did not include the variablein the tableaux presented earlier to simplify the presentation.) Consider removing the constraint thatis 10 to the left of . 
The slack variable , which we added to the inequality to make it an equation, records exactly how this equation has been used to modify the tableau. 
We can remove the inequality by pivoting the tableau untilis basic and then simply drop the row in which it is basic. 
In the tableau in Section 2.5 (obtained after adding the required constraint), is already basic, so removing it simply means dropping the row in which it is basic, obtaining If we wanted to remove this constraint from the tableau before adding (i.e., the final tableau given in Section 2.2, page 11),is a parameter. 
We make basic by treating it as an entry variable and (as usual) determining the most restrictive equation, then using that to pivotinto the basis before finally removing the row. 
There is such a restrictive equation in this example. 
However, if the marker variable does not occur in, or if its coefficients in are all non-negative, then no equation inc addition( , , , , ) := if is of the form if is := where is a new slack variable := else := where is a new error variable := := endif else letbe of the form where the constant in is if is not := := := endif endif for eachin replace in by endfor if exists let be of the form replace by everywhere in := elseif exists where is of the form where the constant in is := replace by in := simplex opt( , ) else %%must be a required constraint letbe of form where the constant in is := where is a new artificial variable := simplex opt( , ) if constant part ofis not zero then exception “unsatisfiable constraints” remove variablefrom (possibly pivoting) := simplex opt( , ) endif return Fig. 8. Incremental addition and reoptimization of a constraint with strength to the system with objective function restricts the value of the marker variable. 
If the marker variable does occur in one or more equations in, always with a positive coefficient, pick the equationwith the smallest ratio of the constant to the marker variable’s coefficient. 
(The row with the marker variable will become infeasible after the pivot, but all the other rows will still be feasible, and we will be dropping the row with the marker variable. 
In effect we are removing the non-negativity restriction on the marker variable.) Finally, if the marker variable occurs only in equations for unrestricted variables, we can choose any equation in which it occurs. 
In the final tableau in Section 2.2, page 11, the rowis the most constraining equation. 
Pivoting to let enter the basis and then removing the row in which it is basic, we obtain In the preceding example the marker variable had a negative coefficient. 
Here is an example that only has positive coefficients. 
The original constraints are: In basic feasible solved form, this is: where , , and are the marker (and slack) variables for , , and respectively. 
This gives a solution for of , which of course satisfies all of the original inequalities. 
Suppose we want to remove theconstraint. 
We need to pivot to make basic. 
The equation that gives the smallest ratio is, so the entry variable is and the exit variable is, giving: This tableau is now infeasible, but we drop the row with giving which is of course feasible. 
A beneficial result of using marker variables is that redundant constraints can be represented and manipulated. 
Consider: When converted to basic feasible solved form, each constraint gets a separate slack variable, which is used as the marker variable for that constraint. 
To delete the second constraint we would simply drop the row. 
To delete the firstconstraint we would pivot, making basic and parametric: and then drop the row. 
A consequence of directly representing redundant constraints is that they must all be removedto eliminate their effect. 
(This seems to be a more desirable behavior for thesolver than removing redundant constraints automatically, although if the latter were desired the solver could be modified to do this.) Another consequence is that when adding a new constraint, we would never decide that it was redundant and not add it to the tableau. 
Before we remove the constraint, there may be some stay constraints that were unsatisfied previously. 
If we just removed the constraint these could come into play, so instead, we reset all of the stays so that all variables are constrained to stay at their current values. 
Also, if the constraint being removed is not required, we need to remove the error variables for it from the objective function. 
To do this we add the following to the expression for the objective function: where is the error variable if it is parametric, or else is its defining expression if it is basic,is the unit symbolic weight for the constraint’s strength, and is its weight at the given strength. 
If we allow non-required constraints other than stays and edits, we must also re-optimize after deleting a constraint, since a non-required constraint might have become satisfiable (or more nearly satisfiable). 
The complete algorithm is shown in Figure 9. 2.7 Strict Inequalities Cassowary supports linear equations and non-strict inequalities, but not strict inequalities. 
It would be straightforward to add support for strict inequalities, but doing this would have some consequences that users might not expect, and so we believe it is not a good idea. 
The issue is that if strict inequalities were allowed, it would be easy to construct constraint hierarchies such that there were no solutions to the hierarchy, even though the required constraints could be satisfied. 
For example, consider the constraint hierarchy . 
For any candidate solution , the solution more nearly satisfies the weak constraint—and so there is no solution to the hierarchy. 
(An analogous problem occurs with the simplex algorithm itself—consider minimizing subject to .) If strict inequalities were nevertheless desired, they could be supported in the same manner as described by either Jaffar et al. [1992] or Van Hentenryck and Graf [1990]. 
The algorithm would additionally check for error variables in the objective function with infinitesimal values; and if one were found, raise a “no solution to constraints” exception. 
2.8 Algorithm Summary The Cassowary algorithm supports three basic operations: —incremental addition of a new constraint, and re-optimization to find a weighted-sumbetter solution; —incremental deletion of a previousconstraint (using its marker variable), and re-optimization to find a weighted-sum-better solution; and inc deletion( , , , , ) foreach if or is basic in row then := 0 endif endfor ifis parametric variable if choose such that remove row from else choose arbitrary rowin remove the row from replace by in for each row in replace by in row endif endfor endif endif := error variables of constraint for which is marker := with coefficients of variables set to 0 := simplex opt( , ) return Fig. 9. Incremental deletion and reoptimization for a constraint with marker variable deleted from with objective function —incremental resolving to find a weighted-sum-better solution after modification of edit constraints, including special treatment of stay constraints may change after every resolve. 
The third operation is the most crucial in terms of performance since it occurs in real-time as the user moves the mouse. 
While we have used only three constraint strengths in the examples in this paper, both the algorithm and implementation are general, and can be used with an arbitrary number of strengths. 
3. EMPIRICAL EVALUATION Cassowary has been implemented in Smalltalk, C++, and Java. 
In this section, we first describe timings for a large, real application (SCWM, the Scheme Constraints Window Manager), and then a set of benchmarks, including two graphical examples and some comparisons between Cassowary and a local propagation solver. 
The C++ and Java tests were performed on an 800 MHz Pentium machine running RedHat/Linux 7.0, using G++-2.96-69 and the Sun HotSpot JVM 1.3.0, respectively. 
All the Smalltalk tests were run using OTI Smalltalk R4.0, on an 800 MHz Pentium machine running Windows 2000. 
(Cassowary has also been ported to the Squeak dialect of Smalltalk.) 3.1 SCWM Performance For these tests, SCWM was running on a 2560x1024 Xinerma-enable XFree86 4.0 display. 
SCWM is written in C and Guile/Scheme and embeds the C++ implementation of Cassowary using a hand-written Guile/Scheme wrapper that was instrumented to support Fig. 10. A Binary Tree of Height 7 recording the time spent inside the various constraint operations. 
Adding 25 new XTerm windows and their implicit stay constraints required 3.6 ms per window to add the 8 initial constraints and 0.14 ms for each of 72 re-solves. 
Moving arbitrary windows around the desktop without any constraints relating the windows required about 0.48 ms for each re-solve. 
We then made awindow tiling of four windows and constrained a fifth window to be to the left of that tiled collection and a sixth to be to the right of it. Adding each of those constraints took 0.9 ms on average. 
Subsequently, we moved those six related windows around the screen a bit and measured that each resolve took only 0.66 ms. 3.2 Graphical Benchmarks Both of the examples in this subsection were implemented in Smalltalk. 
For the bounded quadrilateral demonstration shown in Figure 1, it took an average of 14.97 msec to re-solve the constraints and refresh the display for a new mouse position. 
There were an average of 0.2 pivots per refresh (the mouse was being moved quickly, so that there were a relatively large number of collisions with the sides of the windows). 
Of the 14.97 msec, 1.4% was spent in the constraint solver—in other words, almost all of the time was taken by graphics refresh and input handling. 
Figure 10 shows a binary tree of height 7, which exercises the constraint solver more vigorously. 
Each node in the tree has a weak stay, and is required to lie within the confines of the window. 
Also, thevalues of the two children of each parent are required to be equal, and to be at least 10 pixels below the parent’svalue. 
The value of the parent node is required to be halfway between thevalues of its children. 
There are a total of 1015 constraints for the height 7 tree. 
When the user moved the root node of the tree, it took an average of 41.4 msec to re-solve the constraints and refresh the display for a new mouse position, of which 33% was spent in the constraint solver. 
There were an average of 5.9 pivots per refresh (so many more collisions than with the quadrilateral—as with the quadrilateral, the mouse was being moved very quickly). 
3.3 Local Propagation Comparisons Efficient incremental algorithms have been developed that solve systems of constraints using multi-way local propagation, e.g. 
DeltaBlue [Sannella et al. 1993], SkyBlue [Sannella 1994], and QuickPlan [Vander Zanden 1996]. 
In this section, we compare the performance of DeltaBlue and Cassowary on the same constraint problems. 
DeltaBlue is much more efficient—but it only handles equality constraints, not inequalities, and requires that the constraint graph be acyclic. 
We report the results for three benchmarks: the chain, the tree, and the star. 
These have all been used in previously published descriptions of local propagation algorithms. 
In each case the times are for Smalltalk implementations of DeltaBlue and Cassowary, both running on the same 800 MHz machine, to allow a head-to-head comparison. 
3.3.1 Chain Benchmark. 
In the chain benchmark, we construct a long chain of required equality constraints. 
There is a weak stay on .In DeltaBlue, there is implicitly also a weakest stay on every variable; in Cassowary, the other variables have no additional constraints. 
In DeltaBlue, the equality constraints are satisfied using the methods; in other words, the values ofare all ultimately determined by . 
In Cassowary, the error variablesand for the weak stay on are parametric, and are basic. 
We then add a strong edit constraint to. In DeltaBlue, this causes each of the 999 equality constraints to flip and select the other satisfaction method: . 
In Cassowary, the error variables and for the edit constraint become basic, and one of the error variables for the stay becomes parametric—so that each row formust be changed. 
Thus, adding the edit constraint is a pessimal case for both solvers, in that every constraint must be touched. 
We then repeatedly change the value ofusing the edit constraint. 
The results are shown in Figure 11. Action DeltaBlue Cassowary build chain with 1000 variables (total time) 70.6 38004.0 add strong edit constraint 5.4 61.0 initial solution 4.5 12528.0 change value ofone time 0.4 5.9 Fig. 11. Chain Benchmark for chain of length 1000. 
All times are in msec. 
3.3.2 Star Benchmark. 
In the Star benchmark, there are input variables , output variables, and a single offset . 
These variables are related by required constraints . 
Each input variable has a medium stay, and each output variable has a weak stay. 
We then add a strong edit constraint to the offset. 
(In DeltaBlue, this forces the solver to choose a different methodfor each of the requiredoffset constraints.) Then, as the value of the offset is edited, each output variable changes as well to satisfy the constraints. 
The results are shown in Figure 12. (In the original benchmark, each input variable is multiplied by a scaling factor, rather than being added to an offset—but these constraints would be nonlinear. 
DeltaBlue’s performance is not affected by this change.) Action DeltaBlue Cassowary build star with (total time) 26.3 1483.0 add strong edit constraint to offset 0.7 initial solution 0.6 2003.0 change value of offset one time 0.1 1.5 Fig. 12. Star Benchmark for . 
All times are in msec. 
3.3.3 Tree Benchmark. 
In the Tree benchmark, a binary tree of depth is constructed. 
The value at each interior node is constrained to be the sum of the values of its children. 
There is also a weak stay constraint on each leaf. 
We then add a strong edit constraint to the root. 
This benchmark is a particularly favorable case for DeltaBlue, but not for Cassowary: in DeltaBlue adding the strong edit constraint requires touching onlyof the constraints, while in Cassowary it requires only one pivot, but on a constraint of size. 
The results are shown in Figure 13. Action DeltaBlue Cassowary build tree of depth 10 (total time) 231.5 2413.0 add strong edit constraint to root 0.3 241.0 initial solution 0.1 891.0 change value of root one time 0.01 6.4 Fig. 13. Tree Benchmark for. 
All times are in msec. 
3.4 Remarks In all of our interactive graphical applications, during manipulation the time to refresh the picture and handle input dominated the constraint satisfaction time. 
Interaction times remain satisfactory for diagrams with 1000 constraints. 
Cassowary is much slower than a local propagation solver when run on the same problem—an order of magnitude for resolve time, and slower still for finding the initial solution. 
In many situations this will not matter, since the constraint satisfaction time in either case will be a small portion of the overall time. 
In situations where this is an issue, however, these results indicate that a hybrid solver architecture would be beneficial, in which there are cooperating subsolvers, including one to handle local propagation constraints and another to handle linear equalities and inequalities. 
Then, when possible, constraints would be allocated to the more efficient local propagation solver. 
A cooperating-subsolver architecture is used in Ultraviolet, but some adaptations would be needed to use it efficiently with Cassowary [Borning and Freeman-Benson 1998]. 
4. APPLICATIONS The various implementations of Cassowary are actively being used. 
A Scheme wrapping of the C++ implementation is used in the Scheme Constraints Window Manager. 
We have also embedded the C++ implementation in a prototype web browser that supports Constraint Cascading Style Sheets (CCSS) [Badros et al. 1999], our constraint-based extension to Cascading Style Sheets. 
CCSS allows both the designer and the viewer to place constraints on the appearance of a web page, for example, on page width or font size. 
Some of these constraints can be requirements, and others preferences. 
As a result, the final appearance of the page is in effect the result of an arbitration between the desires of the designer and the viewer, where this arbitration is carried out by solving the combined sets of constraints. 
An earlier, related system is described in Borning et al. [1997; 2000]. 
Just as CCSS extends Cascading Style Sheets with constraints, so CSVG, the Constraint Structured Vector Graphics standard [Badros et al. 2001], extends SVG with constraints. 
A SVG viewer, augmented with Cassowary, allows diagrams to be laid out in different ways depending on the constraints from the author and from the viewer. 
In other work, a demonstration Constraint Drawing Application using the Java implementation was written by Michael Noth and is included with the Cassowary toolkit. 
Cassowary has also been used in a non-interactive application to perform consistency checks in a planning application [Wolfman and Weld 1999]. 
5. CONCLUSION The Cassowary algorithm is an efficient constraint solver for interactive user interface applications, which handles simultaneous linear equations and inequalities. 
Because of the minimal update of the tableau which is performed, it is (perhaps surprisingly) fast on the operation of incrementally resolving the system. 
That operation’s efficiency is crucial for interactive redrawing diagrams during editing. 
Additionally, because Cassowary handles cycles in the constraint graph without difficulty, users of the Cassowary implementations can concentrate on exploiting the additional expressiveness that the library provides; the declarative nature of constraints is not undermined by a need to reformulate the problem to avoid cycles. 
Cassowary has proven to be efficient and expressive enough to be used in many applications. 
ELECTRONIC APPENDIX The electronic appendix for this article can be accessed in the ACM Digital Library by visiting the following URL: http://www.acm.org/pubs/citations/journals/TOCHI/2002?-?/p1-Badros. 
ACKNOWLEDGMENTS Thanks to Kim Marriott for his work on the closely-related QOCA algorithm and comments on Cassowary. 
We received much useful feedback from early users of our toolkit including Anthony Beuriv´e, Alexandre Duret-Lutz, Michael Kaufmann, Brian Grant, Pengling He, Tessa Lau, Sorin Lerner, John MacPhail, Larry Melia, Michael Noth, Emmanual Pietriga, Stefan Saroiu, and Steve Wolfman. 
REFERENCES BADROS,G.,TIRTOWIDJOJO,J.J.,MARRIOTT,K.,MEYER,B.,PORTNOY,W.,AND BORNING, A. 2001. 
A constraint extension to scalable vector graphics. 
In Proceedings of the tenth World Wide Web Conference WWW’10. 
BADROS,G.J.AND BORNING, A. 2001. 
Cassowary constraint solving toolkit. 
Web page. 
http://www. 
cs.washington.edu/research/constraints/cassowary. 
BADROS,G.J.,BORNING,A.,MARRIOTT,K.,AND STUCKEY, P. 1999. 
Constraint cascading style sheets for the web. 
In Proceedings of the 1999 ACM Conference on User Interface Software and Technology. 
ACM, New York. 
BADROS,G.J.,NICHOLS,J.,AND BORNING, A. 2000. 
SCWM—the Scheme Constraints Window Manager. 
In Proceedings of the AAAI Spring Symposium on Smart Graphics. 
BARAFF, D. 1994. 
Fast contact force computation for nonpenetrating rigid bodies. 
In SIGGRAPH ’94 Conference Proceedings. 
ACM, New York, 23–32. 
BORNING,A.,ANDERSON,R.,AND FREEMAN-BENSON, B. 1996. 
Indigo: A local propagation algorithm for inequality constraints. 
In Proceedings of the 1996 ACM Symposium on User Interface Software and Technology. 
ACM, New York, 129–136. 
BORNING,A.AND BADROS, G. 2000. 
On finding graphically plausible solutions to constraint hierarchies: The split stay problem. 
In Workshop on Soft Constraints: Theory and Practice. 
Sixth International Conference on Principles and Practice of Constraint Programming, Singapore. 
Available from http://www.cs. washington.edu/research/constraints. 
BORNING,A.AND FREEMAN-BENSON,B. 
1998. 
Ultraviolet: A constraint satisfaction algorithm for interactive graphics. 
Constraints 3, 1 (Apr.), 9–32. 
BORNING,A.,FREEMAN-BENSON,B.,AND WILSON, M. 1992. 
Constraint hierarchies. 
Lisp and Symbolic Computation 5, 3 (Sept.), 223–270. 
BORNING,A.,LIN,R.,AND MARRIOTT, K. 1997. 
Constraints for the web. 
In Proceedings of ACM MULTIMEDIA’97. 
BORNING,A.,LIN,R.,AND MARRIOTT, K. 2000. 
Constraint-based document layout for the web. 
Multimedia Systems 8, 3, 177–189. 
BORNING,A.,MARRIOTT,K.,STUCKEY,P.,AND XIAO, Y. 1997. 
Solving linear arithmetic constraints for user interface applications. 
In Proceedings of the 1997 ACM Symposium on User Interface Software and Technology. 
ACM, New York. 
HOSOBE,H.,MATSUOKA,S.,AND YONEZAWA, A. 1996. 
Generalized local propagation: A framework for solving constraint hierarchies. 
In Proceedings of the Second International Conference on Principles and Practice of Constraint Programming. 
Springer-Verlag LLNCS 1118, Heidelberg, Germany. 
HUDSON,S.AND SMITH, I. 1996. 
SubArctic UI toolkit user’s manual. Tech. 
rep., College of Computing, Georgia Institute of Technology. 
HUYNH,T.AND MARRIOTT, K. 1995. 
Incremental constraint deletion in systems of linear constraints. 
Information Processing Letters 55, 111–115. 
JAFFAR,J.,MICHAYLOV,S.,STUCKEY,P.,AND YAP, R. 1992. 
The CLP( ) language and system. 
ACM Transactions on Programming Languages and Systems 14, 3 (July), 339–395. 
MARRIOTT,K.AND STUCKEY, P. 1998. 
Programming with Constraints: An Introduction. 
MIT Press, Cambridge, Massachusetts. 
MYERS, B. A. 1996. 
The Amulet user interface development environment. 
In CHI’96 Conference Companion: Human Factors in Computing Systems. 
ACM, New York. 
PRESS,W.H.,FLANNERY,B.P.,TEUKOLSKY,S.A.,AND VETTERLING, W. T. 1989. 
Numerical Recipes: The Art of Scientific Computing, second ed. Cambridge University Press. 
SANNELLA, M. 1994. 
SkyBlue: A multi-way local propagation constraint solver for user interface construction. 
In Proceedings of the 1994 ACM Symposium on User Interface Software and Technology. 
ACM, New York, 137–146. 
SANNELLA,M.,MALONEY,J.,FREEMAN-BENSON,B.,AND BORNING, A. 1993. 
Multi-way versus oneway constraints in user interfaces: Experience with the DeltaBlue algorithm. 
Software—Practice and Experience 23, 5 (May), 529–566. 
SUTHERLAND, I. 1963. 
Sketchpad: A man-machine graphical communication system. 
In Proceedings of the Spring Joint Computer Conference. 
IFIPS, 329–346. 
VAN HENTENRYCK,P.AND GRAF, T. 1990. 
Standard forms for rational linear arithmetic in constraint logic programming. 
Internal report ir-lp-2217, European Computer Research Centre. 
VANDER ZANDEN, B. 1996. 
An incremental algorithm for satisfying hierarchies of multi-way dataflow constraints. 
ACM Transactions on Programming Languages and Systems 18, 1 (Jan.), 30–72. 
WOLFMAN,S.AND WELD, D. 1999. 
The LPSAT engine and its application to resource planning. 
In Proceedings of IJCAI’99. 
Received January 2000; July 2001; accepted November 2001 The Cassowary Linear Arithmetic Constraint Solving Algorithm App–1 THIS DOCUMENT IS THE ONLINE-ONLY APPENDIX TO: The Cassowary Linear Arithmetic Constraint Solving Algorithm GREG J. BADROS and ALAN BORNING University of Washington and PETER J. STUCKEY University of Melbourne To appear, ACM Transactions on Computer-Human Interaction, Vol. 
?, No. ?, ? 
2002, Pages 1–30. 
A. IMPLEMENTATION DETAILS A.1 Principal Classes The principal classes in our implementations are as follows. 
All the classes start with “Cl” for “Constraint Library” and are, of course, direct or indirect subclasses of Object in the Smalltalk and Java implementations. 
Object ClAbstractVariable ClDummyVariable ClObjectiveVariable ClSlackVariable ClVariable ClConstraint ClEditOrStayConstraint ClEditConstraint ClStayConstraint ClLinearConstraint ClLinearEqualityConstraint ClLinearInequalityConstraint ClLinearExpression ClTableau ClSimplexSolver ClStrength ClSymbolicWeight Permission to make digital/hard copy of all or part of this material without fee for personal or classroom use provided that the copies are not made or distributed for profit or commercial advantage, the ACM copyright/server notice, the title of the publication, and its date appear, and notice is given that copying is by permission of the ACM, Inc. 
To copy otherwise, to republish, to post on servers, or to redistribute to lists requires prior specific permission and/or a fee. 
c2002 ACM 0000-0000/2002/0000-0001 $5.00 App–2 Greg Badros et al. Some of these classes make use of the Dictionary (or map) abstract data type: dictionaries have keys and values and permit efficiently finding the value for a given key, and adding or deleting key/value pairs. 
One can also iterate through all keys, all values, or all key/value pairs. 
A.2 Solver Protocol The solver itself is represented as an instance of ClSimplexSolver. 
Its public message protocol is as follows. 
addConstraint(ClConstraint cn). 
Incrementally add the linear constraint cn to the tableau. 
The constraint object contains its strength. 
removeConstraint(ClConstraint cn). 
Remove the constraint cn from the tableau. 
Also remove any error variables associated with cn from the objective function. 
addEditVar(ClVariable v, ClStrength s). Add an edit constraint of strength s on variable v to the tableau so that suggestValue (see below) can be used on that variable after a beginEdit(). 
removeEditVar(ClVariable v). Remove the previously added edit constraint on variable v. The endEdit message automatically removes all the edit variables as part of terminating an edit manipulation. 
beginEdit(). 
Prepare the tableau for new values to be given to the currently-edited variables. 
The addEditVar message should be used before calling beginEdit, and suggestValue and resolve should be used only after beginEdit has been invoked, but before the required matching endEdit. 
suggestValue(ClVariable v, double n). Specify a new desired value n for the variable v. Before this call, v needs to have been added as a variable of an edit constraint (either by addConstraint of a hand-built EditConstraint object or more simply using addEditVar). 
endEdit(). 
Denote the end of an edit manipulation, thus removing all edit constraints from the tableau. 
Each beginEdit call must be matched with a corresponding endEdit invocation, and the calls may be nested properly. 
resolve(). 
Try to re-solve the tableau given the newly specified desired values. 
Calls to resolve should be sandwichedbetween a beginEdit() and an endEdit(), and should occurafter new values for edit variables are set using suggestValue. 
addPointStays(Vector points). 
This method is a bit of a kludge, and addresses the desire to satisfy the stays on both the x and y components of a given point rather than on the x component of one point and the y component of another. 
The argument points is an array of points, whose x and y components are constrainable variables. 
This method adds a weak stay constraint to the x and y variables of each point. 
The weights for the x and y components of a given point are the same. 
However, the weights for successive points are each smaller than those for the previous point (1/2 of the previous weight). 
The effect of this is to encourage the solver to The Cassowary Linear Arithmetic Constraint Solving Algorithm App–3 satisfy the stays on both the x and y of a given point rather than the x stay on one point and the y stay on another. 
See Borning and Badros [2000] for more discussion of this issue, and a proposal for a cleaner solution. 
setAutoSolve(boolean f). Choose whether the solver should automatically optimize and set external variable values after each addConstraint or removeConstraint. 
By default, auto-solving is on, but passing false to this method will turn it off (until later turned back on by passing true to this method). 
When auto-solving is off, solve (below) or resolve must be invoked to see changes to the ClVariables contained in the tableau. 
isAutoSolving() returns boolean. 
Return true if and only if the solver is auto-solving, false otherwise. 
solve(). 
Optimize the tableau and set the external ClVariables contained in the tableau to their new values. 
This method need only be invoked if auto-solving has been turned off. 
It never needs to be called after a resolve method invocation. 
reset(). 
Re-initialize the solver from the original constraints, thus getting rid of any accumulated numerical problems. 
(It is not yet clear how often such problems arise, but we provide the method just in case.) A.2.1 Variables. 
ClAbstractVariable and its subclasses represent various kinds of constrained variables. 
ClAbstractVariable is an abstract class, that is, it is just used as a superclass of other classes; one does not make instances of ClAbstractVariable itself. 
ClAbstractVariable defines the message protocol for constrainable variables. 
Its only instance variable is name, which is a string name for the variable. 
(This field is used for debugging and constraint understanding tasks.) Instances of the concrete ClVariable subclass of ClAbstractVariable are what the user of the solver sees (hence it was given a nicer class name). 
This class has an instance variable value that holds the value of this variable. 
Users of the solver can send one of these variables the message value to get its value. 
The other subclasses of ClAbstractVariable are used only within the solver. 
They do not hold their own values—rather, the value is just given by the current tableau. 
None of them have any additional instance variables. 
Instances of ClSlackVariable are restricted to be non-negative. 
They are used as the slack variable when converting an inequality constraint to an equation and for the error variables to represent non-required constraints. 
Instances of ClDummyVariable is used as a marker variable to allow required equality constraints to be deleted. 
(For inequalities or non-required constraints, the slack or error variable is used as the marker.) These dummy variables are never pivoted into the basis. 
An instance of ClObjectiveVariable is used to index the objective row in the tableau. 
(Conventionally this variable is named.) This kind of variable is just for convenience— the tableau is represented as a dictionary (with some additional cross-references). 
Each row is represented as an entry in the dictionary; the key is a basic variable and the value is an expression. 
So an instance of ClObjectiveVariable is the key for the objective row. 
The objective row is unique in that the coefficients of its expression are ClSymbolicWeights in the Smalltalk implementation, not just ordinary real numbers. 
However, the C++ and Java implementations convert ClSymbolicWeights to real numbers to avoid dealing with App–4 Greg Badros et al. ClLinearExpressions parameterized on the type of the coefficient—see Section A.2.5 for more details. 
All variables understand the following messages: isDummy, isExternal, isPivotable, and isRestricted. 
They also understand messages to get and set the variable’s name. 
Class isDummy isExternal isPivotable isRestricted ClDummyVariable true false false true ClVariable false true false false ClSlackVariable false false true true ClObjectiveVariable false false false false Fig. 14. Subclasses of ClAbstractVariable For isDummy, instances of ClDummyVariable return true and others return false. 
The solver uses this message to test for dummy variables. 
It will not choose a dummy variable as the subject for a new equation, unless all the variables in the equation are dummy variables. 
(The solver also will not pivot on dummy variables, but this is handled by the isPivotable message.) For isExternal, instances of ClVariable return true and others return false. 
If a variable responds true to this message, it means that it is known outside the solver, and so the solver needs to give it a value after solving is complete. 
For isPivotable, instances of ClSlackVariable return true and others return false. 
The solver uses this message to decide whether it can pivot on a variable. 
For isRestricted, instances of ClSlackVariable and of ClDummyVariable return true, and instances of ClVariable and ClObjectiveVariable return false. 
Returning true means that this variable is restricted to being non-negative. 
A variable’s significance is largely just its identity (as mentioned above, variables have little state: a name for debugging and a value for instances of ClVariable). 
The only other messages that variables understand are some messages to ClVariable for creating constraints—see Section A.2.4. 
A.2.2 Linear Expressions. 
Instances of the class ClLinearExpression hold a linear expression and are used in building and representing constraints and in representing the tableau. 
A linear expression holds a dictionary of variables and coefficients (the keys are variables and the values are the corresponding coefficients). 
Only variables with nonzero coefficients are included in the dictionary; if a variable is not in this dictionary its coefficient is assumed to be zero. 
The other instance variable is a constant. 
So to represent the linear expression, the dictionary would hold the key with value, etc., and the constant . 
Linear expressions understand a large number of messages. 
Some of these are for constraint creation (see Section A.2.4). 
The others are to substitute an expression for a variable in the constraint, to add an expression, to find the coefficient for a variable, and so forth. 
A.2.3 Constraints. 
There is an abstract class ClConstraint that serves as the superclass for other concrete classes. 
It defines two instance variables: strength and weight. 
The variable strength is the strength of this constraint in the constraint hierarchy (and should be an instance of ClStrength), while weight is a float indicating the actual weight The Cassowary Linear Arithmetic Constraint Solving Algorithm App–5 of the constraint at its indicated strength, or nil/null if it does not have a weight. 
(Weights are only relevant for weighted-sum-better comparators, not for locally-error-better ones.) Constraints understand various messages that return true or false regarding some aspect of the constraint, such as isRequired, isEditConstraint, isStayConstraint, and isInequality. 
ClLinearConstraint is an abstract subclass of ClConstraint. 
It adds an instance variable expression, which holds an instance of ClLinearExpression. 
It has two concrete subclasses. 
An instance of ClLinearEquation represents the linear equality constraint expression = 0. An instance of ClLinearInequality represents the constraint expression0. 
The other part of the constraint class hierarchy is for edit and stay constraints (both of which are represented explicitly). 
ClEditOrStayConstraint has an instance field variable, which is the ClVariable with the edit or stay. 
Otherwise all that the two concrete subclasses do is respond appropriately to the messages isEditConstraint and isStayConstraint. 
This constraint hierarchy is also intendedto allow extension to include local propagation constraints (which would be another subclass of ClConstraint)—otherwise we could have made everything be a linear constraint, and eliminated the abstract class ClConstraint entirely. 
A.2.4 ConstraintCreation. 
This subsection describes a mechanismto allow constraints to be defined easily by programmers. 
The convenience afforded by our toolkit varies among languages. 
Smalltalk’s dynamic nature makes it the most expressive. 
C++’s operator overloading still permits using natural infix notation. 
Java, however, requires using ordinary methods, and leaves us with the single option of prefix expressions when building constraints. 
In Smalltalk, the messages +, -, *, and / are defined for ClVariable and ClLinearExpression to allow convenient creation of constraints by programmers. 
Also, ClVariable and ClLinearExpression, as well as Number, define cnEqual:, cnGEQ:, and cnLEQ: to return linear equality or inequality constraints. 
Thus, the Smalltalk expression 3*x+5 cnLEQ: y returns an instance of ClLinearEquality representing the constraint. 
The expression is evaluated as follows: the number 3 gets the message *x. Since x is not a number, 3 sends the message *3to x. x is an instance of ClVariable, which understands * to return a new linear expression with a single term, namely itself times the argument. 
(If the argument is not a number it raises an exception that the expression is non-linear.) The linear expression representinggets the message + with the argument 5, and returns a new linear expression representing. 
This linear expression gets the message cnLEQ: with the argument y. It computes a new linear expression representing, and then returns an instance of ClLinearInequality with this expression. 
(It is tempting to make this nicer by using the, , and messages, so that one could write 3*x+5y App–6 Greg Badros et al. instead but because the rest of Smalltalk expects , , and to perform a test and return a boolean, rather than to return a constraint, this would not be a good idea.) Similarly, in C++ the arithmetic operatorsare overloadedto build ClLinearExpressions from ClVariables and other ClLinearExpressions. 
Actual constraints are built using various constructors for ClLinearEquation or ClLinearInequality. 
An enumeration defines the symbolic constants cnLEQ and cnGEQ to approximate the Smalltalk interface. 
For example: ClLinearInequality cn(3*x+5, cnLEQ, y); // C++ build the constraint cn representing. 
In Java, the same constraint would be built as follows: ClLinearInequality cn = new ClLinearInequality(CL.Plus(CL.Times(x,3),5), CL.LEQ, y); Although the Java implementation makes it moredifficultto express programmer-written constraints, this inconvenienceis relativelyunimportant when thesolver is used in conjunction with graphical user interfaces for specifying the constraints. 
A.2.5 Symbolic Weights and Strengths. 
The constraint hierarchy theory allows an arbitrary, finite, number of strengths of constraint. 
In practice, however, programmers use a small numberof strengths in a stylized way. 
The implementationtherefore includes a small number of pre-defined strengths, and for efficiency the maximum number of strengths is defined as a compile-time constant. 
(This constant can be easily changed, but we have not found it necessary to do so in practice.) The strengths provided in the current release are: required. 
Required constraints must be satisfied and should be used only for relationships that make no sense unless they are exactly met. 
The most common use of a required constraint is to give a shorthand name to an expression such as: win right win left win width strong. 
This strength is conventionally used for edit constraints. 
medium. 
This strength can be used for strong stays constraints; for example, we might put medium strength stay constraints on the width and height of an object and weak stay constraints on its position to represent our preference that the object move instead of change size when either is possible to maintain the stronger constraints. 
weak. 
This strength is used for stay constraints. 
Each strength category is represented as an instance of ClStrength. 
A related class is ClSymbolicWeight. 
As mentioned in Section 2.3, the objective function is formed as the weighted sum of the positive and negative errors for the non-required constraints. 
The weights should be such that the stronger constraints totally dominate the weaker ones. 
In general to pick a real number for the weight we need to know how big the values of the variables can be. To avoid this problem altogether, in the Smalltalk and C++ implementations we use symbolic weights and a lexicographic ordering for the weights rather than real numbers, which ensures that strong constraints are always satisfied in preference to weak ones. 
Instances of ClSymbolicWeight are used to represent these symbolic weights. 
These instances have an array of floating point numbers, whose length is the number of nonrequired strengths (so 3 at the moment). 
Each element of the array represents the value The Cassowary Linear Arithmetic Constraint Solving Algorithm App–7 at that strength, so represents a weight of 1.0 strong, 0.0 medium, and 10.0 weak. 
(In Smalltalk ClSymbolicWeight is a variable length subclass; we could have had an instance variable with an array of length 3 instead.) Symbolic weights understand various arithmetic messages (or operator overloading in C++) as follows: +w. w is also a symbolic weight. 
Return the result of adding w to self (or this in C++). 
–w. w is also a symbolic weight. 
Return the result of subtracting w from self. 
*n. n is a number. 
Return the result of multiplying self by n. /n. n is a number. 
Return the result of dividing self by n. n, n, n, n, n. w is a symbolic weight. 
Return true if self is related to n as the operator normally queries. 
negative. 
Return true if this symbolic weight is negative (i.e., it does not consist of all zeros and the first non-zero number is negative). 
Instances of ClStrength represent a strength in the constraint hierarchy. 
The instance variables are name (for printing purposes) and symbolicWeight, which is the unit symbolic weight for this strength. 
Thus, with the 3 strengths as above, strong is, medium is, and weak is . 
The above arithmetic messages let the Smalltalk implementation of the solver use symbolic weights just like numbers in expressions. 
This interface is important because the objective row in the tableau has coefficients which are ClSymbolicWeights but are subject to the same manipulations as the other tableau rows whose expressions have coefficients that are just real numbers. 
In both C++ and Java, an additional message asDouble() is understood by ClSymbolicWeights. 
This converts the representation to a real number that approximates the total ordering suggested by the more general vector of real numbers. 
It is these real numbers that are used as the coefficients in the objective row of the tableau instead of ClSymbolicWeights (which the coefficients conceptually are). 
This kludge avoids the complexities that such genericity introduces to the static type systems of C++ and Java. 
Also, since Java lacks operator overloading, the above operations are invoked using suggestive alphabetic method names such as add, subtract, times, and lessThan. 
A.3 ClSimplexSolver Implementation Here are the instance variables of ClSimplexSolver (some fields areinherited from ClTableau, the base class of ClSimplexSolver which provides the basic sparse-matrix interface—see Section A.3.1). rows. 
A dictionary with keys ClAbstractVariable and values ClLinearExpression. 
This holds the tableau. 
Note that the keys can be either restricted or unrestricted variables, i.e., both and are actually merged into one tableau. 
This simplified the code considerably, since most operations are applied to both restricted and unrestricted rows. 
App–8 Greg Badros et al. columns. 
A dictionary with keys ClAbstractVariable and values Set of ClAbstractVariable. 
These are the column cross-indices. 
Each parametric variable p should be a key in this dictionary. 
The corresponding set should include exactly those basic variables whose linear expression includes p (p will of course have a non-zero coefficient). 
The keys can be either unrestricted or restricted variables. 
objective. 
An instance of ClObjectiveVariable (named z) that is the key for the objective row in the tableau. 
infeasibleRows. 
A set of basic variables that have infeasible rows. 
(This field is used when re-optimizing with the dual simplex method.) prevEditConstants. 
An array of constants (floats)for the edit constraints onthe previousiteration. 
The elements in this array must be in the same order as editPlusErrorVars and editMinusErrorVars, and the argument to the public resolve: message. 
stayPlusErrorVars, stayMinusErrorVars. 
An array of plus/minus error variables (instances of ClSlackVariable) for the stay constraints. 
The corresponding negative/positive error variable must have the same index in stayMinusErrorVars/stayPlusErrorVars. 
editPlusErrorVars, editMinusErrorVars. 
An array of plus/minus error variables (instances of ClSlackVariable) for the edit constraints. 
The corresponding negative/positive error variable must have the same index in editMinusErrorVars/editPlusErrorVars. 
markerVars. 
A dictionary whose keys are constraints and whose values are instances of a subclass of ClAbstractVariable. 
This dictionary is used to find the marker variable for a constraint when deleting that constraint. 
A secondary use is that iterating through the keys will give all of the original constraints (useful for the reset method). 
errorVars. 
A dictionary whose keys are constraints and whose values are arrays of ClSlackVariable. 
This dictionary gives the error variable (or variables) for a given non-required constraint. 
We need this if the constraint is deleted because the corresponding error variables must be deleted from the objective function. 
A.3.1 ClTableau (Sparse Matrix) Operations. 
The basic requirements for the tableau representation are that one should be able to perform the following operations efficiently: —determine whether a variable is basic or parametric —find the corresponding expression for a basic variable —iterate through all the parametric variables with non-zero coefficients in a given row —find all the rows that contain a given parametric variable with a non-zero coefficient —add/remove a row —remove a parametric variable —substitute out a variable (i.e., replace all occurrences of a variable with an expression, updating the tableau as appropriate). 
The Cassowary Linear Arithmetic Constraint Solving Algorithm App–9 The representation of the tableau as a dictionary of rows, with column cross-indices, supports these operations. 
Keeping the cross indices up-to-date and consistent with the row dictionary is error-prone. 
Thus, the solver actually accesses the rows and columns only via the below interface of ClTableau. 
addRow(ClAbstractVariable var, ClLinearExpression expr). 
Add the constraint var=expr to the tableau. 
var will become a basic variable. 
Update the column cross indices. 
noteAddedVariable(ClAbstractVariable var, ClAbstractVariable subject). 
Variable var has been added to the linear expression for subject. 
Update the column cross indices. 
noteRemovedVariable(ClAbstractVariable var, ClAbstractVariable subject). 
Variable var has been removed from the linear expression for subject. 
Update the column cross indices. 
removeColumn(ClAbstractVariable var). 
Remove the parametric variable var from the tableau. 
This operation involves removing the column cross index for var and removing var from every expression in rows in which it occurs. 
removeRow(ClAbstractVariable var). 
Remove the basic variable var from the tableau. 
Because var is basic, there should be a row var=expr. 
Remove this row, and also update the column cross indices. 
substituteOut(ClAbstractVariable var, ClLinearExpression expr). 
Replace all occurrences of var with expr and update the column cross indices. 
To appear, ACM Transactions on Computer-Human Interaction, Vol. 
?, No. ?, ? 
2002. 