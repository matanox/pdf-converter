JEL codes: E30, E10 Keywords: DSGE models; Solution of Linear Rational Expectations Models; Bayesian and Maximum-Likelihood Estimation; Inattentiveness. 
∗ This is an extended version of ou r paper with the same title published in th e Journal of the European Economic Asso ciation, April-May 2007. 
It includes a lengthy appendix laying out the model, solving it, proving the propositions, and exp laining the algorithms. 
All of the programs used are available at our websites. 
We are grateful to Tiago Berriel for excellent research assistance, and to Ruchir Agarwal and Mark Watson for useful comments. 
1. Introduction Estimation and simulation of medium-sized macroeconometric models has increasingly attracted the attention of economists who study monetary policy and the business cycle. 
1 This paper contributes to that eﬀort by focusing on a model in which sticky information is the key imperfection that causes output to deviate from its long-run classical benchmark. 
In this otherwise standard dynamic stochastic general equilibrium model, information is updated sporadically by firms setting prices, workers setting wages, and consumers setting the level of spending. 
Solution and estimation of a general equilibrium model with sticky information raises sev eral thorny technical issues. 
We begin this paper outlining those issues and proposing solutions. 
Our first contribution is methodological. It consists of two propositions that pro vide an algorithm that eﬃciently solves medium-sized sticky-information models, derives their impulse response functions, and calculates their likelihood in a few seconds. 
We then proceed to estimate the model using five key time-series: inflation, output, hours worked, wages, and an interest rate. 
The sec ond contribution of this paper is to propose, implement, and compare two estimation strategies for the model: maximum likelihood and a Bayesian approac h. The two strategies yield similar results. 
We thus obtain estimates of how much information stickiness is needed to explain business cycle dynamics. 
We find that about a fifth of workers and consumers update their information sets every quarter, so the mean information lag for both household members is approximately five quarters. 
By con trast, firms are estimated to be much better informed when sett ing prices: about two-thirds update their information set every quarter. 
The model also produces an estimated variance decomposition, which shows how much of the variation in each variable is attributable to each of the five shocks in the model. 
For inflation, over 80 percent of the variance is attributable to the monetary policy shock. 
For output growth and hours worked, the monetary policy shock is important, but so is the shock to aggregate demand. 
The other three shocks–to productivity, the goods markup, and the labor markup–are estimated to explain only a small fraction of the variance of inflation, output growth, a nd hours worked. 
2. Themodeloftheeconomy 1 See, for instance, Smets and Wouters (2003) and Levin, Onatksi, Williams and Williams (2006) We study a general-equilibrium model with monopolistic competition and no capital accumulation, familiar in the literature on monetary policy. 
We assume a c on tinuum of households with preferences that are additively separable and iso-elastic in consumption and leisure. 
Households live forever and wish to maximize expected discounted utility while being able to s ave and borrow b y trading bonds between themselves. 
We think of households as having two members: a worker and a consumer. 
The workers sell labor to firms in a set of segmented markets for diﬀerent labor varieties, where each worker is the sole provider of each variety. 
The consumers buy a continuum of varie ties of goods from firms, which they value according to a Dixit-Stiglitz aggregator. 
There is a continuum of firms, each selling one variety of goods under monopolistic competition. 
Each firm operates a decreasing returns to scale technology in total labor input, which is a Dixit-Stiglitz aggregate of the diﬀeren t varieties of labor. 
Finally, monetary policy follows a Taylor rule. 
Less common is our assumption on information. 
There are three agents making decisions in this economy: consumers, workers, and firms. 
We assume that each period, a fraction δ of consumers, a fraction ω or workers, and a fraction λ of firms, randomly drawn from their respective populations, obtain new information and calculate their optimal actions. 
This assumption of sticky information can be justified by costs of acquiring, absorbing and processing information (Reis, 2004, 2006) or by appealing to epidemiology (Carroll, 2002). 
2 We leave the detailed presentation of the model, the definition of an equilibrium and its log-linearization to the appendix. 
Here, we discuss the 5 key reduced-form relations. 
The first relation is the Phillips curve or aggregate supply curve: p t = λ ∞ X j=0 (1 − λ) j E t−j ∙ p t + β(w t − p t )+(1− β)y t − a t β + ν(1 − β) − βν t (ν − 1)[β + ν(1 − β)] ¸ . 
(1) The price level (p t ) depends on past expectations of: its current value, real marginal costs, and desired markups. 
3 Marginal costs are higher: the higher are the real wages paid to workers (w t − p t ), the more is produced (y t ) because of decreasing returns to scale ( β<1), and the lower is aggregate productivity (a t ). The desired markup falls with the elasticity of substitution across goods varieties (ν t ), which we allow to vary randomly over time. 
2 The optimal behavior of these inattentive agents and their interaction in markets raise some interesting challenges. 
We discuss these in Mankiw and Reis (2006). 
3 All variables with a t subscript refer to log-linearized values around their non-stochastic steady state. 
Without any subscript are fixed parameters and steady state values. 
Unexpected shocks to any o f these three variables only raise prices b y λ since only this share of price-setters is aware of the news. 
The second relation i s the IS curv e: y t = δ ∞ X j=0 (1 − δ) j E t−j (y n ∞ − θR t )+g t , (2) where the long-run equilibrium output is y n ∞ =lim i→∞ E t (y t+i ), and the long real interest rate is R t = E t h P ∞ j=0 (i t+j − ∆p t+1+j ) i . 
Higher expected future output raises wealth and increases spending, while higher expected interest rates encourage savings and lower spending. 
The impact of interest rates on spending depends on the intertemporal elasticity of substitution θ. Wedenotebyg t aggregate demand shocks, which in the model correspond to changes in government spending, but could also be modelled as changes in the desire f or leisure. 
The higher is δ, the larger the share of informed consumers that respond to shocks immediately. 
Next comes the wage curve: w t = ω ∞ X j=0 (1 − ω) j E t−j ∙ p t + γ(w t − p t ) γ + ψ + l t γ + ψ + ψ (y n ∞ − θR t ) θ(γ + ψ) − ψγ t (γ + ψ)(γ − 1) ¸ . 
(3) The five determinants of nominal wages are split into the five terms on the right-hand side. 
First, nominal wages rise one-to-one with prices since workers care about real wages. 
Second, the higher are real wages elsewhere in the economy the higher is demand for a worker’s variety of labor so the higher the wage she will demand. 
Third, the more labor is hired (l t ) t he better it must be compensated since the marginal disutility of working rises. 
Fourth, higher wealth discourages work through an income eﬀect, and higher interest rates promote it b y giving a larger return on saved earnings today. 
The product of ψ, the Frisch elasticity of labor supply, and θ, the intertemporal elasticity of substitution, determine the strength of this intertemporal labor supply eﬀect. 
Fifth and finally, if the elasticity of substitution across labor varieties (γ t ) rises, workers’ desired markup falls so they lower their wage demands. 
If many workers are informed (ω is high), wages are instantly very responsive to changes in these determinants, whereas otherwise wages only respond gradually over time. 
The fourth relation is a standard production function: y t = a t + βl t , (4) where β measures the extent of decreasing returns to scale from using more labor. 
The fifth and final relation i s the Taylor rule: i t = φ y (y t − y n t )+φ p ∆p t − ε t , (5) where y t − y n t is the output gap, or the diﬀerence between actual output and its level if all agents were attentive, and ε t are policy disturbances. 
These 5 equations give the equilibrium values for output, wages, prices, labor, and nominal interest rates as a function of shoc ks to aggregate p roductivity growth, aggregate demand, goods markups, labor markups, and monetary policy. 
We assume that each of these shocks follo ws an autoregressive process of order 1 with coeﬃcients ρ ∆a , ρ g , ρ ν , ρ γ , and ρ ε , and is subject to innovations e ∆a t , e g t , e ν t , e γ t ,ande ε t , that are independent and normally distributed with standard deviations σ ∆a , σ g , σ ν , σ γ ,andσ ε . 
3. Solving for the economy’s dynamics Our model fits into the general class of linear rational expectations models for which there are several ready-to-use solution algorithms. 
However, none of them is particularly useful to solve the sticky-information model. 
The model involv es both an infinite number of past expectations of the present through sticky information, as well as present expectations of variables at an infinite number of future dates through intert emporal smoothing. 
This double infinity implies that the state-space of the model has an infinite dimension, which current algo rithms cannot handle. 
4 We have developed a general algorithm that can solve this and much larger generalequilibrium models with sticky information in a few seconds. 
It is based on the following result, which comes from using a method of undetermined coeﬃcients and exploiting the recursiveness of the model’s dynamics: Proposition 1. Letting s ∈ S = {∆a, g, ν, γ, ε} denote the diﬀerent shocks, then p t = 4 Recently, Wang and Wei (2006) proposed an ingenious method to adapt existing algorithms to solve sticky-information models. 
We leave a systematic comparison of their m ethod with the one in this paper for future research. 
P s∈S P ∞ n=0 ˆp n (s)e s t−n where ˆp n (s) is a scalar measuring the impact of shock s at lag n on the price level. 
The undetermined coeﬃcients solve the second-or der diﬀerence equation: A n+1 ˆp n+1 (s) − B n ˆp n (s)+φ p ˆp n−1 (s)=C n (s) for n =0, 1, 2,... (6) with boundary conditions : ˆp −1 =0and lim n→∞ (ˆp n − ˆp n−1 )=0. 
The coeﬃcients A n and B n do not depend on the shock, while C n (s) does; all depend on the parameters and are given in the appendix. 
The appendix describes our algorithm to solve this diﬀerence equation and finds, in corollary 1, the solution for the other variables in the model as a function of the price dynamics. 
Figure 1 shows the responses of inflation, the output gap, and labor to one-standarddeviation shocks to monetary policy, aggregate productivity grow th, and aggregate demand. 
5 In response to a monetary expansion, output and labor increase as the economy enters a boom. 
Inflation rises gradually, following the hump-shaped pattern that has been found in empirical work. 
Noticeably, inflation is more persistent than output, another robust feature of the data that m any monetary models have trouble reproducing. 
The model fits well the facts on how the economy responds to monetary policy shocks. 
In response to a positive technological shock, inflation falls but converges rapidly to its previous level. 
Intere stingly positive productivity shocks in this economy lead to recessions, just as in sticky price models (Gali, 1999). 
However, this is not a robust feature of the sticky-information model: for diﬀerent parameter values, we can get a boom following a technological improvement. 
Finally, a positive innovation to aggregate demand raises inflation, output, and labor. 
4. Estimating the model We use U.S. quarterly data from 1954:3 to 2006:1 for the non-farm business sector. 
We measure wages using the total compensation per hour and labor input using total hours. 
We divide output and hours by the total civilian non-institutional population and deflate nominal variables using the implicit price deflator for the nonfarm business sector. 
Changes in the log of this deflator are our measure of inflation, and the eﬀective federal funds rate measures the nominal interest rate . 
5 The parameters are set at the maximum-likeliho od estimates in Table 1, described in the next section. 
Using these data, we build series for de-meaned inflation, output growth, nominal in terest rates, real wage growth, and hours. 
These are our observables, collected in the vector x t =(∆p t , ∆y t ,l t ,i t , ∆(w t − p t )) 0 . 
The sticky-information general-equilibrium model implies that x t = P ∞ i=0 Φ i e t−i where e t is the vector of shocks (e ε t ,e ∆a t ,e g t ,e ν t ,e γ t ) 0 and the Φ i are 5x5 matrices of coeﬃcients, found in proposition 1 and corollary 1. The question we ask in this section is how to estimate the vector of parameters of the model using these data. 
We estimate our model using both maximum likelihood and Bayesian methods. 
6 The key input into these methods is the likelihood function, which in standard dynamic m odels with a state-space solution can be evaluated using the Kalman filter. 
The solution of the model using proposition 1 does not have a con venient state-space representation, so we use instead the following result: Proposition 2. Given a sample of data of length T,letX be the 5T ×1 vector that vertically stacks the x t ,andletΩ be the 5T×5N matrix that vertically stacks [Φ j−1 Φ j−2 ... Φ 0 Φ 1 ... Φ N ] from j =1to j = T .Finally,letΣ be a diagonal matrix with (σ 2 ε ,σ 2 ∆a ,σ 2 g ,σ 2 ν ,σ 2 γ ) in the diagonal and I N be an identity matrix of size N . 
The log-likelihood function is: L = −2.5T ln(2π) − 0.5ln ¯ ¯ Ω(I N ⊗ Σ)Ω 0 ¯ ¯ − 0.5X 0 ¡ Ω (I N ⊗ Σ) Ω 0 ¢ −1 X (7) The main diﬃculty with evaluating this expression is that inverting the large 5T ×5T matrix Ω (I N ⊗ Σ) Ω 0 is both slow and subject to potentially large numerical errors. 
The appendix shows how to evaluate (7) w ithout inverting this matrix by instead solving a recursiv e linear system of equations. 
This provides an algorithm to evaluate the log-likelihood function quickly and reliably. 
Turningtoestimation,wesetthevalueof 9 out of the 20 parameters. 
Namely, we set the intertemporal elasticity of substitution to 1 (the King-Plosser-Rebelo, 1988, utility function) to guarantee that hours are stationary, the Frisch elasticity of labor supply to 4, and the labor share to 2/3. 
Using the production function, we can then measure the aggregate productivity shocks exactly, and estimate that ρ ∆a = .350 and σ ∆a = .010.We set φ y =0.33 and φ p =1.24 to match Rudebusch’s (2002) estimates of the Taylor rule, and using these we estimate that ρ ε = .918 and σ ε = .012. 
We start our estimation of the model by finding the set of parameters that maximize 6 See An and Schorfheide (forthcoming) and Canova (forthcoming) for recent surveys on the estimation of dynamic stochastic general equilibrium models. 
the likelihood function. 
Table 1 present s the estimates. 
Curiously, we estimate a value for the elasticity of substitution between goods that is higher and a value for the elasticity of substitution between labor that is lower than what is typically assumed. 
The implied price markup is only 3% and the implied wage markup is 31%, whereas usually these are calibrated to values between 5% and 20%. 
A second feature to note is that most estimates are quite precise, with t ight confidence intervals. 
Our main focus of interest are the measures of information stickine ss. We estimate that firms are relatively attentive, updating their information about every 4 months, whereas consumers and workers are quite inattentiv e, only updating their plans about every 16 months. 
We test the null hypothesis that both members of a household, the c onsumer and the worker, update their information at the same time. 
The likelihood ratio statistic is .089, which has a p-value of .23 in the χ 2 1 distribution. 
The data do not reject this plausible hypothesis. 
7 Table 2 presents the variance decompositions associated with these estimates. 
Noticeably, the variance of inflation, output, and hours is almost entirely accounted for s olely by monetary and aggregate demand shocks. 
Shocks to productivity and price markups are relatively unimportant for these three variables, but play a role on the fluctuations of interest rates and real wages. 
Wage markups are on average large, but their fluctuations explain little of the variance of any of the variables. 
Next we estimate our model using Bayesian methods instead. 
We see the main virtue of these methods as allowing us, through the priors, to focus on an area of the parameter space that we are particularly interested in. In our case, this area corresponds to the typical calibrations of these models. 
For instance, we pick priors for the average substitutability of goods and labor that imply average markups that are with 95% confidence between 6% and 21%, the values commonly assumed in the literature. 
For the parameters of inattentiveness, we instead opt for a flat prior in order to impose as little as possible on the data. 
The priors for the correlation and the variance of shocks are similar to those on the literature, although they are more diﬀuse than u sual. Table 1 contains the results, which turn out to be similar to the maximum-likelihood 7 With δ = ω, the wage curve can be re-written instead as: wt= δ ∞ [ j=0 (1 − δ) j Et−j  pt+ γ(w t − p t )+l t − ψγ t /(γ − 1) γ + ψ  + ψ (y t − g t ) θ(γ + ψ) . 
(8) results. 
As expected, the diﬀerence between the markups on goods and labor is not as extreme as before, as our prior heavily penalizes those extreme results. 
Also as expected, our diﬀuse priors lead t o wider credible sets. 
However, the estimates of inattentiveness are relatively similar: consumers and workers update their information every 5 to 6 quarters, whereas firms update every 1.5 quarters. 
Table 2 shows the variance decompositions using these Bayesian estimates. 
These are similar to the maximum-likelihood conclusions, with the exception of shocks to goods markups, which now account for a larger share of the variance of all variables. 
5. Conclusion In Mankiw and Reis (2002) we proposed a new way to model sluggish macroeconomic adjustment. 
In this paper we have explored how this a pproach can be used in an empirical dynamic stochastic general equilibrium model. 
One lesson from our estimation (and also emphasized in Mankiw and Reis, 2006) is that informationstickinessispervasive: itappliestofirms, workers, and consumers. 
Some recent research has estimated empirical dynamic stochastic general equilibrium models with sticky information on the part of firms, assuming fully informed workers and consumers. 
8 Our results suggest that these models were misspecified; this misspecification can potentially explain reported poor fits of the model. 
Although more work is needed before reaching a final verdict, we believe the assumption of sticky information remains a promising tool for applied macroeconomists. 
8 See Trabandt (2003) and Keen (2003) for early attempts to build DSGE models with sticky information on the part of firms, and Andres et al (2005), Korenok and Swanson (2005), Kiley (2005) and Laforte (2005) for estimations. 
Coibion (2006) finds that sticky information on the part of consumers is important to explains inflation dynamics. 
Appendix This appendix sets out the model in the paper formally, solves it, proves the propositions, and describes the algorithms tha t we used. 
A.1. 
The economic environmen t The model is similar to the one in Mankiw and Reis (2006), but allows for shocks to the elasticities of substitution between varieties of goods and labor. 
The reader is referred to that article for a more detailed exposition and a description of the intuition behind our assumptions and optimal behavior. 
Here, we are brief. 
There are three types of agents: consumers, workers and firms, of which there is a continuum evenly distributed in the unit interval. Consumers and workers share a household and strive to maximize the same utility function subject to the same budget constraint. 
Within consumers, there are two mem bers: a shopper, that decides the allocation of spending across the diﬀerent varieties and is always atten tive, and a planner that decides total expenditure and is often inattentive. 
Firms have two departments: a purchasing department that is always attentive and chooses how muc h of each variety of labor t o hire, and a sales department that is only sporadically attentiv e and sets the price of the firm’s output. 
These agen ts meet in three sets of markets. 
In the labor market, workers sell their labor to firms; in the goods market, firms sell t heir goods to consum ers; and in the savings market consumers trade bonds between themselves. 
Monetary and aggregate demand policy follow exogenous rules and close the model. 
To lay down the model formally, we start by describing the market clearing conditions and policy processes, then set out the attentive agents’ problem, and finally write down the inattentive agents’ problem. 
Policy and market c learing. 
We assume that the government consumes a common fraction of each good in the economy. 
This is financed by lump-sum taxes that keep the budget balanced at all dates. 
Therefore, the market clearing condition in the market for goods’ variety i is: G t Z 1 0 C t,j (i)dj = Y t,i , (9) where 1 − 1/G t is the fraction of output consumed by the government, C t,j (i) is the consumption of variety i by agent j at time t,andY t,i is the t otal production of good i at time t. The fraction G t is stochastic and shocks to it can be interpreted broadly as aggregate demand shocks. 
9 The market clearing condition in each labor variety i is: L t,i = Z 1 0 N t,j (i)dj, (10) where L t,i is the total labor supply of variety i at time t,andN t,j (i) is the labor demand by firm j of variety i at time t. Monetary policy sets interest rates according t o: i t ≡ log [E t (Π t+1 P t /P t+1 )] = φ y log µ Y t Y n t ¶ + φ p log µ P t P t−1 ¶ − ε t . 
(11) The definition of the nominal interest rate follows the Fisher relation, whereas policy is set according to a Taylor rule. 
The new notation is P t for the price level, Π t+1 for the gross real interest rate between t and t +1, Y n t for the equilibrium level of output if all are attentive, and ε t to discretionary policy shocks. 
Note that a positive ε t corresponds to an expansionary shock. 
The coeﬃcient φ y is positive reflecting a desire for stabilization, and φ p > 1 to respect the Taylor principle and lead to a determinate solution for inflation. 
This rule by itself leaves the price level indeterminate, but we peg the initial price level at P −1 =1ensuring determinacy. 
Finally, we define total output and total labor as the aggregators across all varieties: 10 Y t = µZ 1 0 Y ˆν t −1 ˆν t t,i di ¶ ˆν t ˆν t −1 , (12) L t = µZ 1 0 L ˆγ t −1 ˆγ t t,i di ¶ ˆγ t ˆγ t −1 . 
(13) A ttentive agents. 
Consumer’s shopper j at date t solv es: min {C t,j (i)} i∈[0,1] Z 1 0 P t,i C t,j (i)di s.t. 
C t,j = µZ 1 0 C t,j (i) ˆν t −1 ˆν t di ¶ ˆν t ˆν t −1 . 
(14) The price of each variety of goods is P t,i , and the c onsumer values them according to a Dixit-Stilitz utility function, with a stochastic elasticity of substitution ˆν t . 
The standard 9 Shocks to the utility of leisure relative to consumption enter the mo del in a similar way to Gt. 10 Note that using instead the definitions Y t = U 1 0 Y t,i di and L t = U 1 0 L t,i di leads to the same results up to a first-order approximation. 
solution to this problem is: C t,j (i)=C t,j (P t (i)/P t ) −ˆνt with P t = µZ 1 0 P t (i) 1−ˆν t di ¶ 1 1−ˆν t , (15) so that P t is the static price index. 
Summing over all consumers and using the market clearing condition gives the total demand for variety i: Y t,i =(P t (i)/P t ) −ˆνt ¯ C t G t , where ¯ C t ≡ Z 1 0 C t,j dj. (16) The purchasing department of firm j at date t minimizes expenditures given a DixitStiglitz production function that aggregates labor of diﬀerent varieties into a labor aggregate: min {N t,j (i)} i∈[0,1] Z 1 0 W t,i N t,j (i)di s.t. 
N t,j = µ Z 1 0 N t,j (i) ˆγ t −1 ˆγ t di ¶ ˆγ t ˆγ t −1 . 
(17) Wt,iis the wage paid to labor variety i and ˆγ t is the stochastic elasticity of substitution across labor varieties. 
The solution is: N t,j (i)=N t,j (W t (i)/W t ) −ˆγ t with W t = µZ 1 0 W t (i) 1−ˆγ t di ¶ 1 1−ˆγ t , (18) where W t is the static wage index. 
Summing over all firms and using the market clearing condition, we obtain t he demand for labor variety i: L t,i =(W t (i)/W t ) −ˆγ t¯ N t , where ¯ N t ≡ Z 1 0 N t,j dj. (19) Inattentive agents. 
We start by considering the problem facing the pricing department of a firm that last updated its information j periods ago. 
We assume that each period, a randomly drawn fraction of firms λ updates their information, so there are λ(1 − λ) j firms in this situation. 
They choose a nominal price to maximize expected re al profits: max P t,j E t−j ∙ P t,j Y t,j P t − W t N t,j P t ¸ (20) s.t.: Y t,j = A t N β t,j and (16) (21) The first constraint is the production function, where β measures the degree of returns to scale. 
We in terpret this model with no capital accumulation as one in which there is a fixed stock of capital, so β corresponds to the labor share. 
Aggregate productivity A t is stochastic. 
The second constraint is the demand for the firm’s product in (16). 
After some rearranging, the first-order condition of this optimization problem is: P t,j = E t−j [ˆν t W t N t,j /P t ] E t−j [β(ˆν t − 1)Y t,j /P t ] . 
(22) Next, consider the problem of an inattentive consumer’s planner. 
If she updates her plan at date t, she chooses a plan for current and future consumption to solve: V (A t )= max {C t+i,i } ( ∞ X i=0 ξ i (1 − δ) i C 1−1/θ t+i,i − 1 1 − 1/θ + ξδ ∞ X i=0 ξ i (1 − δ) i E t [V (A t+1+i )] ) , (23) s.t. : A t+1+i = Π t+1+i µ A t+i − C t+i,i + W t+1+i,. 
L t+1+i,. 
+ T t+1+i,. 
P t+1 ¶ for i=0,1,...(24) and a no-Ponzi scheme condition. 
V (.) is the value function of the agent that depends on her wealth A t . 
The parameter ξ isthediscountfactor,whileδ is the probability at each date that the consumer updates her plan. 
The coeﬃcient θ is the intertemporal elasticity of substitution so preferences are iso-elastic. 
Preferences are also additively separable in consumption and leisure, but since the consumer does not control labor supply, the term in leisure drops out of her problem. 
The budget constraint assumes that wages are received at the beginning of the period so they earn interest before the next period. 
Finally T t,. denote both lump-sum taxes as well as the payments from an insurance contract that all agents sign at the beginning of time that ensures that they all have the same wealth at the start of each period. 
This is a standard assumption in these models to avoid tracking the wealth distribution over time. 
The optimality conditions a re: ξ i (1 − δ) i C −1/θ t+i,i = ξδ ∞ X k=i ξ k (1 − δ) k E t £ V 0 (A t+1+k ) ¯ Π t+i , t+1+k ¤ for i=0,1,2,... (25) V 0 (A t )=ξδ ∞ X k=0 ξ k (1 − δ) k E t £ V 0 (A t+1+k ) ¯ Π t , t+1+k ¤ . 
(26) We denote by ¯ Π t+i , t+1+k = t+k Q z=t+i Π z+1 the compound return between t + i and t +1+k. 
Combining (25) for i =0with (26) one learns that C −1/θ t,0 = V 0 (A t ). Writing (26) recursively and using these results one gets the first condition below. 
Condition (25) for i = j and (26) for date t + j imply the second result: C −1/θ t,0 = ξE t h R t+1 C −1/θ t+1,0 i , (27) C −1/θ t+j,j = E t−j h C −1/θ t+j,0 i , (28) Finally, we turn to wo rkers. 
They solve a similar problem to consumers: ˆ V (A t )= max {W t+i,i } ( − ∞ X i=0 ξ i (1 − ω) i E t Ã L 1+1/ψ t+i,i +1 1+1/ψ ! 
+ ξω ∞ X i=0 ξ i (1 − ω) i E t h ˆ V (A t+1+i ) i ) ,(29) s.t. (24) and (19) (30) where ˆ V (.) is the value function perceived by the worker, ω is the probability eac h period that she will update her information, and ψ is the Frisch elasticity of labor supply in the isoelastic utility function. 
The worker faces as constraints the same b udget as the consumer, as well as the total demand for her services. 
The optimality conditions are: ξ i (1 − ω) i E t ³ ˆγ t+i L 1+1/ψ t+i,i ´ /W t+i,i = ξω ∞ X k=i ξ k (1 − ω) k E t £ V 0 (A t+1+k ) ¯ Π t+i , t+1+k ¡ ˆγ t+i − 1 ¢ L t+i,i /P t+i ¤ for i=0,1,2,... (31) ˆ V 0 (A t )=ξω ∞ X k=0 ξ k (1 − ω) k E t h ˆ V 0 (A t+1+k ) ¯ Π t , t+1+k i . 
(32) Combining (31) for i =0with (32) one learns that W t,0 = ˆγ t ˆγ t − 1 × P t L 1/ψ t,0 ˆ V 0 t (A t ) . 
(33) Writing (32) recursively and using these results one gets the first condition below. 
Condition (31) for i = j and (32) for date t + j imply the second result: ˆγ t ˆγ t − 1 × L 1/ψ t,0 P t W t,0 = ξE t Ã R t+1 × ˆγ t+1 ˆγ t+1 − 1 × L 1/ψ t+1,0 P t+1 W t+1,0 ! 
, (34) W t+i,i = E t ³ ˆγ t+i L 1/ψ t+i,i ´ E t ³ ˆγ t+i L t+i,i L 1/ψ−1 t+i,0 /W t+i,0 ´. (35) Monopolistically competitive equilibrium. 
A competitive equilibrium of this economy is an allocation of total expenditures, consum ption of varieties, labor supplied of the diﬀerent varieties, and output produced of each variety such that consumers, workers and firms all beha ve optimally, monetary policy follows the Taylor rule, and all markets clear. 
A.2. 
The log-linearized econom y and shocks We log-linearize the equilibrium conditions around the non-stochastic steady state. 
Small caps denote the log-deviations of the respective large-cap variable from this steady state, with the exceptions of: ν t and γ t which are the log-deviations of ˆν t and ˆγ t , r t whic h is the log-deviation of the short rate E t [Π t+1 ],andR t which is the log-deviation of the long rate lim k→∞ E t [ ¯ Π t , t+1+k ]. Log-linearizing t he market clearing conditions and policy rules, we get: y t = g t + c t , (36) i t = φ y (y t − y n t )+φ p ∆p t − ε t , (37) i t = r t + E t (∆p t+1 ) , (38) c t = δ ∞ X j=0 (1 − δ) j c t,j , (39) From the attentive agents’ section: y t,j = y t − ν (p t,j − p t ) , (40) p t = λ ∞ X j=0 (1 − λ) j p t,j , (41) l t,j = l t − γ(w t,j − w t ), (42) w t = ω ∞ X j=0 (1 − ω) j w t,j (43) From the inatten tive firm’s problem: y t,j = a t + βl t,j , (44) p t,j = E t−j [w t − (y t,j − n t,j ) − ν t /(¯ν − 1)] = E t−j ∙ p t + β(w t − p t )+(1− β)y t − a t − ν t β/(¯ν − 1) β +¯ν(1 − β) ¸ . 
(45) The second expression uses the two constraints in (21) to eliminate firm-specificvariables. 
From the inattentive consumer’s problem: c t,0 = E t (c t+1,0 − θr t ) , (46) c t,j = E t−j (c t,0 ) , (47) and from the inattentive worker’s problem: w t,0 − p t − l t,0 /ψ + γ t /(¯γ − 1) = E t [−r t + w t+1,0 − p t+1 − l t+1,0 /ψ + γ t+1 /(¯γ − 1)],(48) w t,j = E t−j (w t,0 ) . 
(49) There are five source of shocks in the model: monetary policy, aggregate productivity growth, aggregate demand, goods markups, and labor markups. 
We assume that each follows an independent AR(1): ε t = ρ ε ε t−1 + e ε t , ∆a t = ρ ∆a ∆a t−1 + e ∆a t , (50) g t = ρ g g t−1 + e g t ,ν t = ρ ν ν t−1 + e ν t ,γ t = ρ γ γ t−1 + e γ t , (51) where the shocks e s t ∼ N(0,σ 2 s ) are i.i.d. over time, E[e s t e s t+k ]=0for k 6=0, and independent of each other, E[e s t e s 0 t ]=0for s 6= s 0 . 
A.3. 
The attentive equilibrium The attentive equilibrium is the o ne that obtains when δ = ω = λ =1,soallare attentive. 
Following convention, we refer to variables in this equilibrium as being at their “natural” lev els and superscript them with n. Note however that this is not a Pareto optimal equilibrium since there is monopoly power. 
Moreov er, note t hat because the elasticities of substitution change, markups change as w ell, so the “natural” levels or output or labor are not a constant fraction of their Pareto optimal levels. 
If all are attentive, all are identical, so: y t,j = y t , l t,j = l t , p t,j = p t , w t,j = w t ,and c t,j = c t . 
The model then collapses into the system of 6 equations: y n t = g t + c n t , E t ¡ ∆p n t+1 ¢ = φ p ∆p n t − r n t − ε t , y n t = a t + βl n t , 0=β(w n t − p n t )+(1− β)y n t − a t − ν t β/(¯ν − 1), c n t = −θr t + E t ¡ c n t+1 ¢ , z t = −r n t + E t (z t+1 ) , with z t ≡ w n t − p n t − l n t /ψ + γ t /(¯γ − 1), in 6 variables (y n t ,c n t ,l n t ,p n t ,r n t ,w n t ). The solution for output is: y n t = Ξ a a t + Ξ g g t + Ξ γ γ t + Ξ ν ν t , where: Ξ a ≡ (1 + 1/ψ)/ (1 + 1/ψ + β/θ − β) , Ξ g ≡ (β/θ)/ (1 + 1/ψ + β/θ − β) , Ξ γ ≡ (β/(γ − 1))/ (1 + 1/ψ + β/θ − β) , Ξ ν ≡ (β/(ν − 1))/ (1 + 1/ψ + β/θ − β) . 
Using the solution for output, the solution for the other real variables follows: l n t =(y n t − a t )/β, w n t − p n t = y n t − l n t − ν t β/(¯ν − 1), c n t = y n t − g t , and θr n t = E t ¡ y n t+1 − y n t − g t+1 + g t ¢ . 
Note that for hours to remain bounded, E(l n t )=0, requires the King-Plosser-Rebelo (1988) restriction, θ =1. In this case, output and real wages increase proportionally with aggregate productivity and labor is independent of productivity shocks. 
T his economy respects the classical dichotomy as real variables are determined independently of monetary shocks. 
Finally, the solution for inflationintheθ =1case is: ∆p n t = ρ a ∆a t φ p − ρ a + (1 − β/(1 + 1/ψ))(1 − ρ g )g t φ p − ρ g − (1 − ρ γ )γ t (¯γ − 1)(1 + 1/ψ)(φ p − ρ γ ) − (1 − ρ ν )ν t (¯ν − 1)(1 + 1/ψ)(φ p − ρ ν ) + ε t φ p − ρ ε . 
(52) Expansionary monetary policy, h igher productivity growth, higher government spending, and higher markups all raise inflation. 
Nominal interest rates are i n t = r n t + E t ¡ ∆p n t+1 ¢ , and the equilibrium is fully characterized. 
A.4. 
The sticky-information equilibrium Starting with (41), replace y t,j using (40) and p t,j using (45) and rearrange to get the AS curve in (1). 
Denoting by mc t (real marginal c osts) the fraction on the right-hand side, it can be r e-arranged to obtain a sticky-information Phillips curve: ∆p t = λmc t 1 − λ + λ ∞ X j=0 (1 − λ) j E t−1−j (∆p t + ∆mc t ) . 
(53) Next, starting with (46), iterate forward and take the limit as time goes to infinity. 
Then, use the definition of the long rate R t and the fact that complete insurance plus the fact that eventually all become aware of shocks implies that lim i→∞ E t (c t+i,0 )=lim i→∞ E t £ y n t+i ¤ ≡ y ∞ t . 
Then, using this solution to replace for c t,0 in (47) and (39) gives an expression for aggregate consumption. 
Replacing it in (36) and using the fact that g t is stationary giv es the IS curve in (2). 
Very similar steps, using the expressions for w t,0 in (48), for w t,j in (49), the aggregator for w t in (43) and replacing out l t,j using (42), gives the wage curve in (3). 
Aggregating (44) over j gives the aggregate production function in (4). 
Finally, the expressions for the nominal interest rate in (37) and (38) give the Taylor rule in (5). 
These 5 equations together with the initial condition p −1 =0define an equilibrium in the 5 variables (y t ,p t ,w t ,l t ,i t ) as function of the five stochastic variables ( ε t , ∆a t ,g t ,ν t ,γ t ) A.5. 
ProofofProposition1 Using a method of undetermined coeﬃcients, the solution for the generic variable z t ∈ Z t = {y t ,p t ,w t ,l t ,i t } as a function of the innovations e s t−n for all non-negative n and s ∈ S = {∆a, g, ν, γ, ε} is: z t = X s∈S ∞ X n=0 ˆz n (s)e s t−n , (54) where ˆz n (s) is the undetermined coeﬃcient measuring the impact of shock s at lag n on variable z.Define the follo wing auxiliary parameters that will be useful: Λ n = λ n X i=0 (1 − λ) i , ∆ n = δ n X i=0 (1 − δ) i , and Ω n = ω n X i=0 (1 − ω) i ; (55) Ψ n = θ∆ n n [ψ + γ(1 − Ω n )] h β+ν(1−β) Λ n − ν(1 − β) i − βψΩ n o (1 − β)(γ + ψ)θ∆ n + Ω n {θ∆ n [1 − γ(1 − β)] + ψβ} ≡ Ψ num n Ψ den n . 
(56) Focus first on the impact of monetary policy shocks. 
The AS in (1) implies that ∙ β + ν(1 − β) Λn − ν(1 − β) ¸ ˆp n (ε)=(1− β)ˆy n + β ˆw n (57) for all n. The IS in equation (2) implies that: ˆy n = −∆ n θ ∞ X i=0 ˆr n+i , (58) for all n. The wage curve in (3) in turn implies that: (γ + ψ − Ω n γ)ˆw n = Ω n ψˆp n + Ω n Ã ˆy n /β − ψ ∞ X i=0 ˆr n+i ! 
. 
(59) for all n. Using these three equations to substitute out P ∞ i=0 ˆr n+i and ˆw n and firstdiﬀerencing (58) gives the two equations: ˆy n = Ψ n ˆp n , (60) θˆr n = ˆy n+1 ∆ n+1 − ˆy n ∆ n . 
(61) where we used t he definition of the parameter Ψ n . 
Finally, using the Taylor rule: (5): φ p ˆp n = φ y ˆy n+1 +(1+φ p )ˆp n+1 − ˆp n+2 − ˆr n+1 − ρ n+1 e , (62) and replacing for ˆy n and ˆr n gives the solution in the p roposition with: A n =1+ Ψ n θ∆ n ,B n = A n + φ y Ψ n + φ p ,C n (ε)=ρ e (63) You can go through the exact same steps for the other four shocks. 
It should be evident though that the only change is that there is a new term on the right-hand side of (60) which we denote by Υ n (s), and that the term in ρ e no longer appears on the righ t-hand side of (62). 
The solution will therefore have the same form, but now: C n (s)= ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ 1 1−ρ a h (1 − ρ n+1 a ) ³ φ y Υ n (a) − φ y Ξ a + Υ n (a) θ∆ n ´ − (1−ρ n+2 a )Υ n+1 (a) θ∆ n+1 i for s = a h (1−Υ n+1 (g))ρ g θ∆ n+1 − 1−Υ n (g) θ∆ n + φ y (Υ n (g) − Ξ g ) i ρ n g for s = g h³ φ y + 1 θ∆ n ´ Υ n (γ) − φ y Ξ γ − Υ n+1 (γ)ρ γ θ∆ n+1 i ρ n γ for s = γ h³ φ y + 1 θ∆ n ´ Υ n (ν) − φ y Ξ ν − Υ n+1 (ν)ρ ν θ∆ n+1 i ρ n ν for s = ν , (64) and Υ n (s)= ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ θ∆ n [γ + ψ + Ω n (1 − γ)] /Ψ den n for s = a βψΩ n /Ψ den n for s = g βθψΩ n ∆ n /Ψ den n (γ − 1) for s = γ βθ∆ n [ψ + γ(1 − Ω n )] /Ψ den n (ν − 1) for s = ν . 
(65) Finally, turning to the boundary conditions, the first follows from the initial condition that ensures the determinacy of the price level. 
The second condition follows from the fact that as the time after a shocks goes to infinity, all become aware of the shock, inflation approaches its natural level, and this in turn tends to zero since ∆p n t is stationary. 
This concludes the proof. 
A.6. 
Algorithm to solve for the sticky-information equilibrium In principle, solving the second-order diﬀerence equation should be easy. 
In practice, we found that shooting algorithms (including multiple shooting alternatives) or the extended path method were often unreliable. 
Small numerical imprecisions are compounded by both of these algorithms leading them to quickly diverge awa y from the solution. 
As an alternative we found that solving the system of linear equations implied by the diﬀerence equation and the boundary conditions: ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ −B 0 A 1 ... 000 φ p −B 1 ... 000 ... ... ... ... ... ... 00... −B N−2 A N−1 0 00... φ p −B N−1 A N 00... 01−1 ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ˆp 0 (s) ˆp 1 (s) ... ˆp N−2 (s) ˆp N−1 (s) ˆp N (s) ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ = ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ C 0 (s) C 1 (s) ... C N−2 (s) C N−1 (s) 0 ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ (66) was fast and reliable even for a very large N. Because the matrix of coeﬃcients is sparse and recursive, this system poses no diﬃculties to most equation-solving programs. 
Note that A n and B n are bounded and non-zero: tedious algebra shows that Ψ n > 0 for all finite n and lim n→∞ Ψ n =0and that as long as all parameters are finite, so is Ψ n . 
Therefore, A n 6=0, B n 6=0, lim n→∞ A n =1,andlim n→∞ B n =1+φ p . 
The system of equations is therefore well-behav ed. We have found that setting N = 1000, Matlab can find the solution in less than 5 seconds, and that the ignored terms ˆz n (s),forn>1000, are typically lower than 10 −15 . 
With a solution for prices, after tedious algebra, we can find: Corollary 1. The coeﬃcients for output, real interest rates, nominal interest rates, real wages and labor are: ˆy n (s)=Ψ n ˆp n (s)+ ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ Υ a n( 1−ρ n+1 a ) 1−ρ a for s = a Υ s n ρ n j for s = g, γ, ν 0 for s = ε (67) ˆr n (s)= ˆy n+1 (s) θ∆ n+1 − ˆy n θ∆ n + ⎧ ⎨ ⎩ g n θ∆ n − g n+1 θ∆ n+1 for s = g 0 for s = a, γ, ν, ε (68) ˆı n (s)=ˆr n (s)+ˆp n+1 (s) − ˆp n (s) (69) (ˆw n − ˆp n )(s)=[1+ν(1/β − 1)] (1/Λ n − 1) ˆp n (s)+(1− 1/β)ˆy n (s)+ ⎧ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎩ 1−ρ n+1 a β(1−ρ a ) for s = a ρ n ν ν−1 for s = ν 0 for s = g, γ, ε (70) ˆ l n (s)= ˆy n (s) β − ⎧ ⎨ ⎩ 1−ρ n+1 a β(1−ρ a ) for s = a 0 for s = g, γ, ν, ε (71) A.7. 
ProofofProposition2 From the properties of the exogenous shocks: e t v N(0 5 , Σ) and E(e t e 0 t−j )=0for any j 6=0. 
The properties of the normal distribution then imply that X v N(0 5T , Ω(I N ⊗Σ)Ω 0 ). The likelihood function follows from the density of the multivariate normal. A.8. 
Two algorithms to evaluate the log-likelihood function. 
The formula for the log-likelihood function in proposition 2 involves inverting a 5T ×5T matrix V = Ω (I 5 ⊗ Σ) Ω 0 , which is both slow and subject to potentially large numerical errors. 
There are two approaches to g etting around this problem. 
The first approach is common in the estimation of ARMA models. 
A Choleski decomposition gives V = LL 0 ,whereL is a lower triangular matrix. 
Defining L ˜ X = X,we can construct the ˜ X vector easily since this is a recursive system of equations. 
Moreover, ln |V | = |LL 0 | = |L| 2 =2 P 5T j=1 ln(l j ), where l j is the j th element in the diagonal of L.The first equality uses the Choleski decomposition, the second the properties that the determinant of the product of t wo square matrices is equal to the product of the determinants and that the determinant of a matrix is equal to the determinant of its transpose, and the third equality uses the fact that for triangular matrices the determinant equals the product of the elements in the diagonal and the properties of logarithms. 
The log-likelihood function then becomes: L = −2.5T ln(2π) − 5T X j=1 ln(l j ) − 0.5 ˜ X 0 ˜ X. (72) We have found that this algorithm takes less than 5 seconds to execute. 
There is an alternative algorithm that is sometimes faster but only applicable if we have alongdataseries. 
IfT is large, then se tting N = T leads to a negligible error in the solution of the model. 
In this case, defining Ω ˆ X = X,thenX 0 (Ω (I 5 ⊗ Σ) Ω 0 ) −1 X= ˆ X 0 ¡ I 5 ⊗ Σ −1 ¢ ˆ X. Because Σ is diagonal with σ 2 k as its k th element, th is expression equals P 5 k=1 P T j=1 ˆx 2 5(j−1)+k /σ 2 k . 
Moreover, ln |V | =2ln|Ω| +ln(I 5 ⊗ Σ)=2ln|Ω| + T P 5 k=1 ln(σ 2 k ). Therefore, the loglikelihood function becomes: L = −2.5T ln(2π) − ln |Ω| − 0.5T 5 X k=1 ln(σ 2 k ) − 0.5 5 X k=1 T X j=1 ˆx 2 5(j−1)+k /σ 2 k . 
(73) One diﬃculty with applying this algorithm is that it requires solving the linear system of 5T equations Ω ˆ X = X. While in principle this could be diﬃcult and numerically imprecise, we have typically found that Matlab is able to do it well. 
A.9. 
Estimation The goal is to estimate the vector of pa rameters θ =(ν, γ, ρ g ,σ g ,ρ ν ,σ ν ,ρ γ ,σ γ ,δ,ω, λ). The parameter space is (1, +∞) for ν and γ, (−1, 1) for ρ g ,ρ ν , and ρ γ , (0 , +∞) for σ g , σ ν , and σ γ and (0, 1] for δ, ω, and λ. Maximum likelihood estimates come from m a ximizing L with respect to these parameters. 
We tried several algorithms (Matlab’s simplex-search algorithm, fminsearch, Matlab’s modified Newton-Raphson algorithm, fmincon, and Chris Sims’s alternative modified Newton-Raphson algorithm, csminwel), and we started them from several points. 
While there were several local maxima, especially close to the boundaries of the parameter space, the clear global maximum found b y all the algorithms is reported in table 1. For an estimate of the variance-covariance matrix of the estimates, we use the inverse of the Hessian: − ¡ ∂ 2 L/∂θ∂θ 0 ¢ −1 . 
Bay esian estimates come from postulating a prior density for the parameters f(θ),and computing their posterior density using Bayes law: f(θ |X ) ∝ exp (L) f(θ). 
The priors we use are described in the notes of table 1. There is no closed-form solution for the posterior, which must be simulated numerically using Markov Chain Monte Carlo methods. 
We developed two ways to do so. The first uses the Gibbs sampler and exploits the fact that conditional on the remaining parameters, the posterior for (σ 2 g ,σ 2 ν ,σ 2 γ ) is kno wn. Since the prior for each of these parameters is an independent inverse-gamma distribution with parameter (τ k,1 ,τ k,2 ), the density of the prior is proportional to: 5 Y k=3 ¡ σ 2 k ¢ −0.5τ k,1 +1 exp(−0.5τ k,2 /σ 2 k ). (74) Multiplying by the lik elihood in (73) shows that the posterior for (σ 2 g ,σ 2 ν ,σ 2 γ ) conditional on the other parameters is proportional to: 5 Y k=3 ¡ σ 2 k ¢ −0.5(τ k,1 +T )+1 exp " −0.5 Ã τ k,2 τ k,1 + P T j=1 ˆy 2 5(j−1)+k ) τ k,1 + T ! 
/σ 2 s # . 
(75) Therefore, the posterior is also proportional to the product of three independent inversegamma distributions, with parameters ³ τ k,1 + T, ³ τ k,2 τ k,1 + P T j=1 ˆx 2 5(j−1)+k ) ´ /(τ k,1 + T ) ´ . 
The density of the other parameters conditional on the variance does not have a known density, so it must be simulated using a Metropolis algorithm. 
The Gibbs sampler therefore alternatively draws variances from the product of inverse gamma densities conditional on the other parameters, and then uses a Metropolis step to draw these other parameters conditional on the variances. 
The second approach is to use a Metropolis random-walk algorithm for all 11 parameters. 
The proposal function is a multivariate normal with mean equal to the last draw and variance covariance matrix proportional to its maximum-lik elihood estimate. 
A n atural starting point is the vector of maximum-likelihoods estimates. 
One would expect that the first approach dominates the second. 
The pure Metropolis algorithm must learn the shape of all of the distributions, whereas the Gibbs algorithm exploits the knowledge that the density of t h e variances conditional on the o ther parameters is a product of inverse gamma distributions. 
However, for our particular application, we found that the pure Metropolis algorithm converged faster than the Gibbs algorithm. 
The results in tables 1 and 2 were therefore generated using it. We started 5 Metropolis chains, oneatthemaximum-likelihoodvalueandtheother4atoverlydisperseddrawsfromthe multivariate normal. Multiplying the maximum-likelihood variance-covariance matrix by 0.75 led to an acceptance rate of 25% for the Metropolis algorithm. 
Each chain was ran for 50,000 draws and the first 30,000 were discarded. 
It took only about 3 days using in two parallel P entium 4, 3.2 Ghz computers to obtain these 250,000 draws–this confirms the speed of the algorithms behind propositions 1 and 2. We monitored the scale reduction factors proposed by Brooks and Gellman (1998). 
The largest of these factors wa s 1.010 supporting convergence, and plots of the between and within variances confirmed it. We therefore proceeded to mix the draws from the 5 samples to obtain 100,000 independent draws from the posterior density. 
References An, Sungbae, and Frank Schorfheide (forthcoming). 
“Bayesian Analysis of DSGE models.” Econometric Reviews, forthcoming. 
Brooks, Stephen P., and Andrew Gelman (1998) “General Methods for Monitoring Convergence of Iterative Simulations.” Journal of Computational and Graphic al Statistics,7 (4), 434 -455. 
Canova, Fabio (forthcoming). 
Applied Macroeconomic Research. 
Princeton University Press: Princeton. 
Coibion, Olivier (2006). 
“Inflation Inertia in Sticky Information Models.” Contributions to Macroeconomics, 6 (1), article 1. Gali, Jordi (1999). 
“Technology, Employment, and the Business Cycle: Do Technology Shocks Explain Aggregate Fluctuations?” American Economic Review, 89 (1), 249271. 
Kiley, Michael (2005). 
“A Quantitative Comparison of Sticky-Price and Sticky-Information Models of Price Setting.” Working paper, Federal Reserve Board. 
King, Robert G., Charles Plosser, and Sergio T. Rebelo (1988). 
“Production, Growth and Business Cycles I. The Basic Neoclassical Model.” Journal of Monetary Economics, 21, 195-232. 
Korenok, Oleg, and Norman R. Swanson (2005). 
“The Incremental Predictive Information Associated with Using Theoretical New Keynesian DSGE Models vs. Simple Linear Econometric Models.” Oxford Bulletin of Economics and Statistics, 67 ( 1), 905-930. 
Laforte, Jean-Philippe (2005). 
“Pricing Models: A Bayesian DSGE approach for the US Economy.” Working paper, Federal Reserve Board. 
Levin, Andrew T., Alexei Onatski, John C. Williams and Noah Williams (2006). 
“Monetary Policy Under Uncertain ty in Micro-Fo unded Macroeconometric Models.” In NBER Macroeconomics Annual 2005, edited by Mark Gertler and Kenneth Rogoﬀ,MIT Press: Cambridge. 
Mankiw, N. Gregory and Ricardo Reis (2002). 
“Sticky Information versus Sticky Prices: A Proposal to Replace the New Keynesian Phillips Curve.” Quarterly Journal of Economics, 117 (4), 1295-1328. 
Mankiw, N. Gregory and Ricardo Reis (2006) “P ervasive Stickiness.” American Economic Review, 96 (2), 164-169. 
Nelson, Edw ard, Javier Andrés and David López-Salido (2005). 
“Sticky-Price Models and the Natural Rate Hypothesis.” Journal of Monetary Economics, 52 (5), 1025-1053. 
Reis, Ricardo (2004). 
“Inattentive Consumers.” NBER Working Paper No. 10883. 
Reis, Ricardo (2006). 
“Inattentive Producers,” Review of Economic Studies, 73 (3), 793-821. 
Rudebusch, Glenn D. (2002). 
“Term Structure Evidence on Interest Rate Smoothing and Monetary Policy Inertia.” Journal of Monetary Economics, 4 9 (6), 1161-1187. 
Smets, Frank and Raf Wouters (2003). 
“An Estimated Stochastic Dynamic General Equilibrium Model of the Euro Area.” Journal of the European Economic Association,1 (5), 1123—1175. 
Wang, Pengfei and Yie Wen (2006). 
“Solving Linear Diﬀerence Systems with Lagged Expectations by a Meth od of Undetermined Coeﬃcients.” FRB Saint Louis Working Paper No. 2006-003c. 
Figure 1: Impulse responses to one-standard-deviation shocks 0 10 20 30 4000.0020.0040.0060.0080.01Inflation Monetary shock 0 10 20 30 4000.0050.010.015Output gap 0 10 20 30 4000.0050.010.0150.02Labor 0 10 20 30 40-4-202x 10-3 Technology shock 0 10 20 30 40-6-4-20x 10-3 0 10 20 30 40-8-6-4-20x 10-3 0 10 20 30 4000.51x 10-3 Aggregate demand shock0 10 20 30 400246x 10-3 0 10 20 30 4000.0050.010.0150.02 Table 1. Parameter estimates Maximum likelihood Prior Bayesian posterior Estimate Standard error 95% confidence interval Density Mean Standard error 95% coverage set Median Standard error 95% coverage set ν 34.068 1.000 [32.109 ; 36.027] 1+G 11 3.162 [5.795 ; 18.085] 20.547 2.781 [15.554 ; 26.408] γ 4.196 .626 [2.970 ; 5.422] 1+G 11 3.162 [5.795 ; 18.085] 6.884 1.438 [4.542 ; 10.245] ρg .938 .021 [.897 ; .979] B .7 .224 [.198 ; .991] .950 .022 [.904 ; .988] σg .014 .002 [.010 ; .018] IG1/2 .222 .114 [.107 ; .507] .015 .002 [.012 ; .019] ρν .630 .019 [.593 ; .666] B .7 .224 [.198 ; .991] .676 .023 [.628 ; .719] σν 1.819 .252 [1.325 ; 2.313] IG1/2 .222 .14 [.107 ; .507] 1.289 .242 [.887 ; 1.838] ργ .667 .035 [.599 ; .735] B .7 .224 [.198 ; .991] .638 .043 [.534 ; .701] σγ .187 .047 [.094 ; .279] IG1/2 .222 .114 [.107 ; .507] .347 .122 [.184 ; .674] δ .184 .026 [.133 ; .234] U .5 .289 [.025 ; .975] .176 .027 [.134 ; .242] ω .195 .011 [.173 ; . 
217] U .5 .289 [.025 ; .975] .210 .016 [.182 ; .244] λ .702 .015 [.673; .731] U .5 .289 [.025 ; .975] .657 .023 [.612 ; .703] Notes: Sample size is 206. 
The calibrated coefficients are β=2/3, ψ=4, θ=1, φy=.33, φπ=1.24, ρε=.918, σε=.012, ρΔa=.350, σΔa=.010. 
Maximum likelihood estimates come from using a modified Newton-Raphson search algorithm to maximize the log-likelihood, and the standard errors from inverting the Hessian at the optimum. 
The confidence intervals come from the cumulative density function of the multivariate normal. For the prior densities we used the gamma (G), the beta (B), the inverse gamma (IG) and the uniform (U) distributions, with parameters (10,1), (2.24,.96), (2.02,.06) and (0,1) respectively. 
The posterior moments are based on 100,000 draws from the posterior, which come from mixing 5 independent simulations of 50,000 draws, each with the first 30,000 draws discarded to ensure convergence. 
Table 2. Variance decompositions Maximum likelihood estimates and 95% confidence intervals Shock Variable Monetary Aggregate productivity Aggregate demand Goods markup Labor markup Inflation .896 [.826 ; .937] .028 [.019 ; .041] .004 [.002 ; .009] .070 [.033 ; .130] .003 [.001 ; .006] Output growth .247 [.171 ; .320] .153 [.115 ; .198] .436 [.257 ; .610] .101 [.040 ; .185] .064 [.024 ; .132] Hours .551 [.319 ; .663] .032 [.014 ; .067] .336 [.179 ; .612] .041 [.012 ; .084] .041 [.010 ; .116] Interest rate .506 [.352 ; .646] .066 [.048 ; .089] .017 [.008 ; .031] .295 [.163 ; .438] .117 [.053 ; .200] Wage growth .183 [.136 ; .244] .262 [.195 ; .360] .016 [.007 ; .033] .479 [.300 ; .605] .061 [.027 ; .099] Bayesian median estimates and 95% credible sets Shock Variable Monetary Aggregate productivity Aggregate demand Goods markup Labor markup Inflation .835 [.717 ; .906] .028 [.019 ; .040] .005 [.003 ; .010] .129 [.066 ; .242] .002 [.001 ; .004] Output growth .213 [.155 ; .274] .133 [.101 ; .164] .446 [.309 ; .590] .150 [.080 ; .263] .048 [.021 ; .107] Hours .469 [.237 ; .603] .028 [.010 ; .057] .398 [.238 ; .703] .063 [.023 ; .144] .025 [.006 ; .076] Interest rate .408 [.251 ; .569] .057 [.039 ; .077] .016 [.010 ; .027] .416 [.266 ; .585] .093 [.043 ; .188] Wage growth .093 [.053 ; .146] .192 [.125 ; .271] .035 [.008 ; .027] .663 [.514 ; .786] .035 [.017 ; .070] Notes: Maximum likelihood estimates come from using the MLE parameter estimates. 
The confidence intervals are the 2.5% and 97.5% percentiles from 1,000 draws taken from a multivariate normal distribution with mean and variance-covariance equal to their MLE estimates. 
Bayesian estimates are the median, 2.5% and 97.5% percentiles cell-by-cell using 100,000 draws from the posterior density. 