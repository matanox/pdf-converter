<!DOCTYPE html>
<!-- Created by pdf2htmlEX (https://github.com/coolwanglu/pdf2htmlex) -->
<html>
<head>
<meta charset="utf-8">
<meta name="generator" content="pdf2htmlEX">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<link rel="stylesheet" href="base.min.css"/>
<link rel="stylesheet" href="fancy.min.css"/>
<link rel="stylesheet" href="1310.4546.css"/>
<script src="compatibility.min.js"></script>
<script src="pdf2htmlEX.min.js"></script>
<script>
try{
  pdf2htmlEX.defaultViewer = new pdf2htmlEX.Viewer({});
}catch(e){}
</script>
<title></title>
</head>
<body>
<div id="sidebar">
<div id="outline">
<ul><li><a class="l" href="#pf1" data-dest-detail='[1,"XYZ",108.135,299.114,null]'>1 Introduction</a></li><li><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",108.135,220.701,null]'>2 The Skip-gram Model</a><ul><li><a class="l" href="#pf3" data-dest-detail='[3,"XYZ",108.135,607.707,null]'>2.1 Hierarchical Softmax</a></li><li><a class="l" href="#pf3" data-dest-detail='[3,"XYZ",108.135,236.119,null]'>2.2 Negative Sampling</a></li><li><a class="l" href="#pf4" data-dest-detail='[4,"XYZ",108.135,239.491,null]'>2.3 Subsampling of Frequent Words</a></li></ul></li><li><a class="l" href="#pf5" data-dest-detail='[5,"XYZ",108.135,467.744,null]'>3 Empirical Results</a></li><li><a class="l" href="#pf5" data-dest-detail='[5,"XYZ",108.135,179.025,null]'>4 Learning Phrases</a><ul><li><a class="l" href="#pf6" data-dest-detail='[6,"XYZ",108.135,337.538,null]'>4.1 Phrase Skip-Gram Results</a></li></ul></li><li><a class="l" href="#pf7" data-dest-detail='[7,"XYZ",108.135,397.04,null]'>5 Additive Compositionality</a></li><li><a class="l" href="#pf7" data-dest-detail='[7,"XYZ",108.135,184.325,null]'>6 Comparison to Published Word Representations</a></li><li><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",108.135,402.701,null]'>7 Conclusion</a></li></ul></div>
</div>
<div id="page-container">
<div id="pf1" class="pf w0 h0" data-page-no="1"><div class="pc pc1 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bg1.png"/><div class="t m0 x1 h1 y1 ff1 fs0 fc0 sc0 ls0 ws0">arXiv:1310.4546v1  [cs.CL]  16 Oct 2013</div><div class="t m1 x2 h2 y2 ff2 fs1 fc1 sc0 ls0 ws0">Distributed<span class="_ _0"> </span>Representations of<span class="_ _0"> </span>W<span class="_ _1"></span>ords and Phra<span class="_ _2"></span>ses</div><div class="t m1 x3 h2 y3 ff2 fs1 fc1 sc0 ls0 ws0">and their Composi<span class="_ _2"></span>tionality</div><div class="t m1 x4 h3 y4 ff2 fs2 fc1 sc0 ls0 ws0">T<span class="_ _3"></span>omas Mikolov</div><div class="t m1 x5 h4 y5 ff1 fs2 fc1 sc0 ls0 ws0">Google Inc.</div><div class="t m1 x4 h4 y6 ff1 fs2 fc1 sc0 ls0 ws0">Mountain V<span class="_ _4"></span>iew</div><div class="t m1 x6 h5 y7 ff3 fs2 fc1 sc0 ls0 ws0">mikolov@goog<span class="_ _2"></span>le.com</div><div class="t m1 x7 h3 y8 ff2 fs2 fc1 sc0 ls0 ws0">Ilya Sutske<span class="_ _5"></span>ver</div><div class="t m1 x8 h4 y9 ff1 fs2 fc1 sc0 ls0 ws0">Google Inc.</div><div class="t m1 x7 h4 ya ff1 fs2 fc1 sc0 ls0 ws0">Mountain V<span class="_ _4"></span>iew</div><div class="t m1 x9 h5 yb ff3 fs2 fc1 sc0 ls0 ws0">ilyasu@googl<span class="_ _2"></span>e.com</div><div class="t m1 xa h3 yc ff2 fs2 fc1 sc0 ls0 ws0">Kai Chen</div><div class="t m1 xb h4 yd ff1 fs2 fc1 sc0 ls0 ws0">Google Inc.</div><div class="t m1 xc h4 ye ff1 fs2 fc1 sc0 ls0 ws0">Mountain V<span class="_ _4"></span>iew</div><div class="t m1 xd h5 yf ff3 fs2 fc1 sc0 ls0 ws0">kai@google.c<span class="_ _2"></span>om</div><div class="t m1 xe h3 y10 ff2 fs2 fc1 sc0 ls0 ws0">Greg Corrado</div><div class="t m1 xf h4 y11 ff1 fs2 fc1 sc0 ls0 ws0">Google Inc.</div><div class="t m1 xe h4 y12 ff1 fs2 fc1 sc0 ls0 ws0">Mountain V<span class="_ _4"></span>iew</div><div class="t m1 x10 h5 y13 ff3 fs2 fc1 sc0 ls0 ws0">gcorrado@goo<span class="_ _2"></span>gle.com</div><div class="t m1 x11 h3 y14 ff2 fs2 fc1 sc0 ls0 ws0">Jeffrey<span class="_ _6"> </span>Dean</div><div class="t m1 x12 h4 y15 ff1 fs2 fc1 sc0 ls0 ws0">Google Inc.</div><div class="t m1 x13 h4 y16 ff1 fs2 fc1 sc0 ls0 ws0">Mountain V<span class="_ _4"></span>iew</div><div class="t m1 x14 h5 y17 ff3 fs2 fc1 sc0 ls0 ws0">jeff@google.<span class="_ _2"></span>com</div><div class="t m1 x15 h6 y18 ff2 fs3 fc1 sc0 ls0 ws0">Abstract</div><div class="t m1 x16 h4 y19 ff1 fs2 fc1 sc0 ls0 ws0">The<span class="_ _7"> </span>recently<span class="_ _7"> </span>introduce<span class="_ _2"></span>d<span class="_ _7"> </span>c<span class="_ _5"></span>ontinuo<span class="_ _2"></span>us<span class="_ _7"> </span>S<span class="_ _4"></span>k<span class="_ _2"></span>ip-gram<span class="_ _7"> </span>model<span class="_ _7"> </span>is<span class="_ _7"> </span>an<span class="_ _7"> </span>efﬁcient<span class="_ _7"> </span>method<span class="_ _7"> </span>for</div><div class="t m1 x16 h4 y1a ff1 fs2 fc1 sc0 ls0 ws0">learning<span class="_ _7"> </span>h<span class="_ _4"></span>igh-<span class="_ _2"></span>quality d<span class="_ _2"></span>istributed vector<span class="_ _7"> </span>r<span class="_ _4"></span>epr<span class="_ _2"></span>esentations that<span class="_ _7"> </span>capture a<span class="_ _7"> </span>l<span class="_ _4"></span>arge<span class="_ _7"> </span>n<span class="_ _4"></span>u<span class="_ _2"></span>m-</div><div class="t m1 x16 h4 y1b ff1 fs2 fc1 sc0 ls0 ws0">ber of precise syntactic and semantic word relationsh<span class="_ _2"></span>ips.<span class="_ _7"> </span>I<span class="_ _4"></span>n this pap<span class="_ _2"></span>er we present</div><div class="t m1 x16 h4 y1c ff1 fs2 fc1 sc0 ls0 ws0">se<span class="_ _5"></span>veral<span class="_ _7"> </span>extensions<span class="_ _7"> </span>that<span class="_ _0"> </span>i<span class="_ _5"></span>mprove<span class="_ _7"> </span>both<span class="_ _7"> </span>the<span class="_ _0"> </span>quality<span class="_ _7"> </span>of<span class="_ _7"> </span>the<span class="_ _0"> </span>v<span class="_ _4"></span>ecto<span class="_ _2"></span>rs<span class="_ _7"> </span>and<span class="_ _0"> </span>t<span class="_ _5"></span>he<span class="_ _7"> </span>tra<span class="_ _2"></span>ining</div><div class="t m1 x16 h4 y1d ff1 fs2 fc1 sc0 ls0 ws0">speed.<span class="_ _8"> </span>By<span class="_ _7"> </span>s<span class="_ _4"></span>ub<span class="_ _2"></span>sampling<span class="_ _7"> </span>o<span class="_ _4"></span>f<span class="_ _7"> </span>t<span class="_ _4"></span>h<span class="_ _2"></span>e<span class="_ _7"> </span>f<span class="_ _4"></span>req<span class="_ _2"></span>uent<span class="_ _9"> </span>words<span class="_ _9"> </span>we<span class="_ _7"> </span>obtain sign<span class="_ _2"></span>iﬁcant<span class="_ _9"> </span>speed<span class="_ _2"></span>up<span class="_ _9"> </span>and</div><div class="t m1 x16 h4 y1e ff1 fs2 fc1 sc0 ls0 ws0">also<span class="_ _9"> </span>learn<span class="_ _9"> </span>more<span class="_ _9"> </span>r<span class="_ _2"></span>egular word<span class="_ _9"> </span>repr<span class="_ _2"></span>esentations.<span class="_ _0"> </span>W<span class="_ _4"></span>e<span class="_ _9"> </span>also<span class="_ _9"> </span>describe<span class="_ _9"> </span>a<span class="_ _9"> </span>simple<span class="_ _7"> </span>alterna-</div><div class="t m1 x16 h4 y1f ff1 fs2 fc1 sc0 ls0 ws0">ti<span class="_ _5"></span>ve to the hierarchical softmax called negati<span class="_ _4"></span>ve sampling.</div><div class="t m1 x16 h4 y20 ff1 fs2 fc1 sc0 ls0 ws0">An in<span class="_ _2"></span>herent limitatio<span class="_ _2"></span>n of<span class="_ _9"> </span>word rep<span class="_ _2"></span>resentations is<span class="_ _9"> </span>their in<span class="_ _2"></span>difference to word<span class="_ _9"> </span>order</div><div class="t m1 x16 h4 y21 ff1 fs2 fc1 sc0 ls0 ws0">and<span class="_ _9"> </span>th<span class="_ _2"></span>eir<span class="_ _7"> </span>i<span class="_ _4"></span>n<span class="_ _2"></span>ability<span class="_ _7"> </span>to<span class="_ _9"> </span>represen<span class="_ _2"></span>t<span class="_ _9"> </span>idiomatic<span class="_ _7"> </span>phrases.<span class="_ _8"> </span>For<span class="_ _7"> </span>e<span class="_ _4"></span>x<span class="_ _2"></span>ample,<span class="_ _9"> </span>th<span class="_ _2"></span>e<span class="_ _9"> </span>m<span class="_ _2"></span>eanings<span class="_ _7"> </span>of</div><div class="t m1 x16 h4 y22 ff1 fs2 fc1 sc0 ls0 ws0">“Canada”<span class="_ _6"> </span>and<span class="_ _6"> </span>“<span class="_ _3"></span>Air” cannot<span class="_ _6"> </span>be<span class="_ _6"> </span>easily<span class="_ _6"> </span>c<span class="_ _5"></span>ombin<span class="_ _2"></span>ed<span class="_ _6"> </span>to<span class="_ _6"> </span>obtain<span class="_ _6"> </span>“<span class="_ _1"></span>Air Canada”.<span class="_ _9"> </span>Motiv<span class="_ _5"></span>ated</div><div class="t m1 x16 h4 y23 ff1 fs2 fc1 sc0 ls0 ws0">by this<span class="_ _6"> </span>example,<span class="_ _6"> </span>we present<span class="_ _6"> </span>a simple<span class="_ _6"> </span>method for<span class="_ _6"> </span>ﬁnding phrases<span class="_ _6"> </span>in te<span class="_ _4"></span>x<span class="_ _2"></span>t, and<span class="_ _6"> </span>show</div><div class="t m1 x16 h4 y24 ff1 fs2 fc1 sc0 ls0 ws0">that learning good vector representations for millions of phrases is possible.</div><div class="t m1 x0 h6 y25 ff2 fs3 fc1 sc0 ls0 ws0">1<span class="_ _a"> </span>Intr<span class="_ _4"></span>o<span class="_ _2"></span>duction</div><div class="t m1 x0 h4 y26 ff1 fs2 fc1 sc0 ls0 ws0">Distributed<span class="_ _7"> </span>represen<span class="_ _2"></span>tations<span class="_ _7"> </span>of<span class="_ _7"> </span>word<span class="_ _2"></span>s<span class="_ _7"> </span>in<span class="_ _0"> </span>a<span class="_ _7"> </span>vector<span class="_ _7"> </span>space<span class="_ _0"> </span>help<span class="_ _7"> </span>learning<span class="_ _7"> </span>alg<span class="_ _2"></span>orithms<span class="_ _7"> </span>to<span class="_ _0"> </span>achiev<span class="_ _4"></span>e<span class="_ _0"> </span>better</div><div class="t m1 x0 h4 y27 ff1 fs2 fc1 sc0 ls0 ws0">perfor<span class="_ _2"></span>mance<span class="_ _6"> </span>in<span class="_ _6"> </span>natural<span class="_ _6"> </span>language<span class="_ _6"> </span>processing tasks<span class="_ _6"> </span>by<span class="_ _6"> </span>group<span class="_ _2"></span>ing<span class="_ _6"> </span>s<span class="_ _5"></span>imilar words.<span class="_ _9"> </span>One of<span class="_ _6"> </span>the<span class="_ _6"> </span>earliest<span class="_ _6"> </span>use</div><div class="t m1 x0 h4 y28 ff1 fs2 fc1 sc0 ls0 ws0">of word repre<span class="_ _2"></span>sentations dates back to 198<span class="_ _2"></span>6 due to Rumelhart, Hinton<span class="_ _2"></span>, and W<span class="_ _4"></span>illiams<span class="_ _9"> </span>[13].<span class="_ _7"> </span>This idea</div><div class="t m1 x0 h4 y29 ff1 fs2 fc1 sc0 ls0 ws0">has<span class="_ _9"> </span>sin<span class="_ _2"></span>ce<span class="_ _7"> </span>been<span class="_ _9"> </span>applied<span class="_ _7"> </span>t<span class="_ _5"></span>o<span class="_ _7"> </span>s<span class="_ _5"></span>tatistical<span class="_ _7"> </span>language<span class="_ _9"> </span>mod<span class="_ _2"></span>eling<span class="_ _9"> </span>with<span class="_ _7"> </span>considerable<span class="_ _9"> </span>success<span class="_ _7"> </span>[1].<span class="_ _b"> </span>The<span class="_ _9"> </span>fo<span class="_ _2"></span>llow</div><div class="t m1 x0 h4 y2a ff1 fs2 fc1 sc0 ls0 ws0">up work includ<span class="_ _2"></span>es applications to autom<span class="_ _2"></span>atic speech recognitio<span class="_ _2"></span>n and machine translation [14, 7<span class="_ _2"></span>], and</div><div class="t m1 x0 h4 y2b ff1 fs2 fc1 sc0 ls0 ws0">a wide range of NLP tasks [2, 20, 15, 3, 18, 19, 9].</div><div class="t m1 x0 h4 y2c ff1 fs2 fc1 sc0 ls0 ws0">Recently<span class="_ _4"></span>, Mikolov<span class="_ _6"> </span>et al. [8] introdu<span class="_ _2"></span>ced the<span class="_ _6"> </span>Skip-g<span class="_ _2"></span>ram model, an ef<span class="_ _4"></span>ﬁcien<span class="_ _2"></span>t method for learning high-</div><div class="t m1 x0 h4 y2d ff1 fs2 fc1 sc0 ls0 ws0">quality<span class="_ _9"> </span>vector<span class="_ _9"> </span>rep<span class="_ _2"></span>resentations<span class="_ _9"> </span>of<span class="_ _9"> </span>words<span class="_ _9"> </span>fr<span class="_ _2"></span>om<span class="_ _9"> </span>large am<span class="_ _2"></span>ounts<span class="_ _9"> </span>of<span class="_ _9"> </span>un<span class="_ _2"></span>structured<span class="_ _9"> </span>text<span class="_ _9"> </span>data.<span class="_ _8"> </span>Unlike<span class="_ _9"> </span>most</div><div class="t m1 x0 h4 y2e ff1 fs2 fc1 sc0 ls0 ws0">of<span class="_ _9"> </span>the pr<span class="_ _2"></span>eviously used neur<span class="_ _2"></span>al ne<span class="_ _2"></span>twork architectu<span class="_ _2"></span>res for lea<span class="_ _2"></span>rning word<span class="_ _9"> </span>vectors, tra<span class="_ _2"></span>ining of<span class="_ _9"> </span>the<span class="_ _9"> </span>Skip-</div><div class="t m1 x0 h4 y2f ff1 fs2 fc1 sc0 ls0 ws0">gram<span class="_ _9"> </span>mod<span class="_ _2"></span>el<span class="_ _9"> </span>(see<span class="_ _9"> </span>Fig<span class="_ _2"></span>ure<span class="_ _9"> </span>1)<span class="_ _7"> </span>does n<span class="_ _2"></span>ot<span class="_ _9"> </span>inv<span class="_ _4"></span>o<span class="_ _2"></span>lve dense<span class="_ _7"> </span>matrix mu<span class="_ _2"></span>ltiplications.<span class="_ _8"> </span>This<span class="_ _9"> </span>makes<span class="_ _9"> </span>th<span class="_ _2"></span>e<span class="_ _9"> </span>training</div><div class="t m1 x0 h4 y30 ff1 fs2 fc1 sc0 ls0 ws0">extremely<span class="_ _6"> </span>efﬁcient: an optimized s<span class="_ _5"></span>ingle-mac<span class="_ _2"></span>hine<span class="_ _6"> </span>implementation<span class="_ _6"> </span>can<span class="_ _6"> </span>train on<span class="_ _6"> </span>more<span class="_ _6"> </span>than<span class="_ _6"> </span>100 billion</div><div class="t m1 x0 h4 y31 ff1 fs2 fc1 sc0 ls0 ws0">words in one day<span class="_ _4"></span>.</div><div class="t m1 x0 h4 y32 ff1 fs2 fc1 sc0 ls0 ws0">The<span class="_ _9"> </span>word representa<span class="_ _2"></span>tions comp<span class="_ _2"></span>uted using<span class="_ _9"> </span>neural n<span class="_ _2"></span>etworks are<span class="_ _9"> </span>very inte<span class="_ _2"></span>resting beca<span class="_ _2"></span>use the<span class="_ _9"> </span>learned</div><div class="t m1 x0 h4 y33 ff1 fs2 fc1 sc0 ls0 ws0">vectors e<span class="_ _5"></span>xplicitly encode many linguistic regularities<span class="_ _6"> </span>and patterns.<span class="_ _7"> </span>S<span class="_ _5"></span>omewhat s<span class="_ _5"></span>urprising<span class="_ _2"></span>ly<span class="_ _4"></span>,<span class="_ _6"> </span>many of</div><div class="t m1 x0 h4 y34 ff1 fs2 fc1 sc0 ls0 ws0">these p<span class="_ _2"></span>atterns ca<span class="_ _2"></span>n b<span class="_ _2"></span>e<span class="_ _9"> </span>represented as<span class="_ _9"> </span>linear<span class="_ _9"> </span>translation<span class="_ _2"></span>s.<span class="_ _0"> </span>F<span class="_ _4"></span>o<span class="_ _2"></span>r examp<span class="_ _2"></span>le, the<span class="_ _9"> </span>result o<span class="_ _2"></span>f a<span class="_ _9"> </span>vector<span class="_ _9"> </span>calcula-</div><div class="t m1 x0 h4 y35 ff1 fs2 fc1 sc0 ls0 ws0">tion vec(<span class="_ _2"></span>“Madrid”) - vec(<span class="_ _2"></span>“Spain”) +<span class="_ _9"> </span>vec(“France”) is clo<span class="_ _2"></span>ser to<span class="_ _9"> </span>vec(“Paris”) than to<span class="_ _9"> </span>any oth<span class="_ _2"></span>er word</div><div class="t m1 x0 h4 y36 ff1 fs2 fc1 sc0 ls0 ws0">vector [9, 8].</div><div class="t m1 x17 h4 y37 ff1 fs2 fc1 sc0 ls0 ws0">1</div><a class="l" href="http://arxiv.org/abs/1310.4546v1"><div class="d m2" style="border-width:1.000000px;border-style:dashed;border-color:rgb(0,255,255);position:absolute;left:13.200000px;bottom:253.500000px;width:21.660000px;height:338.520000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,372.07,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:446.584000px;bottom:225.904000px;width:10.952000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,701.862,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:442.624000px;bottom:215.104000px;width:5.912000px;height:7.712000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,348.101,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:459.664000px;bottom:204.064000px;width:10.952000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,516.128,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:474.664000px;bottom:203.944000px;width:6.032000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,676.206,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:217.744000px;bottom:193.144000px;width:5.912000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,184.168,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:227.704000px;bottom:193.024000px;width:10.952000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,334.129,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:242.584000px;bottom:193.024000px;width:10.952000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,642.119,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:257.584000px;bottom:193.024000px;width:5.912000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,232.107,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:267.544000px;bottom:193.024000px;width:10.952000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,208.138,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:282.424000px;bottom:192.904000px;width:11.072000px;height:8.072000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,468.069,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:297.424000px;bottom:192.904000px;width:6.032000px;height:8.072000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,492.159,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:208.024000px;bottom:176.104000px;width:5.912000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2" data-dest-detail='[2,"XYZ",149.57,546.672,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:205.744000px;bottom:143.344000px;width:6.032000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,468.069,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:137.104000px;bottom:60.423800px;width:5.912000px;height:7.952500px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,492.159,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:147.064000px;bottom:60.543800px;width:5.912000px;height:7.832500px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf2" class="pf w0 h0" data-page-no="2"><div class="pc pc2 w0 h0"><img class="bi x3 y38 w2 h7" alt="" src="bg2.png"/><div class="c x3 y39 w2 h8"><div class="t m1 x18 h9 y2e ff4 fs4 fc2 sc0 ls0 ws0"></div><div class="t m1 x19 h9 y3a ff4 fs4 fc2 sc0 ls0 ws0"></div><div class="t m1 x6 h9 y3b ff4 fs4 fc2 sc0 ls0 ws0"></div><div class="t m1 x6 h9 y3c ff4 fs4 fc2 sc0 ls0 ws0"></div><div class="t m1 x6 h9 y3d ff4 fs4 fc2 sc0 ls0 ws0"></div><div class="t m1 x6 h9 y3e ff4 fs4 fc2 sc0 ls0 ws0"></div></div><div class="t m1 x0 h4 y3f ff1 fs2 fc1 sc0 ls0 ws0">Figure<span class="_ _7"> </span>1:<span class="_ _8"> </span><span class="fs5">T<span class="_ _5"></span>he<span class="_ _9"> </span>Skip-gram<span class="_ _9"> </span>model<span class="_ _9"> </span>architecture.<span class="_ _8"> </span>T<span class="_ _2"></span>he<span class="_ _9"> </span>training<span class="_ _9"> </span>objectiv<span class="_ _4"></span>e<span class="_ _7"> </span>is<span class="_ _9"> </span>to<span class="_ _9"> </span>learn<span class="_ _9"> </span>wo<span class="_ _5"></span>rd<span class="_ _9"> </span>vector<span class="_ _9"> </span>representations</span></div><div class="t m1 x0 ha y40 ff1 fs5 fc1 sc0 ls0 ws0">that are good at predicting the nearby words.</div><div class="t m1 x0 h4 y41 ff1 fs2 fc1 sc0 ls0 ws0">In<span class="_ _7"> </span>this<span class="_ _7"> </span>p<span class="_ _2"></span>aper<span class="_ _7"> </span>we<span class="_ _7"> </span>presen<span class="_ _2"></span>t<span class="_ _7"> </span>sev<span class="_ _4"></span>e<span class="_ _2"></span>ral<span class="_ _7"> </span>extensions<span class="_ _7"> </span>of<span class="_ _7"> </span>the<span class="_ _7"> </span>origin<span class="_ _2"></span>al<span class="_ _7"> </span>Skip-gram<span class="_ _7"> </span>mod<span class="_ _2"></span>el.<span class="_ _c"> </span>W<span class="_ _3"></span>e<span class="_ _0"> </span>s<span class="_ _4"></span>h<span class="_ _2"></span>ow<span class="_ _7"> </span>that<span class="_ _7"> </span>sub-</div><div class="t m1 x0 h4 y42 ff1 fs2 fc1 sc0 ls0 ws0">sampling<span class="_ _9"> </span>of<span class="_ _7"> </span>frequent<span class="_ _9"> </span>words<span class="_ _9"> </span>dur<span class="_ _2"></span>ing<span class="_ _9"> </span>training<span class="_ _7"> </span>res<span class="_ _5"></span>ults<span class="_ _9"> </span>in<span class="_ _7"> </span>a<span class="_ _9"> </span>signiﬁcant<span class="_ _9"> </span>sp<span class="_ _2"></span>eedup<span class="_ _9"> </span>(ar<span class="_ _2"></span>ound<span class="_ _9"> </span>2x<span class="_ _7"> </span>- 10<span class="_ _2"></span>x),<span class="_ _9"> </span>a<span class="_ _2"></span>nd</div><div class="t m1 x0 h4 y43 ff1 fs2 fc1 sc0 ls0 ws0">improves accu<span class="_ _2"></span>racy<span class="_ _9"> </span>of<span class="_ _9"> </span>the<span class="_ _7"> </span>representations<span class="_ _9"> </span>of<span class="_ _9"> </span>less<span class="_ _7"> </span>frequent<span class="_ _9"> </span>words.<span class="_ _8"> </span>In<span class="_ _9"> </span>ad<span class="_ _2"></span>dition,<span class="_ _7"> </span>we pr<span class="_ _2"></span>esent<span class="_ _9"> </span>a<span class="_ _7"> </span>simpli-</div><div class="t m1 x0 h4 y44 ff1 fs2 fc1 sc0 ls0 ws0">ﬁed v<span class="_ _4"></span>ar<span class="_ _2"></span>iant<span class="_ _6"> </span>of Noise<span class="_ _6"> </span>Contrastiv<span class="_ _5"></span>e<span class="_ _6"> </span>Estimation (NCE)<span class="_ _6"> </span>[4] for<span class="_ _6"> </span>training the<span class="_ _6"> </span>Skip-gr<span class="_ _2"></span>am<span class="_ _6"> </span>model<span class="_ _6"> </span>that results</div><div class="t m1 x0 h4 y45 ff1 fs2 fc1 sc0 ls0 ws0">in<span class="_ _7"> </span>f<span class="_ _4"></span>aster<span class="_ _7"> </span>training<span class="_ _9"> </span>and<span class="_ _7"> </span>better<span class="_ _9"> </span>vector<span class="_ _9"> </span>rep<span class="_ _2"></span>resentations<span class="_ _9"> </span>for<span class="_ _7"> </span>frequent<span class="_ _9"> </span>words,<span class="_ _7"> </span>compared<span class="_ _9"> </span>to<span class="_ _7"> </span>more<span class="_ _9"> </span>comp<span class="_ _2"></span>lex</div><div class="t m1 x0 h4 y46 ff1 fs2 fc1 sc0 ls0 ws0">hierarchica<span class="_ _2"></span>l softmax t<span class="_ _5"></span>hat was used in the prior work [8].</div><div class="t m1 x0 h4 y47 ff1 fs2 fc1 sc0 ls0 ws0">W<span class="_ _3"></span>ord<span class="_ _9"> </span>r<span class="_ _2"></span>epresentation<span class="_ _2"></span>s are<span class="_ _9"> </span>limited<span class="_ _9"> </span>b<span class="_ _2"></span>y<span class="_ _9"> </span>their<span class="_ _9"> </span>inability<span class="_ _9"> </span>to<span class="_ _9"> </span>repr<span class="_ _2"></span>esent id<span class="_ _2"></span>iomatic<span class="_ _9"> </span>phrases<span class="_ _9"> </span>that<span class="_ _9"> </span>are<span class="_ _9"> </span>n<span class="_ _2"></span>ot co<span class="_ _2"></span>m-</div><div class="t m1 x0 h4 y48 ff1 fs2 fc1 sc0 ls0 ws0">positions<span class="_ _9"> </span>o<span class="_ _2"></span>f<span class="_ _9"> </span>the<span class="_ _7"> </span>indi<span class="_ _5"></span>vidual<span class="_ _9"> </span>words.<span class="_ _b"> </span>For<span class="_ _9"> </span>example,<span class="_ _9"> </span>“Bosto<span class="_ _2"></span>n<span class="_ _7"> </span>G<span class="_ _5"></span>lobe”<span class="_ _9"> </span>is<span class="_ _7"> </span>a<span class="_ _9"> </span>newspaper<span class="_ _4"></span>,<span class="_ _7"> </span>and<span class="_ _9"> </span>so<span class="_ _9"> </span>it<span class="_ _7"> </span>is<span class="_ _9"> </span>no<span class="_ _2"></span>t<span class="_ _9"> </span>a</div><div class="t m1 x0 h4 y49 ff1 fs2 fc1 sc0 ls0 ws0">natural<span class="_ _7"> </span>c<span class="_ _5"></span>ombinatio<span class="_ _2"></span>n o<span class="_ _2"></span>f<span class="_ _9"> </span>the<span class="_ _7"> </span>meanings<span class="_ _9"> </span>of<span class="_ _9"> </span>“<span class="_ _2"></span>Boston”<span class="_ _9"> </span>an<span class="_ _2"></span>d<span class="_ _9"> </span>“Glob<span class="_ _2"></span>e”.<span class="_ _8"> </span>Theref<span class="_ _2"></span>ore,<span class="_ _9"> </span>u<span class="_ _2"></span>sing<span class="_ _9"> </span>vectors<span class="_ _9"> </span>to<span class="_ _7"> </span>repre-</div><div class="t m1 x0 h4 y4a ff1 fs2 fc1 sc0 ls0 ws0">sent the<span class="_ _6"> </span>whole phrases<span class="_ _6"> </span>makes<span class="_ _6"> </span>the<span class="_ _6"> </span>Skip-gr<span class="_ _2"></span>am<span class="_ _6"> </span>model considerably<span class="_ _6"> </span>more<span class="_ _6"> </span>expressiv<span class="_ _5"></span>e.<span class="_ _9"> </span>Other techniques</div><div class="t m1 x0 h4 y4b ff1 fs2 fc1 sc0 ls0 ws0">that<span class="_ _7"> </span>aim<span class="_ _7"> </span>to<span class="_ _7"> </span>represent<span class="_ _9"> </span>mean<span class="_ _2"></span>ing<span class="_ _7"> </span>of<span class="_ _9"> </span>senten<span class="_ _2"></span>ces<span class="_ _7"> </span>by<span class="_ _7"> </span>composing<span class="_ _9"> </span>th<span class="_ _2"></span>e<span class="_ _7"> </span>w<span class="_ _4"></span>o<span class="_ _2"></span>rd<span class="_ _7"> </span>vectors,<span class="_ _7"> </span>such<span class="_ _7"> </span>a<span class="_ _5"></span>s<span class="_ _7"> </span>the<span class="_ _7"> </span>recursi<span class="_ _5"></span>ve</div><div class="t m1 x0 h4 y4c ff1 fs2 fc1 sc0 ls0 ws0">autoenco<span class="_ _2"></span>ders [15<span class="_ _4"></span>]<span class="_ _2"></span>, would also beneﬁt from using phrase vectors instead of the w<span class="_ _4"></span>o<span class="_ _2"></span>rd vectors.</div><div class="t m1 x0 h4 y4d ff1 fs2 fc1 sc0 ls0 ws0">The e<span class="_ _4"></span>x<span class="_ _2"></span>tension<span class="_ _6"> </span>from w<span class="_ _4"></span>o<span class="_ _2"></span>rd<span class="_ _6"> </span>based t<span class="_ _5"></span>o phrase<span class="_ _6"> </span>based<span class="_ _6"> </span>models is<span class="_ _6"> </span>relati<span class="_ _4"></span>vely simple.<span class="_ _9"> </span>First<span class="_ _6"> </span>we identify<span class="_ _6"> </span>a<span class="_ _6"> </span>large</div><div class="t m1 x0 h4 y4e ff1 fs2 fc1 sc0 ls0 ws0">number o<span class="_ _2"></span>f phrases<span class="_ _9"> </span>using a<span class="_ _9"> </span>data-dr<span class="_ _2"></span>iv<span class="_ _5"></span>en approach, and<span class="_ _9"> </span>then we<span class="_ _9"> </span>treat th<span class="_ _2"></span>e phrases<span class="_ _9"> </span>as individual tokens</div><div class="t m1 x0 h4 y4f ff1 fs2 fc1 sc0 ls0 ws0">during the training.<span class="_ _9"> </span>T<span class="_ _4"></span>o<span class="_ _6"> </span>ev<span class="_ _4"></span>aluate the quality of<span class="_ _6"> </span>the phrase vectors,<span class="_ _6"> </span>we de<span class="_ _4"></span>velop<span class="_ _2"></span>ed<span class="_ _6"> </span>a test set of<span class="_ _6"> </span>analogi-</div><div class="t m1 x0 h4 y50 ff1 fs2 fc1 sc0 ls0 ws0">cal reasonin<span class="_ _2"></span>g<span class="_ _6"> </span>tasks that con<span class="_ _2"></span>tains both words and phrases.<span class="_ _9"> </span>A<span class="_ _9"> </span>typical analogy pair from our test set is</div><div class="t m1 x0 h4 y51 ff1 fs2 fc1 sc0 ls0 ws0">“Montreal”:“M<span class="_ _2"></span>ontreal<span class="_ _6"> </span>Canadiens”::“T<span class="_ _4"></span>oronto”:“T<span class="_ _4"></span>oronto<span class="_ _6"> </span>M<span class="_ _4"></span>aple Leafs”.<span class="_ _9"> </span>It is<span class="_ _6"> </span>considere<span class="_ _2"></span>d<span class="_ _6"> </span>to<span class="_ _6"> </span>hav<span class="_ _5"></span>e<span class="_ _6"> </span>been</div><div class="t m1 x0 h4 y52 ff1 fs2 fc1 sc0 ls0 ws0">answered<span class="_ _9"> </span>correctly<span class="_ _9"> </span>if<span class="_ _9"> </span>the ne<span class="_ _2"></span>arest rep<span class="_ _2"></span>resentation<span class="_ _9"> </span>to<span class="_ _9"> </span>vec(“Montreal Canadiens”)<span class="_ _9"> </span>-<span class="_ _9"> </span>vec(“Montre<span class="_ _2"></span>al”) +</div><div class="t m1 x0 h4 y53 ff1 fs2 fc1 sc0 ls0 ws0">vec(“T<span class="_ _3"></span>o<span class="_ _2"></span>ronto”<span class="_ _2"></span>)<span class="_ _6"> </span>is vec(“T<span class="_ _3"></span>oro<span class="_ _2"></span>nto<span class="_ _6"> </span>Maple Leafs”).</div><div class="t m1 x0 h4 y54 ff1 fs2 fc1 sc0 ls0 ws0">Finally<span class="_ _4"></span>,<span class="_ _7"> </span>we<span class="_ _0"> </span>describe<span class="_ _7"> </span>another<span class="_ _7"> </span>interesting<span class="_ _7"> </span>pr<span class="_ _2"></span>operty<span class="_ _7"> </span>of<span class="_ _7"> </span>the<span class="_ _7"> </span>Skip<span class="_ _2"></span>-gram<span class="_ _7"> </span>model.<span class="_ _c"> </span>W<span class="_ _4"></span>e<span class="_ _7"> </span>foun<span class="_ _2"></span>d<span class="_ _7"> </span>that<span class="_ _7"> </span>simple</div><div class="t m1 x0 h4 y55 ff1 fs2 fc1 sc0 ls0 ws0">vector addition ca<span class="_ _2"></span>n often<span class="_ _9"> </span>produ<span class="_ _2"></span>ce meaningfu<span class="_ _2"></span>l results.<span class="_ _7"> </span>For example, vec(“Russia”) +<span class="_ _9"> </span>vec(“river”)<span class="_ _6"> </span>is</div><div class="t m1 x0 h4 y56 ff1 fs2 fc1 sc0 ls0 ws0">close<span class="_ _7"> </span>to<span class="_ _9"> </span>vec(“V<span class="_ _1"></span>olg<span class="_ _2"></span>a<span class="_ _9"> </span>River”),<span class="_ _7"> </span>and<span class="_ _9"> </span>vec(“Germ<span class="_ _2"></span>any”)<span class="_ _9"> </span>+<span class="_ _7"> </span>vec(“capital”)<span class="_ _9"> </span>is<span class="_ _7"> </span>close<span class="_ _7"> </span>to<span class="_ _9"> </span>vec(“Berlin”<span class="_ _2"></span>).<span class="_ _b"> </span>This</div><div class="t m1 x0 h4 y57 ff1 fs2 fc1 sc0 ls0 ws0">composition<span class="_ _2"></span>ality suggests that a<span class="_ _9"> </span>non-<span class="_ _2"></span>obvious degree<span class="_ _6"> </span>of la<span class="_ _2"></span>nguage under<span class="_ _2"></span>standing can be o<span class="_ _2"></span>btained by</div><div class="t m1 x0 h4 y58 ff1 fs2 fc1 sc0 ls0 ws0">using basic mathematical operation<span class="_ _2"></span>s on<span class="_ _6"> </span>the word vector representations.</div><div class="t m1 x0 h6 y59 ff2 fs3 fc1 sc0 ls0 ws0">2<span class="_ _a"> </span>The Skip-gram Model</div><div class="t m1 x0 h4 y5a ff1 fs2 fc1 sc0 ls0 ws0">The<span class="_ _7"> </span>trainin<span class="_ _2"></span>g<span class="_ _7"> </span>objective<span class="_ _7"> </span>of<span class="_ _7"> </span>the<span class="_ _7"> </span>Skip-gram<span class="_ _7"> </span>mo<span class="_ _2"></span>del<span class="_ _7"> </span>is<span class="_ _7"> </span>to<span class="_ _0"> </span>ﬁnd<span class="_ _7"> </span>word<span class="_ _7"> </span>representation<span class="_ _2"></span>s<span class="_ _7"> </span>that<span class="_ _7"> </span>are<span class="_ _7"> </span>useful<span class="_ _7"> </span>fo<span class="_ _2"></span>r</div><div class="t m1 x0 h4 y5b ff1 fs2 fc1 sc0 ls0 ws0">predicting the<span class="_ _9"> </span>surro<span class="_ _2"></span>unding words in<span class="_ _9"> </span>a senten<span class="_ _2"></span>ce or<span class="_ _9"> </span>a d<span class="_ _2"></span>ocumen<span class="_ _2"></span>t.<span class="_ _7"> </span>More fo<span class="_ _2"></span>rmally<span class="_ _4"></span>, given a sequen<span class="_ _2"></span>ce of</div><div class="t m1 x0 h4 y5c ff1 fs2 fc1 sc0 ls0 ws0">training<span class="_ _6"> </span>w<span class="_ _5"></span>ords<span class="_ _6"> </span><span class="ff5">w</span></div><div class="t m1 x1a hb y5d ff6 fs6 fc1 sc0 ls0 ws0">1</div><div class="t m1 x1b hc y5c ff5 fs2 fc1 sc0 ls0 ws0">,<span class="_ _6"> </span>w</div><div class="t m1 x1c hb y5d ff6 fs6 fc1 sc0 ls0 ws0">2</div><div class="t m1 xe hc y5c ff5 fs2 fc1 sc0 ls0 ws0">,<span class="_ _6"> </span>w</div><div class="t m1 x3 hb y5d ff6 fs6 fc1 sc0 ls0 ws0">3</div><div class="t m1 x1d hc y5c ff5 fs2 fc1 sc0 ls0 ws0">,<span class="_ _6"> </span>.<span class="_ _d"></span>.<span class="_ _6"> </span>.<span class="_ _d"></span>,<span class="_ _6"> </span>w</div><div class="t m1 x1e hb y5d ff7 fs6 fc1 sc0 ls0 ws0">T</div><div class="t m1 x1f h4 y5c ff1 fs2 fc1 sc0 ls0 ws0">,<span class="_ _6"> </span>the<span class="_ _6"> </span>objecti<span class="_ _5"></span>ve<span class="_ _6"> </span>o<span class="_ _4"></span>f<span class="_ _6"> </span>the<span class="_ _6"> </span>Skip-gram<span class="_ _6"> </span>model<span class="_ _6"> </span>i<span class="_ _4"></span>s to<span class="_ _6"> </span>maximize<span class="_ _6"> </span>t<span class="_ _4"></span>he<span class="_ _6"> </span>average</div><div class="t m1 x0 h4 y5e ff1 fs2 fc1 sc0 ls0 ws0">log proba<span class="_ _2"></span>bility</div><div class="t m1 x1e hc y5f ff8 fs2 fc1 sc0 ls0 ws0">1</div><div class="t m1 x1e hc y60 ff5 fs2 fc1 sc0 ls0 ws0">T</div><div class="t m1 x20 hb y61 ff7 fs6 fc1 sc0 ls0 ws0">T</div><div class="t m1 x21 hd y62 ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x21 hb y63 ff7 fs6 fc1 sc0 ls0 ws0">t<span class="ff6">=1</span></div><div class="t m1 x22 hd y62 ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x9 hb y33 ffa fs6 fc1 sc0 ls0 ws0">−<span class="ff7">c</span>≤<span class="ff7">j<span class="_ _2"></span></span>≤<span class="ff7">c,j<span class="_ _e"></span></span><span class="ff6">=0</span></div><div class="t m1 x23 hc y64 ff8 fs2 fc1 sc0 ls0 ws0">log<span class="_ _6"> </span><span class="ff5">p<span class="_ _4"></span><span class="ff8">(<span class="ff5">w</span></span></span></div><div class="t m1 x24 hb y32 ff7 fs6 fc1 sc0 ls0 ws0">t<span class="ff6">+</span>j</div><div class="t m1 x25 hc y64 ffb fs2 fc1 sc0 ls0 ws0">|<span class="ff5">w</span></div><div class="t m1 x13 hb y32 ff7 fs6 fc1 sc0 ls0 ws0">t</div><div class="t m1 x11 h4 y64 ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _f"> </span><span class="ff1">(1)</span></div><div class="t m1 x0 h4 y35 ff1 fs2 fc1 sc0 ls0 ws0">where<span class="_ _9"> </span><span class="ff5">c<span class="_ _9"> </span></span>is<span class="_ _9"> </span>th<span class="_ _2"></span>e<span class="_ _9"> </span>size<span class="_ _9"> </span>of<span class="_ _9"> </span>the<span class="_ _7"> </span>t<span class="_ _5"></span>raining<span class="_ _9"> </span>context<span class="_ _9"> </span>(which<span class="_ _9"> </span>can<span class="_ _9"> </span>be<span class="_ _9"> </span>a<span class="_ _7"> </span>function of<span class="_ _9"> </span>the<span class="_ _7"> </span>center word<span class="_ _9"> </span><span class="ff5">w</span></div><div class="t m1 x26 hb y65 ff7 fs6 fc1 sc0 ls0 ws0">t</div><div class="t m1 x27 h4 y35 ff1 fs2 fc1 sc0 ls0 ws0">).<span class="_ _0"> </span>L<span class="_ _2"></span>arger</div><div class="t m1 x0 h4 y36 ff5 fs2 fc1 sc0 ls0 ws0">c<span class="_ _7"> </span><span class="ff1">results<span class="_ _7"> </span>in<span class="_ _7"> </span>mor<span class="_ _2"></span>e<span class="_ _7"> </span>training<span class="_ _7"> </span>examples<span class="_ _7"> </span>a<span class="_ _5"></span>nd<span class="_ _7"> </span>thu<span class="_ _2"></span>s<span class="_ _7"> </span>can<span class="_ _7"> </span>lead<span class="_ _7"> </span>to<span class="_ _7"> </span>a<span class="_ _7"> </span>higher<span class="_ _7"> </span>accuracy<span class="_ _4"></span>,<span class="_ _7"> </span>at<span class="_ _7"> </span>the<span class="_ _7"> </span>expense<span class="_ _7"> </span>of<span class="_ _7"> </span>the</span></div><div class="t m1 x17 h4 y37 ff1 fs2 fc1 sc0 ls0 ws0">2</div><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,618.029,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:315.304000px;bottom:466.144000px;width:5.912000px;height:7.712000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,492.159,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:319.624000px;bottom:444.064000px;width:5.912000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,334.129,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:164.944000px;bottom:372.304000px;width:10.832000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf3" class="pf w0 h0" data-page-no="3"><div class="pc pc3 w0 h0"><img class="bi x7 y2 w3 hd" alt="" src="bg3.png"/><div class="t m1 x0 h4 y66 ff1 fs2 fc1 sc0 ls0 ws0">training time.<span class="_ _7"> </span>The<span class="_ _6"> </span>basic Skip-gra<span class="_ _2"></span>m formulation<span class="_ _6"> </span>deﬁnes <span class="ff5">p<span class="ff8">(</span>w</span></div><div class="t m1 x28 hb y67 ff7 fs6 fc1 sc0 ls0 ws0">t<span class="ff6">+</span>j</div><div class="t m1 x29 hc y66 ffb fs2 fc1 sc0 ls0 ws0">|<span class="ff5">w</span></div><div class="t m1 x11 hb y67 ff7 fs6 fc1 sc0 ls0 ws0">t</div><div class="t m1 x12 h4 y66 ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">us<span class="_ _5"></span>ing the softmax function:</span></div><div class="t m1 x2a hc y68 ff5 fs2 fc1 sc0 ls0 ws0">p<span class="ff8">(</span>w</div><div class="t m1 x21 hb y69 ff7 fs6 fc1 sc0 ls0 ws0">O</div><div class="t m1 x2b hc y68 ffb fs2 fc1 sc0 ls0 ws0">|<span class="ff5">w</span></div><div class="t m1 x2c hb y69 ff7 fs6 fc1 sc0 ls0 ws0">I</div><div class="t m1 x2d hc y68 ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _9"> </span>=</div><div class="t m1 x2e hc y6a ff8 fs2 fc1 sc0 ls0 ws0">exp</div><div class="t m1 x2f hd y6b ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x30 hc y6a ff5 fs2 fc1 sc0 ls0 ws0">v</div><div class="t m1 x31 he y6c ffa fs6 fc1 sc0 ls0 ws0">′</div><div class="t m1 x31 hb y6d ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x32 hf y6d ffc fs7 fc1 sc0 ls0 ws0">O</div><div class="t m1 x33 he y6e ffa fs6 fc1 sc0 ls0 ws0">⊤</div><div class="t m1 x28 hc y6f ff5 fs2 fc1 sc0 ls0 ws0">v</div><div class="t m1 x14 hb y70 ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x25 hf y70 ffc fs7 fc1 sc0 ls0 ws0">I</div><div class="t m1 x34 hd y71 ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x7 hd y72 ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x2e hb y73 ff7 fs6 fc1 sc0 ls0 ws0">W</div><div class="t m1 x2e hb y74 ff7 fs6 fc1 sc0 ls0 ws0">w<span class="ff6">=1</span></div><div class="t m1 x2f hc y75 ff8 fs2 fc1 sc0 ls0 ws0">exp</div><div class="t m1 x32 hd y76 ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x33 hc y75 ff5 fs2 fc1 sc0 ls0 ws0">v</div><div class="t m1 x28 he y77 ffa fs6 fc1 sc0 ls0 ws0">′</div><div class="t m1 x35 hb y78 ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x14 he y73 ffa fs6 fc1 sc0 ls0 ws0">⊤</div><div class="t m1 x25 hc y75 ff5 fs2 fc1 sc0 ls0 ws0">v</div><div class="t m1 x36 hb y79 ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x11 hf y79 ffc fs7 fc1 sc0 ls0 ws0">I</div><div class="t m1 x12 hd y7a ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x37 h4 y68 ff1 fs2 fc1 sc0 ls0 ws0">(2)</div><div class="t m1 x0 h4 y7b ff1 fs2 fc1 sc0 ls0 ws0">where<span class="_ _0"> </span><span class="ff5">v</span></div><div class="t m1 x38 hb y7c ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x39 h4 y7b ff1 fs2 fc1 sc0 ls0 ws0">and<span class="_ _0"> </span><span class="ff5">v</span></div><div class="t m1 x1a he y7d ffa fs6 fc1 sc0 ls0 ws0">′</div><div class="t m1 x1a hb y7c ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x3a h4 y7b ff1 fs2 fc1 sc0 ls0 ws0">are<span class="_ _0"> </span>the<span class="_ _7"> </span>“in<span class="_ _2"></span>put”<span class="_ _0"> </span>and<span class="_ _7"> </span>“o<span class="_ _2"></span>utput”<span class="_ _0"> </span>v<span class="_ _4"></span>e<span class="_ _2"></span>ctor<span class="_ _7"> </span>r<span class="_ _2"></span>epresentation<span class="_ _2"></span>s<span class="_ _7"> </span>of<span class="_ _0"> </span><span class="ff5">w</span>,<span class="_ _8"> </span>and<span class="_ _0"> </span><span class="ff5">W<span class="_ _b"> </span></span>is<span class="_ _0"> </span>the<span class="_ _0"> </span>num-</div><div class="t m1 x0 h4 y7e ff1 fs2 fc1 sc0 ls0 ws0">ber<span class="_ _0"> </span>of<span class="_ _0"> </span>words<span class="_ _0"> </span>in<span class="_ _0"> </span>the<span class="_ _0"> </span>v<span class="_ _4"></span>o<span class="_ _2"></span>cabulary<span class="_ _4"></span>.<span class="_ _10"> </span>This<span class="_ _0"> </span>form<span class="_ _2"></span>ulation<span class="_ _0"> </span>i<span class="_ _5"></span>s<span class="_ _0"> </span>impractical<span class="_ _0"> </span>because<span class="_ _0"> </span>the<span class="_ _0"> </span>cost<span class="_ _0"> </span>of<span class="_ _0"> </span>comp<span class="_ _2"></span>uting</div><div class="t m1 x0 hc y7f ffb fs2 fc1 sc0 ls0 ws0">∇<span class="_ _11"> </span><span class="ff8">log<span class="_ _11"> </span><span class="ff5">p</span>(<span class="ff5">w</span></span></div><div class="t m1 x3b hb y80 ff7 fs6 fc1 sc0 ls0 ws0">O</div><div class="t m1 x3c hc y7f ffb fs2 fc1 sc0 ls0 ws0">|<span class="ff5">w</span></div><div class="t m1 x3d hb y80 ff7 fs6 fc1 sc0 ls0 ws0">I</div><div class="t m1 x10 h4 y7f ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">i<span class="_ _4"></span>s p<span class="_ _2"></span>ropor<span class="_ _2"></span>tional<span class="_ _6"> </span>to <span class="ff5">W<span class="_ _d"> </span></span>, wh<span class="_ _2"></span>ich is often large<span class="_ _6"> </span>(<span class="ff8">10</span></span></div><div class="t m1 x25 hb y81 ff6 fs6 fc1 sc0 ls0 ws0">5</div><div class="t m1 x34 h4 y7f ff1 fs2 fc1 sc0 ls0 ws0">–<span class="ff8">10</span></div><div class="t m1 x3e hb y81 ff6 fs6 fc1 sc0 ls0 ws0">7</div><div class="t m1 x3f h4 y7f ff1 fs2 fc1 sc0 ls0 ws0">terms).</div><div class="t m1 x0 h3 y82 ff2 fs2 fc1 sc0 ls0 ws0">2.1<span class="_ _12"> </span>Hierarchical S<span class="_ _5"></span>oftmax</div><div class="t m1 x0 h4 y83 ff1 fs2 fc1 sc0 ls0 ws0">A<span class="_ _7"> </span>compu<span class="_ _2"></span>tationally<span class="_ _7"> </span>ef<span class="_ _4"></span>ﬁcient<span class="_ _7"> </span>app<span class="_ _2"></span>roximatio<span class="_ _2"></span>n<span class="_ _9"> </span>of<span class="_ _0"> </span>t<span class="_ _4"></span>h<span class="_ _2"></span>e<span class="_ _7"> </span>full<span class="_ _7"> </span>softmax<span class="_ _7"> </span>is<span class="_ _7"> </span>the<span class="_ _7"> </span>hierarch<span class="_ _2"></span>ical<span class="_ _7"> </span>softmax.<span class="_ _c"> </span>In<span class="_ _7"> </span>the</div><div class="t m1 x0 h4 y84 ff1 fs2 fc1 sc0 ls0 ws0">context of<span class="_ _9"> </span>neural<span class="_ _9"> </span>network langu<span class="_ _2"></span>age mod<span class="_ _2"></span>els, it<span class="_ _9"> </span>was<span class="_ _9"> </span>ﬁrst in<span class="_ _2"></span>troduced by<span class="_ _9"> </span>Morin<span class="_ _9"> </span>and Ben<span class="_ _2"></span>gio<span class="_ _9"> </span>[12].<span class="_ _0"> </span>The</div><div class="t m1 x0 h4 y85 ff1 fs2 fc1 sc0 ls0 ws0">main<span class="_ _7"> </span>advantage<span class="_ _7"> </span>is<span class="_ _7"> </span>that<span class="_ _7"> </span>instead<span class="_ _7"> </span>o<span class="_ _2"></span>f<span class="_ _7"> </span>ev<span class="_ _4"></span>alu<span class="_ _2"></span>ating<span class="_ _7"> </span><span class="ff5">W<span class="_ _b"> </span></span>output<span class="_ _7"> </span>nod<span class="_ _2"></span>es<span class="_ _7"> </span>in<span class="_ _7"> </span>the<span class="_ _7"> </span>neu<span class="_ _2"></span>ral<span class="_ _7"> </span>network<span class="_ _7"> </span>to<span class="_ _7"> </span>obtain<span class="_ _7"> </span>th<span class="_ _2"></span>e</div><div class="t m1 x0 h4 y86 ff1 fs2 fc1 sc0 ls0 ws0">probab<span class="_ _2"></span>ility<span class="_ _6"> </span>distribution, it is needed to e<span class="_ _4"></span>valuate only about <span class="ff8">log</span></div><div class="t m1 x25 hb y87 ff6 fs6 fc1 sc0 ls0 ws0">2</div><div class="t m1 x29 h4 y86 ff8 fs2 fc1 sc0 ls0 ws0">(<span class="ff5">W<span class="_ _d"> </span></span>)<span class="_ _9"> </span><span class="ff1">nodes.</span></div><div class="t m1 x0 h4 y88 ff1 fs2 fc1 sc0 ls0 ws0">The<span class="_ _9"> </span>hierarchical so<span class="_ _2"></span>ftmax uses<span class="_ _9"> </span>a<span class="_ _9"> </span>bina<span class="_ _2"></span>ry tree<span class="_ _9"> </span>represen<span class="_ _2"></span>tation of<span class="_ _9"> </span>the ou<span class="_ _2"></span>tput layer<span class="_ _9"> </span>with<span class="_ _9"> </span>the<span class="_ _9"> </span><span class="ff5">W<span class="_ _8"> </span></span>w<span class="_ _4"></span>or<span class="_ _2"></span>ds as</div><div class="t m1 x0 h4 y89 ff1 fs2 fc1 sc0 ls0 ws0">its leav<span class="_ _4"></span>e<span class="_ _2"></span>s and,<span class="_ _6"> </span>for each node, explicitly<span class="_ _6"> </span>represents the relati<span class="_ _4"></span>ve probabilities of<span class="_ _6"> </span>its child nodes.<span class="_ _9"> </span>Th<span class="_ _2"></span>ese</div><div class="t m1 x0 h4 y8a ff1 fs2 fc1 sc0 ls0 ws0">deﬁne a random walk that assigns probabilities to words.</div><div class="t m1 x0 h4 y8b ff1 fs2 fc1 sc0 ls0 ws0">More<span class="_ _9"> </span>p<span class="_ _2"></span>recisely<span class="_ _4"></span>,<span class="_ _9"> </span>each<span class="_ _7"> </span>w<span class="_ _5"></span>ord<span class="_ _9"> </span><span class="ff5">w<span class="_ _7"> </span></span>can<span class="_ _7"> </span>be<span class="_ _9"> </span>reached<span class="_ _9"> </span>by<span class="_ _7"> </span>an<span class="_ _9"> </span>appr<span class="_ _2"></span>opriate<span class="_ _9"> </span>path<span class="_ _9"> </span>f<span class="_ _2"></span>rom<span class="_ _9"> </span>the<span class="_ _7"> </span>root<span class="_ _9"> </span>of<span class="_ _9"> </span>the<span class="_ _7"> </span>tree.<span class="_ _8"> </span>Let</div><div class="t m1 x0 h4 y8c ff5 fs2 fc1 sc0 ls0 ws0">n<span class="ff8">(</span>w,<span class="_ _11"> </span>j<span class="_ _d"></span><span class="ff8">)<span class="_ _9"> </span><span class="ff1">b<span class="_ _5"></span>e the<span class="_ _9"> </span><span class="ff5">j<span class="_ _e"></span></span>-th<span class="_ _9"> </span>n<span class="_ _2"></span>ode on<span class="_ _9"> </span>the<span class="_ _9"> </span>path<span class="_ _9"> </span>from th<span class="_ _2"></span>e<span class="_ _9"> </span>root to<span class="_ _9"> </span><span class="ff5">w<span class="_ _2"></span></span>,<span class="_ _9"> </span>an<span class="_ _2"></span>d let<span class="_ _9"> </span><span class="ff5">L<span class="ff8">(</span>w<span class="_ _2"></span><span class="ff8">)<span class="_ _9"> </span></span></span>be<span class="_ _9"> </span>the<span class="_ _9"> </span>length<span class="_ _9"> </span>of th<span class="_ _2"></span>is p<span class="_ _2"></span>ath,<span class="_ _9"> </span>so</span></span></div><div class="t m1 x0 h4 y8d ff5 fs2 fc1 sc0 ls0 ws0">n<span class="ff8">(</span>w,<span class="_ _11"> </span><span class="ff8">1<span class="_ _2"></span>)<span class="_ _7"> </span>=<span class="_ _0"> </span>roo<span class="_ _2"></span>t<span class="_ _9"> </span><span class="ff1">and<span class="_ _9"> </span></span></span>n<span class="ff8">(</span>w ,<span class="_ _6"> </span>L<span class="ff8">(</span>w<span class="ff8">))<span class="_ _0"> </span>=<span class="_ _7"> </span></span>w<span class="ff1">.<span class="_ _8"> </span>In<span class="_ _9"> </span>addition<span class="_ _2"></span>,<span class="_ _9"> </span>for<span class="_ _9"> </span>any<span class="_ _9"> </span>inner<span class="_ _9"> </span>nod<span class="_ _2"></span>e </span>n<span class="ff1">,<span class="_ _7"> </span>let<span class="_ _9"> </span><span class="ff8">ch(<span class="_ _5"></span><span class="ff5">n<span class="ff8">)<span class="_ _9"> </span><span class="ff1">be<span class="_ _7"> </span>a<span class="_ _5"></span>n<span class="_ _9"> </span>arbitrary</span></span></span></span></span></div><div class="t m1 x0 h4 y8e ff1 fs2 fc1 sc0 ls0 ws0">ﬁxed child of <span class="ff5">n<span class="_ _9"> </span></span>and let <span class="ff8">[<span class="_ _1"></span>[<span class="_ _4"></span><span class="ff5">x<span class="ff8">]<span class="_ _1"></span>]<span class="_ _6"> </span><span class="ff1">be<span class="_ _9"> </span>1 if <span class="ff5">x<span class="_ _9"> </span></span>is true and -1 oth<span class="_ _2"></span>erwise.<span class="_ _7"> </span>Then the hierarch<span class="_ _2"></span>ical softmax deﬁnes</span></span></span></span></div><div class="t m1 x0 hc y8f ff5 fs2 fc1 sc0 ls0 ws0">p<span class="ff8">(</span>w</div><div class="t m1 x40 hb y90 ff7 fs6 fc1 sc0 ls0 ws0">O</div><div class="t m1 x6 hc y8f ffb fs2 fc1 sc0 ls0 ws0">|<span class="ff5">w</span></div><div class="t m1 x38 hb y90 ff7 fs6 fc1 sc0 ls0 ws0">I</div><div class="t m1 x41 h4 y8f ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">a<span class="_ _5"></span>s follows:</span></div><div class="t m1 x10 hc y1c ff5 fs2 fc1 sc0 ls0 ws0">p<span class="ff8">(</span>w<span class="ffb">|</span>w</div><div class="t m1 xe hb y91 ff7 fs6 fc1 sc0 ls0 ws0">I</div><div class="t m1 x42 hc y1c ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _9"> </span>=</div><div class="t m1 x43 hb y92 ff7 fs6 fc1 sc0 ls0 ws0">L<span class="ff6">(</span>w<span class="_ _2"></span><span class="ff6">)<span class="ffa">−</span>1</span></div><div class="t m1 x44 hd y93 ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x44 hb y94 ff7 fs6 fc1 sc0 ls0 ws0">j<span class="_ _2"></span><span class="ff6">=1</span></div><div class="t m1 x21 hc y1c ff5 fs2 fc1 sc0 ls0 ws0">σ</div><div class="t m1 x2b hd y1b ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x45 hc y1c ff8 fs2 fc1 sc0 ls0 ws0">[<span class="_ _1"></span>[<span class="_ _4"></span><span class="ff5">n<span class="ff8">(</span>w<span class="_ _2"></span>,<span class="_ _11"> </span>j<span class="_ _7"> </span><span class="ff8">+<span class="_ _6"> </span>1)<span class="_ _9"> </span>=<span class="_ _9"> </span>c<span class="_ _4"></span>h(<span class="ff5">n</span>(<span class="ff5">w,<span class="_ _11"> </span>j<span class="_ _e"></span></span>))]<span class="_ _1"></span>]<span class="_ _6"> </span><span class="ffb">·<span class="_ _6"> </span><span class="ff5">v</span></span></span></span></div><div class="t m1 x46 he y95 ffa fs6 fc1 sc0 ls0 ws0">′</div><div class="t m1 x46 hb y96 ff7 fs6 fc1 sc0 ls0 ws0">n<span class="ff6">(</span>w,<span class="_ _2"></span>j<span class="_ _2"></span><span class="ff6">)</span></div><div class="t m1 x47 he y97 ffa fs6 fc1 sc0 ls0 ws0">⊤</div><div class="t m1 x48 hc y1c ff5 fs2 fc1 sc0 ls0 ws0">v</div><div class="t m1 x49 hb y98 ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x4a hf y91 ffc fs7 fc1 sc0 ls0 ws0">I</div><div class="t m1 x4b hd y1b ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x37 h4 y1c ff1 fs2 fc1 sc0 ls0 ws0">(3)</div><div class="t m1 x0 h4 y1f ff1 fs2 fc1 sc0 ls0 ws0">where <span class="ff5">σ<span class="_ _2"></span><span class="ff8">(</span>x<span class="ff8">)<span class="_ _7"> </span>=<span class="_ _7"> </span>1</span>/<span class="ff8">(1<span class="_ _6"> </span>+<span class="_ _6"> </span>exp(<span class="ffb">−</span></span>x<span class="ff8">))</span></span>.<span class="_ _0"> </span>It can be veriﬁed tha<span class="_ _2"></span>t</div><div class="t m1 x32 hd y99 ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x24 hb y9a ff7 fs6 fc1 sc0 ls0 ws0">W</div><div class="t m1 x24 hb y9b ff7 fs6 fc1 sc0 ls0 ws0">w<span class="ff6">=1</span></div><div class="t m1 x36 hc y1f ff5 fs2 fc1 sc0 ls0 ws0">p<span class="ff8">(</span>w<span class="ffb">|</span>w</div><div class="t m1 x46 hb y9c ff7 fs6 fc1 sc0 ls0 ws0">I</div><div class="t m1 x4c h4 y1f ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _7"> </span>=<span class="_ _9"> </span>1<span class="ff1">.<span class="_ _7"> </span>T<span class="_ _2"></span>his implies<span class="_ _9"> </span>that the</span></div><div class="t m1 x0 h4 y4d ff1 fs2 fc1 sc0 ls0 ws0">cost<span class="_ _9"> </span>of<span class="_ _9"> </span>compu<span class="_ _2"></span>ting <span class="ff8">log<span class="_ _11"> </span><span class="ff5">p</span>(<span class="ff5">w</span></span></div><div class="t m1 x4d hb y9d ff7 fs6 fc1 sc0 ls0 ws0">O</div><div class="t m1 x4e hc y4d ffb fs2 fc1 sc0 ls0 ws0">|<span class="ff5">w</span></div><div class="t m1 x2a hb y9d ff7 fs6 fc1 sc0 ls0 ws0">I</div><div class="t m1 x4f h4 y4d ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">and<span class="_ _9"> </span><span class="ffb">∇<span class="_ _11"> </span></span></span>log<span class="_ _11"> </span><span class="ff5">p</span>(<span class="ff5">w</span></div><div class="t m1 x2e hb y9d ff7 fs6 fc1 sc0 ls0 ws0">O</div><div class="t m1 x50 hc y4d ffb fs2 fc1 sc0 ls0 ws0">|<span class="ff5">w</span></div><div class="t m1 x2f hb y9d ff7 fs6 fc1 sc0 ls0 ws0">I</div><div class="t m1 x30 h4 y4d ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">is<span class="_ _9"> </span>propo<span class="_ _2"></span>rtional to<span class="_ _9"> </span><span class="ff5">L</span></span>(<span class="ff5">w</span></div><div class="t m1 xa hb y9d ff7 fs6 fc1 sc0 ls0 ws0">O</div><div class="t m1 x49 h4 y4d ff8 fs2 fc1 sc0 ls0 ws0">)<span class="ff1">,<span class="_ _9"> </span>which<span class="_ _9"> </span>on<span class="_ _9"> </span>average</span></div><div class="t m1 x0 h4 y4e ff1 fs2 fc1 sc0 ls0 ws0">is<span class="_ _7"> </span>no<span class="_ _7"> </span>greater<span class="_ _7"> </span>than<span class="_ _7"> </span><span class="ff8">log<span class="_ _11"> </span><span class="ff5">W<span class="_ _d"> </span></span></span>.<span class="_ _c"> </span>Also,<span class="_ _7"> </span>unlike<span class="_ _7"> </span>the<span class="_ _7"> </span>standard<span class="_ _7"> </span>softmax<span class="_ _7"> </span>formulation<span class="_ _9"> </span>o<span class="_ _2"></span>f<span class="_ _7"> </span>the<span class="_ _7"> </span>Skip-gram<span class="_ _7"> </span>which</div><div class="t m1 x0 h4 y4f ff1 fs2 fc1 sc0 ls0 ws0">assigns<span class="_ _7"> </span>two<span class="_ _7"> </span>representation<span class="_ _2"></span>s<span class="_ _9"> </span><span class="ff5">v</span></div><div class="t m1 x44 hb y9e ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x51 h4 y4f ff1 fs2 fc1 sc0 ls0 ws0">and<span class="_ _7"> </span><span class="ff5">v</span></div><div class="t m1 x52 he y9f ffa fs6 fc1 sc0 ls0 ws0">′</div><div class="t m1 x52 hb y22 ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x2d h4 y4f ff1 fs2 fc1 sc0 ls0 ws0">to<span class="_ _7"> </span>each<span class="_ _7"> </span>word<span class="_ _7"> </span><span class="ff5">w</span>,<span class="_ _0"> </span>the<span class="_ _7"> </span>hierarchical<span class="_ _7"> </span>softmax<span class="_ _7"> </span>formulation<span class="_ _7"> </span>has</div><div class="t m1 x0 h4 y50 ff1 fs2 fc1 sc0 ls0 ws0">one<span class="_ _0"> </span>r<span class="_ _5"></span>epresentatio<span class="_ _2"></span>n<span class="_ _7"> </span><span class="ff5">v</span></div><div class="t m1 x1c hb ya0 ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x42 h4 y50 ff1 fs2 fc1 sc0 ls0 ws0">for<span class="_ _0"> </span>e<span class="_ _5"></span>ach<span class="_ _7"> </span>word<span class="_ _0"> </span><span class="ff5">w<span class="_ _0"> </span></span>and<span class="_ _7"> </span>one<span class="_ _0"> </span>r<span class="_ _5"></span>epresentatio<span class="_ _2"></span>n<span class="_ _7"> </span><span class="ff5">v</span></div><div class="t m1 x12 he ya1 ffa fs6 fc1 sc0 ls0 ws0">′</div><div class="t m1 x12 hb y23 ff7 fs6 fc1 sc0 ls0 ws0">n</div><div class="t m1 x3f h4 y50 ff1 fs2 fc1 sc0 ls0 ws0">for<span class="_ _0"> </span>e<span class="_ _4"></span>very<span class="_ _7"> </span>inner<span class="_ _0"> </span>node<span class="_ _7"> </span><span class="ff5">n<span class="_ _7"> </span></span>o<span class="_ _2"></span>f<span class="_ _0"> </span>t<span class="_ _5"></span>he</div><div class="t m1 x0 h4 y51 ff1 fs2 fc1 sc0 ls0 ws0">binary tree.</div><div class="t m1 x0 h4 ya2 ff1 fs2 fc1 sc0 ls0 ws0">The<span class="_ _7"> </span>s<span class="_ _5"></span>tructure<span class="_ _7"> </span>of<span class="_ _7"> </span>t<span class="_ _5"></span>he<span class="_ _7"> </span>tree<span class="_ _7"> </span>used<span class="_ _9"> </span>by<span class="_ _7"> </span>the<span class="_ _9"> </span>hie<span class="_ _2"></span>rarchical<span class="_ _7"> </span>softmax<span class="_ _9"> </span>has<span class="_ _7"> </span>a<span class="_ _7"> </span>considerable<span class="_ _9"> </span>effect<span class="_ _7"> </span>on<span class="_ _9"> </span>the<span class="_ _7"> </span>perfor-</div><div class="t m1 x0 h4 ya3 ff1 fs2 fc1 sc0 ls0 ws0">mance.<span class="_ _0"> </span>Mnih<span class="_ _9"> </span>and H<span class="_ _2"></span>inton<span class="_ _9"> </span>explored a<span class="_ _9"> </span>nu<span class="_ _2"></span>mber of<span class="_ _9"> </span>meth<span class="_ _2"></span>ods fo<span class="_ _2"></span>r co<span class="_ _2"></span>nstructing<span class="_ _9"> </span>the tree<span class="_ _9"> </span>stru<span class="_ _2"></span>cture<span class="_ _9"> </span>and th<span class="_ _2"></span>e</div><div class="t m1 x0 h4 y25 ff1 fs2 fc1 sc0 ls0 ws0">effect on both the tr<span class="_ _2"></span>aining time and th<span class="_ _2"></span>e resultin<span class="_ _2"></span>g model accuracy [10].<span class="_ _7"> </span>In o<span class="_ _2"></span>ur work we use a<span class="_ _9"> </span>binar<span class="_ _2"></span>y</div><div class="t m1 x0 h4 y55 ff1 fs2 fc1 sc0 ls0 ws0">Huffman<span class="_ _9"> </span>tree,<span class="_ _7"> </span>as<span class="_ _7"> </span>i<span class="_ _5"></span>t<span class="_ _7"> </span>ass<span class="_ _5"></span>igns<span class="_ _7"> </span>short<span class="_ _9"> </span>co<span class="_ _2"></span>des<span class="_ _9"> </span>to<span class="_ _7"> </span>the<span class="_ _7"> </span>frequent<span class="_ _9"> </span>words<span class="_ _7"> </span>which<span class="_ _9"> </span>results<span class="_ _7"> </span>in<span class="_ _9"> </span>fast<span class="_ _7"> </span>training.<span class="_ _b"> </span>It<span class="_ _7"> </span>has</div><div class="t m1 x0 h4 y56 ff1 fs2 fc1 sc0 ls0 ws0">been<span class="_ _9"> </span>observed be<span class="_ _2"></span>fore that<span class="_ _9"> </span>g<span class="_ _2"></span>roupin<span class="_ _2"></span>g words<span class="_ _9"> </span>together b<span class="_ _2"></span>y th<span class="_ _2"></span>eir<span class="_ _9"> </span>freque<span class="_ _2"></span>ncy works well<span class="_ _9"> </span>as<span class="_ _9"> </span>a<span class="_ _9"> </span>very<span class="_ _9"> </span>simple</div><div class="t m1 x0 h4 y57 ff1 fs2 fc1 sc0 ls0 ws0">speedup techniqu<span class="_ _2"></span>e<span class="_ _6"> </span>for the neural network based language models [5, 8].</div><div class="t m1 x0 h3 y3b ff2 fs2 fc1 sc0 ls0 ws0">2.2<span class="_ _12"> </span>Negative Sampling</div><div class="t m1 x0 h4 ya4 ff1 fs2 fc1 sc0 ls0 ws0">An<span class="_ _7"> </span>alternative<span class="_ _7"> </span>to<span class="_ _7"> </span>the<span class="_ _7"> </span>hierarchical<span class="_ _7"> </span>softmax<span class="_ _7"> </span>is<span class="_ _7"> </span>N<span class="_ _2"></span>oise<span class="_ _7"> </span>Contrastive<span class="_ _7"> </span>E<span class="_ _5"></span>stimation<span class="_ _7"> </span>(NCE),<span class="_ _7"> </span>which<span class="_ _0"> </span>w<span class="_ _4"></span>as<span class="_ _0"> </span>i<span class="_ _5"></span>n-</div><div class="t m1 x0 h4 ya5 ff1 fs2 fc1 sc0 ls0 ws0">troduced b<span class="_ _2"></span>y<span class="_ _9"> </span>Gutmann<span class="_ _9"> </span>and Hyvarinen<span class="_ _9"> </span>[4] a<span class="_ _2"></span>nd app<span class="_ _2"></span>lied to<span class="_ _9"> </span>langu<span class="_ _2"></span>age mo<span class="_ _2"></span>deling b<span class="_ _2"></span>y Mn<span class="_ _2"></span>ih a<span class="_ _2"></span>nd<span class="_ _9"> </span>T<span class="_ _4"></span>eh [11].</div><div class="t m1 x0 h4 ya6 ff1 fs2 fc1 sc0 ls0 ws0">NCE<span class="_ _9"> </span>posits<span class="_ _7"> </span>t<span class="_ _5"></span>hat<span class="_ _9"> </span>a<span class="_ _7"> </span>good mod<span class="_ _2"></span>el<span class="_ _9"> </span>should<span class="_ _9"> </span>be<span class="_ _7"> </span>able to<span class="_ _7"> </span>dif<span class="_ _4"></span>f<span class="_ _2"></span>erentiate<span class="_ _9"> </span>data<span class="_ _9"> </span>from<span class="_ _9"> </span>no<span class="_ _2"></span>ise<span class="_ _9"> </span>by<span class="_ _9"> </span>mean<span class="_ _2"></span>s<span class="_ _9"> </span>of<span class="_ _7"> </span>l<span class="_ _5"></span>ogistic</div><div class="t m1 x0 h4 ya7 ff1 fs2 fc1 sc0 ls0 ws0">regression.<span class="_ _8"> </span>This is<span class="_ _9"> </span>similar<span class="_ _7"> </span>to h<span class="_ _2"></span>inge<span class="_ _9"> </span>loss<span class="_ _9"> </span>used<span class="_ _7"> </span>by Collob<span class="_ _2"></span>ert<span class="_ _9"> </span>and<span class="_ _9"> </span>W<span class="_ _4"></span>eston<span class="_ _9"> </span>[2]<span class="_ _9"> </span>who<span class="_ _7"> </span>t<span class="_ _5"></span>rained<span class="_ _9"> </span>the<span class="_ _9"> </span>m<span class="_ _2"></span>odels</div><div class="t m1 x0 h4 ya8 ff1 fs2 fc1 sc0 ls0 ws0">by rankin<span class="_ _2"></span>g<span class="_ _6"> </span>the data above noise.</div><div class="t m1 x0 h4 ya9 ff1 fs2 fc1 sc0 ls0 ws0">While NCE<span class="_ _9"> </span>can<span class="_ _9"> </span>be<span class="_ _9"> </span>shown to appr<span class="_ _2"></span>oximately maximize<span class="_ _9"> </span>the log<span class="_ _9"> </span>pro<span class="_ _2"></span>bability of<span class="_ _9"> </span>the so<span class="_ _2"></span>ftmax, th<span class="_ _2"></span>e Skip<span class="_ _2"></span>-</div><div class="t m1 x0 h4 yaa ff1 fs2 fc1 sc0 ls0 ws0">gram<span class="_ _9"> </span>m<span class="_ _2"></span>odel<span class="_ _9"> </span>is<span class="_ _7"> </span>only<span class="_ _9"> </span>co<span class="_ _2"></span>ncerned<span class="_ _9"> </span>with<span class="_ _7"> </span>learning<span class="_ _9"> </span>hig<span class="_ _2"></span>h-quality<span class="_ _9"> </span>vector<span class="_ _7"> </span>representations,<span class="_ _9"> </span>so<span class="_ _7"> </span>we<span class="_ _9"> </span>are<span class="_ _7"> </span>free to</div><div class="t m1 x0 h4 yab ff1 fs2 fc1 sc0 ls0 ws0">simplify<span class="_ _6"> </span>NCE<span class="_ _6"> </span>as long<span class="_ _6"> </span>as<span class="_ _6"> </span>the<span class="_ _6"> </span>vector<span class="_ _6"> </span>representations<span class="_ _6"> </span>retain<span class="_ _6"> </span>their<span class="_ _11"> </span>q<span class="_ _2"></span>uality<span class="_ _4"></span>.<span class="_ _9"> </span>W<span class="_ _3"></span>e deﬁne Ne<span class="_ _5"></span>gative<span class="_ _11"> </span>sampling</div><div class="t m1 x0 h4 y60 ff1 fs2 fc1 sc0 ls0 ws0">(NEG) by the objective</div><div class="t m1 xe hc yac ff8 fs2 fc1 sc0 ls0 ws0">log<span class="_ _11"> </span><span class="ff5">σ<span class="_ _2"></span></span>(<span class="ff5">v</span></div><div class="t m1 x44 he yad ffa fs6 fc1 sc0 ls0 ws0">′</div><div class="t m1 x44 hb yae ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x53 hf yae ffc fs7 fc1 sc0 ls0 ws0">O</div><div class="t m1 x51 he yaf ffa fs6 fc1 sc0 ls0 ws0">⊤</div><div class="t m1 x54 hc yb0 ff5 fs2 fc1 sc0 ls0 ws0">v</div><div class="t m1 x21 hb yb1 ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x20 hf yb1 ffc fs7 fc1 sc0 ls0 ws0">I</div><div class="t m1 x52 hc yb2 ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _6"> </span>+</div><div class="t m1 x22 hb yb3 ff7 fs6 fc1 sc0 ls0 ws0">k</div><div class="t m1 x55 hd yb4 ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x55 hb yb5 ff7 fs6 fc1 sc0 ls0 ws0">i<span class="ff6">=1</span></div><div class="t m1 x56 h10 yb6 ffd fs2 fc1 sc0 ls0 ws0">E</div><div class="t m1 x57 hb yb1 ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x17 hf yae ffc fs7 fc1 sc0 ls0 ws0">i</div><div class="t m1 x50 hb yb1 ffa fs6 fc1 sc0 ls0 ws0">∼<span class="ff7">P</span></div><div class="t m1 x58 hf yae ffc fs7 fc1 sc0 ls0 ws0">n</div><div class="t m1 x30 hb yb1 ff6 fs6 fc1 sc0 ls0 ws0">(<span class="ff7">w</span>)</div><div class="t m1 x59 hd yb7 ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x24 hc yb6 ff8 fs2 fc1 sc0 ls0 ws0">log<span class="_ _11"> </span><span class="ff5">σ<span class="_ _2"></span></span>(<span class="ffb">−<span class="ff5">v</span></span></div><div class="t m1 x5a he yb8 ffa fs6 fc1 sc0 ls0 ws0">′</div><div class="t m1 x5a hb yb9 ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x3f hf yae ffc fs7 fc1 sc0 ls0 ws0">i</div><div class="t m1 x5b he yba ffa fs6 fc1 sc0 ls0 ws0">⊤</div><div class="t m1 x5c hc ybb ff5 fs2 fc1 sc0 ls0 ws0">v</div><div class="t m1 x5d hb ybc ff7 fs6 fc1 sc0 ls0 ws0">w</div><div class="t m1 x5e hf yb1 ffc fs7 fc1 sc0 ls0 ws0">I</div><div class="t m1 x5f hc ybd ff8 fs2 fc1 sc0 ls0 ws0">)</div><div class="t m1 x47 hd ybe ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x37 h4 ybd ff1 fs2 fc1 sc0 ls0 ws0">(4)</div><div class="t m1 x17 h4 ybf ff1 fs2 fc1 sc0 ls0 ws0">3</div><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,396.16,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:467.464000px;bottom:551.224000px;width:10.952000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,444.099,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:370.984000px;bottom:271.744000px;width:10.952000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,585.869,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:372.304000px;bottom:238.864000px;width:5.912000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,492.159,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:382.264000px;bottom:238.864000px;width:5.912000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,618.029,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:261.784000px;bottom:180.664000px;width:5.912000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,420.13,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:486.784000px;bottom:180.664000px;width:10.952000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,676.206,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:396.784000px;bottom:158.704000px;width:6.032000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf4" class="pf w0 h0" data-page-no="4"><div class="pc pc4 w0 h0"><img class="bi x3c y65 w4 h11" alt="" src="bg4.png"/><div class="t m1 x16 h10 yc0 ffe fs6 fc1 sc0 ls0 ws0">-2</div><div class="t m1 x60 h10 y13 ffe fs6 fc1 sc0 ls0 ws0">-1.5</div><div class="t m1 x16 h10 yc1 ffe fs6 fc1 sc0 ls0 ws0">-1</div><div class="t m1 x60 h10 yc2 ffe fs6 fc1 sc0 ls0 ws0">-0.5</div><div class="t m1 x41 h10 yc3 ffe fs6 fc1 sc0 ls0 ws0"> 0</div><div class="t m1 x60 h10 yc4 ffe fs6 fc1 sc0 ls0 ws0"> 0.5</div><div class="t m1 x41 h10 yc5 ffe fs6 fc1 sc0 ls0 ws0"> 1</div><div class="t m1 x60 h10 y73 ffe fs6 fc1 sc0 ls0 ws0"> 1.5</div><div class="t m1 x41 h10 y6b ffe fs6 fc1 sc0 ls0 ws0"> 2</div><div class="t m1 x39 h10 yc6 ffe fs6 fc1 sc0 ls0 ws0">-2<span class="_ _13"> </span>-1.5<span class="_ _13"> </span>-1<span class="_ _13"> </span>-0.5<span class="_ _13"> </span> 0<span class="_ _14"> </span> 0.5<span class="_ _14"> </span> 1<span class="_ _13"> </span> 1.5<span class="_ _14"> </span> 2</div><div class="t m1 x1d h3 yc7 ffe fs2 fc1 sc0 ls0 ws0">Country and Capital Vectors Projected by PCA</div><div class="t m1 x61 hb y6c fff fs6 fc1 sc0 ls0 ws0">China</div><div class="t m1 x44 hb yc8 fff fs6 fc1 sc0 ls0 ws0">Japan</div><div class="t m1 x62 hb yc9 fff fs6 fc1 sc0 ls0 ws0">France</div><div class="t m1 x63 hb y77 fff fs6 fc1 sc0 ls0 ws0">Russia</div><div class="t m1 x64 hb yca fff fs6 fc1 sc0 ls0 ws0">Germany</div><div class="t m1 x1a hb ycb fff fs6 fc1 sc0 ls0 ws0">Italy</div><div class="t m1 x10 hb y87 fff fs6 fc1 sc0 ls0 ws0">Spain</div><div class="t m1 x42 hb ycc fff fs6 fc1 sc0 ls0 ws0">Greece</div><div class="t m1 x44 hb ycd fff fs6 fc1 sc0 ls0 ws0">Turkey</div><div class="t m1 x65 hb yce fff fs6 fc1 sc0 ls0 ws0">Beijing</div><div class="t m1 x66 hb yc2 fff fs6 fc1 sc0 ls0 ws0">Paris</div><div class="t m1 x4b hb ycf fff fs6 fc1 sc0 ls0 ws0">Tokyo</div><div class="t m1 x3 hb yd0 fff fs6 fc1 sc0 ls0 ws0">Poland</div><div class="t m1 x48 hb yd1 fff fs6 fc1 sc0 ls0 ws0">Moscow</div><div class="t m1 x5 hb y13 fff fs6 fc1 sc0 ls0 ws0">Portugal</div><div class="t m1 x47 hb y7 fff fs6 fc1 sc0 ls0 ws0">Berlin</div><div class="t m1 x4c hb yd2 fff fs6 fc1 sc0 ls0 ws0">Rome</div><div class="t m1 x66 hb yd3 fff fs6 fc1 sc0 ls0 ws0">Athens</div><div class="t m1 xd hb y89 fff fs6 fc1 sc0 ls0 ws0">Madrid</div><div class="t m1 x65 hb yd4 fff fs6 fc1 sc0 ls0 ws0">Ankara</div><div class="t m1 x66 hb y6 fff fs6 fc1 sc0 ls0 ws0">Warsaw</div><div class="t m1 x67 hb yd5 fff fs6 fc1 sc0 ls0 ws0">Lisbon</div><div class="t m1 x0 h4 yd6 ff1 fs2 fc1 sc0 ls0 ws0">Figure 2:<span class="_ _9"> </span><span class="fs5">T<span class="_ _4"></span>wo-dimensiona<span class="_ _5"></span>l P<span class="_ _2"></span>CA projec<span class="_ _5"></span>tion of the 1000-d<span class="_ _5"></span>imensional Skip-gram vectors of coun<span class="_ _5"></span>tries and their</span></div><div class="t m1 x0 ha y8f ff1 fs5 fc1 sc0 ls0 ws0">capital cities.<span class="_ _9"> </span>The ﬁgure illustrates ability of the mod<span class="_ _5"></span>el to automatically organize co<span class="_ _5"></span>ncepts and learn implicitly</div><div class="t m1 x0 ha yd7 ff1 fs5 fc1 sc0 ls0 ws0">the<span class="_ _9"> </span>relationships<span class="_ _7"> </span>between<span class="_ _9"> </span>them,<span class="_ _7"> </span>as<span class="_ _9"> </span>during<span class="_ _7"> </span>the<span class="_ _9"> </span>training<span class="_ _7"> </span>w<span class="_ _5"></span>e<span class="_ _9"> </span>did<span class="_ _7"> </span>not<span class="_ _9"> </span>provide<span class="_ _9"> </span>any<span class="_ _9"> </span>supervised<span class="_ _7"> </span>information<span class="_ _9"> </span>about</div><div class="t m1 x0 ha y1b ff1 fs5 fc1 sc0 ls0 ws0">what a capital city means.</div><div class="t m1 x0 h4 yd8 ff1 fs2 fc1 sc0 ls0 ws0">which<span class="_ _9"> </span>is<span class="_ _7"> </span>us<span class="_ _5"></span>ed<span class="_ _9"> </span>to<span class="_ _7"> </span>replace<span class="_ _9"> </span>ev<span class="_ _5"></span>ery<span class="_ _9"> </span><span class="ff8">log<span class="_ _11"> </span><span class="ff5">P<span class="_ _11"> </span></span>(<span class="ff5">w</span></span></div><div class="t m1 x9 hb y4c ff7 fs6 fc1 sc0 ls0 ws0">O</div><div class="t m1 x55 hc yd8 ffb fs2 fc1 sc0 ls0 ws0">|<span class="ff5">w</span></div><div class="t m1 x15 hb y4c ff7 fs6 fc1 sc0 ls0 ws0">I</div><div class="t m1 x7 h4 yd8 ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">term<span class="_ _9"> </span>in<span class="_ _7"> </span>the<span class="_ _9"> </span>Skip-g<span class="_ _2"></span>ram<span class="_ _9"> </span>objective.<span class="_ _0"> </span>Thu<span class="_ _2"></span>s th<span class="_ _2"></span>e<span class="_ _9"> </span>task<span class="_ _9"> </span>is<span class="_ _7"> </span>to</span></div><div class="t m1 x0 h4 yd9 ff1 fs2 fc1 sc0 ls0 ws0">distinguish the target word <span class="ff5">w</span></div><div class="t m1 x44 hb yda ff7 fs6 fc1 sc0 ls0 ws0">O</div><div class="t m1 x4f h4 yd9 ff1 fs2 fc1 sc0 ls0 ws0">from draws from th<span class="_ _2"></span>e noise distribution <span class="ff5">P</span></div><div class="t m1 xd hb yda ff7 fs6 fc1 sc0 ls0 ws0">n</div><div class="t m1 x65 h4 yd9 ff8 fs2 fc1 sc0 ls0 ws0">(<span class="ff5">w</span>)<span class="_ _9"> </span><span class="ff1">using<span class="_ _9"> </span>logistic regres-</span></div><div class="t m1 x0 h4 y20 ff1 fs2 fc1 sc0 ls0 ws0">sion, where there<span class="_ _6"> </span>are <span class="ff5">k<span class="_ _9"> </span></span>negativ<span class="_ _4"></span>e samples for<span class="_ _6"> </span>each data sample.<span class="_ _9"> </span>Our experiments<span class="_ _6"> </span>indicate that v<span class="_ _5"></span>alues</div><div class="t m1 x0 h4 y21 ff1 fs2 fc1 sc0 ls0 ws0">of <span class="ff5">k<span class="_ _9"> </span></span>in<span class="_ _9"> </span>the range 5–20 are usef<span class="_ _2"></span>ul for small train<span class="_ _2"></span>ing datasets, while for large datasets th<span class="_ _2"></span>e <span class="ff5">k<span class="_ _9"> </span></span>can be as</div><div class="t m1 x0 h4 y22 ff1 fs2 fc1 sc0 ls0 ws0">small as 2–5.<span class="_ _9"> </span>T<span class="_ _2"></span>he main dif<span class="_ _4"></span>fer<span class="_ _2"></span>ence between<span class="_ _6"> </span>the Negati<span class="_ _5"></span>ve<span class="_ _6"> </span>sampling and NCE is that<span class="_ _6"> </span>NCE needs both</div><div class="t m1 x0 h4 y23 ff1 fs2 fc1 sc0 ls0 ws0">samples<span class="_ _6"> </span>and the<span class="_ _6"> </span>numerical<span class="_ _6"> </span>probabilities<span class="_ _6"> </span>of t<span class="_ _5"></span>he noise<span class="_ _6"> </span>dist<span class="_ _5"></span>ribution,<span class="_ _6"> </span>while Ne<span class="_ _4"></span>g<span class="_ _2"></span>ativ<span class="_ _5"></span>e<span class="_ _6"> </span>sampling<span class="_ _6"> </span>uses<span class="_ _6"> </span>only</div><div class="t m1 x0 h4 y24 ff1 fs2 fc1 sc0 ls0 ws0">samples.<span class="_ _9"> </span>And while<span class="_ _6"> </span>NCE<span class="_ _6"> </span>approx<span class="_ _2"></span>imately<span class="_ _6"> </span>maximizes<span class="_ _6"> </span>the<span class="_ _6"> </span>log<span class="_ _6"> </span>probability<span class="_ _6"> </span>of<span class="_ _6"> </span>the<span class="_ _6"> </span>softmax, this<span class="_ _6"> </span>property</div><div class="t m1 x0 h4 ydb ff1 fs2 fc1 sc0 ls0 ws0">is not importan<span class="_ _2"></span>t for<span class="_ _6"> </span>our applica<span class="_ _2"></span>tion.</div><div class="t m1 x0 h4 ydc ff1 fs2 fc1 sc0 ls0 ws0">Both<span class="_ _6"> </span>NCE<span class="_ _11"> </span>and<span class="_ _6"> </span>NEG<span class="_ _11"> </span>have<span class="_ _11"> </span>the<span class="_ _6"> </span>noise<span class="_ _11"> </span>distribution<span class="_ _11"> </span><span class="ff5">P</span></div><div class="t m1 x68 hb ydd ff7 fs6 fc1 sc0 ls0 ws0">n</div><div class="t m1 x50 h4 ydc ff8 fs2 fc1 sc0 ls0 ws0">(<span class="ff5">w</span>)<span class="_ _6"> </span><span class="ff1">as<span class="_ _6"> </span>a<span class="_ _11"> </span>free<span class="_ _6"> </span>parameter<span class="_ _4"></span>.<span class="_ _9"> </span>W<span class="_ _3"></span>e<span class="_ _6"> </span>in<span class="_ _4"></span>vestigated<span class="_ _11"> </span>a<span class="_ _6"> </span>number</span></div><div class="t m1 x0 h4 yde ff1 fs2 fc1 sc0 ls0 ws0">of<span class="_ _9"> </span>choices for<span class="_ _9"> </span><span class="ff5">P</span></div><div class="t m1 x69 hb ydf ff7 fs6 fc1 sc0 ls0 ws0">n</div><div class="t m1 x1b h4 yde ff8 fs2 fc1 sc0 ls0 ws0">(<span class="ff5">w</span>)<span class="_ _9"> </span><span class="ff1">an<span class="_ _2"></span>d fou<span class="_ _2"></span>nd that<span class="_ _9"> </span>the un<span class="_ _2"></span>igram distribution <span class="ff5">U<span class="_ _d"> </span></span></span>(<span class="ff5">w</span>)<span class="_ _9"> </span><span class="ff1">raised<span class="_ _9"> </span>to<span class="_ _9"> </span>the </span>3<span class="ff5">/</span>4<span class="_ _2"></span><span class="ff1">rd power (i.e.,</span></div><div class="t m1 x0 hc ye0 ff5 fs2 fc1 sc0 ls0 ws0">U<span class="_ _d"></span><span class="ff8">(</span>w<span class="ff8">)</span></div><div class="t m1 x6 hb ye1 ff6 fs6 fc1 sc0 ls0 ws0">3<span class="ff7">/</span>4</div><div class="t m1 x16 h4 ye0 ff5 fs2 fc1 sc0 ls0 ws0">/<span class="_ _4"></span>Z<span class="_ _e"></span><span class="ff1">)<span class="_ _7"> </span>ou<span class="_ _2"></span>tperfor<span class="_ _2"></span>med<span class="_ _9"> </span>signiﬁcantly<span class="_ _7"> </span>the<span class="_ _7"> </span>unigram<span class="_ _7"> </span>and<span class="_ _7"> </span>the<span class="_ _7"> </span>uniform<span class="_ _7"> </span>distrib<span class="_ _4"></span>utio<span class="_ _2"></span>ns,<span class="_ _7"> </span>for<span class="_ _7"> </span>both<span class="_ _7"> </span>NCE</span></div><div class="t m1 x0 h4 ye2 ff1 fs2 fc1 sc0 ls0 ws0">and NEG on ev<span class="_ _5"></span>ery task we tried including language modeling (not reported here).</div><div class="t m1 x0 h3 ye3 ff2 fs2 fc1 sc0 ls0 ws0">2.3<span class="_ _12"> </span>Subsampling of Frequent W<span class="_ _3"></span>ords</div><div class="t m1 x0 h4 y59 ff1 fs2 fc1 sc0 ls0 ws0">In very large corpor<span class="_ _2"></span>a, the most fr<span class="_ _2"></span>equent words can easily o<span class="_ _2"></span>ccur hund<span class="_ _2"></span>reds of millions of<span class="_ _9"> </span>times (e.g<span class="_ _2"></span>.,</div><div class="t m1 x0 h4 ye4 ff1 fs2 fc1 sc0 ls0 ws0">“in”,<span class="_ _7"> </span>“the”,<span class="_ _9"> </span>and<span class="_ _9"> </span>“a”)<span class="_ _2"></span>.<span class="_ _8"> </span>Such<span class="_ _9"> </span>word<span class="_ _2"></span>s<span class="_ _9"> </span>usually<span class="_ _7"> </span>provide less<span class="_ _7"> </span>i<span class="_ _5"></span>nform<span class="_ _2"></span>ation value<span class="_ _9"> </span>than<span class="_ _7"> </span>the<span class="_ _9"> </span>rare<span class="_ _9"> </span>words.<span class="_ _8"> </span>For</div><div class="t m1 x0 h4 ye5 ff1 fs2 fc1 sc0 ls0 ws0">example,<span class="_ _7"> </span>while<span class="_ _9"> </span>the<span class="_ _7"> </span>Skip-gram<span class="_ _7"> </span>m<span class="_ _5"></span>odel<span class="_ _7"> </span>beneﬁts<span class="_ _9"> </span>f<span class="_ _2"></span>rom<span class="_ _9"> </span>o<span class="_ _2"></span>bserving<span class="_ _7"> </span>the<span class="_ _9"> </span>co-o<span class="_ _2"></span>ccurren<span class="_ _2"></span>ces<span class="_ _9"> </span>of<span class="_ _7"> </span>“<span class="_ _5"></span>France”<span class="_ _7"> </span>and</div><div class="t m1 x0 h4 ye6 ff1 fs2 fc1 sc0 ls0 ws0">“Paris”, it beneﬁts m<span class="_ _2"></span>uch less fro<span class="_ _2"></span>m observ<span class="_ _2"></span>ing the freque<span class="_ _2"></span>nt co-occurren<span class="_ _2"></span>ces<span class="_ _6"> </span>of “Franc<span class="_ _2"></span>e” and “the”,<span class="_ _9"> </span>as</div><div class="t m1 x0 h4 ye7 ff1 fs2 fc1 sc0 ls0 ws0">nearly every word co-occu<span class="_ _2"></span>rs frequen<span class="_ _2"></span>tly within a sen<span class="_ _2"></span>tence with<span class="_ _9"> </span>“the”.<span class="_ _0"> </span>This idea can<span class="_ _9"> </span>also be<span class="_ _9"> </span>applied</div><div class="t m1 x0 h4 ye8 ff1 fs2 fc1 sc0 ls0 ws0">in<span class="_ _7"> </span>the<span class="_ _9"> </span>opp<span class="_ _2"></span>osite<span class="_ _9"> </span>d<span class="_ _2"></span>irection;<span class="_ _7"> </span>the<span class="_ _7"> </span>v<span class="_ _5"></span>ector<span class="_ _9"> </span>r<span class="_ _2"></span>epresentation<span class="_ _2"></span>s<span class="_ _9"> </span>of<span class="_ _7"> </span>frequent<span class="_ _9"> </span>words<span class="_ _7"> </span>do<span class="_ _9"> </span>no<span class="_ _2"></span>t<span class="_ _9"> </span>c<span class="_ _2"></span>hange<span class="_ _7"> </span>s<span class="_ _4"></span>ig<span class="_ _2"></span>niﬁcantly</div><div class="t m1 x0 h4 ye9 ff1 fs2 fc1 sc0 ls0 ws0">after training on sev<span class="_ _5"></span>eral million examples.</div><div class="t m1 x0 h4 yea ff1 fs2 fc1 sc0 ls0 ws0">T<span class="_ _3"></span>o<span class="_ _7"> </span>counter the<span class="_ _7"> </span>imbalance between<span class="_ _7"> </span>t<span class="_ _5"></span>he<span class="_ _9"> </span>rare<span class="_ _9"> </span>and<span class="_ _7"> </span>frequent words,<span class="_ _9"> </span>we<span class="_ _7"> </span>used a<span class="_ _9"> </span>simp<span class="_ _2"></span>le<span class="_ _9"> </span>subsamp<span class="_ _2"></span>ling<span class="_ _9"> </span>ap-</div><div class="t m1 x0 h4 yeb ff1 fs2 fc1 sc0 ls0 ws0">proach<span class="_ _2"></span>:<span class="_ _9"> </span>each word <span class="ff5">w</span></div><div class="t m1 x64 hb yec ff7 fs6 fc1 sc0 ls0 ws0">i</div><div class="t m1 xe h4 yeb ff1 fs2 fc1 sc0 ls0 ws0">in the training set is discarded with probab<span class="_ _2"></span>ility<span class="_ _6"> </span>compu<span class="_ _2"></span>ted by the formula</div><div class="t m1 x52 hc yac ff5 fs2 fc1 sc0 ls0 ws0">P<span class="_ _d"> </span><span class="ff8">(</span>w</div><div class="t m1 x6a hb yb1 ff7 fs6 fc1 sc0 ls0 ws0">i</div><div class="t m1 x22 hc yac ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _9"> </span>=<span class="_ _9"> </span>1<span class="_ _6"> </span><span class="ffb">−</span></div><div class="t m1 x2f hd yed ff9 fs2 fc1 sc0 ls0 ws0"></div><div class="t m1 x59 hc yee ff5 fs2 fc1 sc0 ls0 ws0">t</div><div class="t m1 x31 hc yef ff5 fs2 fc1 sc0 ls0 ws0">f<span class="_ _d"></span><span class="ff8">(</span>w</div><div class="t m1 x24 hb yf0 ff7 fs6 fc1 sc0 ls0 ws0">i</div><div class="t m1 x28 hc yef ff8 fs2 fc1 sc0 ls0 ws0">)</div><div class="t m1 x37 h4 yac ff1 fs2 fc1 sc0 ls0 ws0">(5)</div><div class="t m1 x17 h4 y37 ff1 fs2 fc1 sc0 ls0 ws0">4</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf5" class="pf w0 h0" data-page-no="5"><div class="pc pc5 w0 h0"><img class="bi x0 y35 w5 h12" alt="" src="bg5.png"/><div class="t m1 x3d ha yf1 ff1 fs5 fc1 sc0 ls0 ws0">Method<span class="_ _15"> </span>T<span class="_ _4"></span>i<span class="_ _2"></span>me [min]<span class="_ _a"> </span>Syntactic [%]<span class="_ _a"> </span>Semantic [%]<span class="_ _a"> </span>T<span class="_ _4"></span>otal accurac<span class="_ _5"></span>y [%]</div><div class="t m1 x3d ha yf2 ff1 fs5 fc1 sc0 ls0 ws0">NEG-5<span class="_ _16"> </span>38<span class="_ _17"> </span>63<span class="_ _18"> </span>54<span class="_ _19"> </span>59</div><div class="t m1 x3d h13 yf3 ff1 fs5 fc1 sc0 ls0 ws0">NEG-15<span class="_ _1a"> </span>97<span class="_ _17"> </span>63<span class="_ _18"> </span>58<span class="_ _19"> </span><span class="ff2">61</span></div><div class="t m1 x3c ha yf4 ff1 fs5 fc1 sc0 ls0 ws0">HS-Huffman<span class="_ _1b"> </span>41<span class="_ _17"> </span>53<span class="_ _18"> </span>40<span class="_ _19"> </span>47</div><div class="t m1 x3d ha y72 ff1 fs5 fc1 sc0 ls0 ws0">NCE-5<span class="_ _1c"> </span>38<span class="_ _17"> </span>60<span class="_ _18"> </span>45<span class="_ _19"> </span>53</div><div class="t m1 x44 ha yf5 ff1 fs5 fc1 sc0 ls0 ws0">The followin<span class="_ _5"></span>g results use <span class="ff10">10</span></div><div class="t m1 x31 h14 y75 ff11 fs8 fc1 sc0 ls0 ws0">−<span class="ff12">5</span></div><div class="t m1 x6b ha yf5 ff1 fs5 fc1 sc0 ls0 ws0">subsampling</div><div class="t m1 x3d ha yf6 ff1 fs5 fc1 sc0 ls0 ws0">NEG-5<span class="_ _16"> </span>14<span class="_ _17"> </span>61<span class="_ _18"> </span>58<span class="_ _19"> </span>60</div><div class="t m1 x3d h13 y7c ff1 fs5 fc1 sc0 ls0 ws0">NEG-15<span class="_ _1a"> </span>36<span class="_ _17"> </span>61<span class="_ _18"> </span>61<span class="_ _19"> </span><span class="ff2">61</span></div><div class="t m1 x3c ha y7e ff1 fs5 fc1 sc0 ls0 ws0">HS-Huffman<span class="_ _1b"> </span>21<span class="_ _17"> </span>52<span class="_ _18"> </span>59<span class="_ _19"> </span>55</div><div class="t m1 x0 h4 yd0 ff1 fs2 fc1 sc0 ls0 ws0">T<span class="_ _3"></span>ab<span class="_ _2"></span>le<span class="_ _9"> </span>1:<span class="_ _0"> </span>Accuracy of<span class="_ _9"> </span>various<span class="_ _9"> </span>Skip-g<span class="_ _2"></span>ram 30<span class="_ _2"></span>0-dimen<span class="_ _2"></span>sional models<span class="_ _9"> </span>on<span class="_ _9"> </span>the<span class="_ _9"> </span>an<span class="_ _2"></span>alogical<span class="_ _9"> </span>reasoning<span class="_ _9"> </span>task</div><div class="t m1 x0 h4 y82 ff1 fs2 fc1 sc0 ls0 ws0">as<span class="_ _7"> </span>deﬁned<span class="_ _9"> </span>in<span class="_ _7"> </span>[8<span class="_ _5"></span>].<span class="_ _b"> </span>NEG-<span class="ff5">k<span class="_ _7"> </span></span>stands<span class="_ _7"> </span>for<span class="_ _9"> </span>Negati<span class="_ _5"></span>ve Sam<span class="_ _2"></span>pling<span class="_ _7"> </span>w<span class="_ _5"></span>ith<span class="_ _9"> </span><span class="ff5">k<span class="_ _0"> </span></span>ne<span class="_ _5"></span>gative samples<span class="_ _9"> </span>f<span class="_ _2"></span>or<span class="_ _7"> </span>each<span class="_ _9"> </span>positiv<span class="_ _4"></span>e</div><div class="t m1 x0 h4 yf7 ff1 fs2 fc1 sc0 ls0 ws0">sample;<span class="_ _9"> </span>NCE stand<span class="_ _2"></span>s for<span class="_ _9"> </span>Noise<span class="_ _9"> </span>Contrastive Estimation and HS-Huffman stands<span class="_ _9"> </span>for<span class="_ _9"> </span>the Hier<span class="_ _2"></span>archical</div><div class="t m1 x0 h4 yf8 ff1 fs2 fc1 sc0 ls0 ws0">Softmax with the frequ<span class="_ _2"></span>ency-based<span class="_ _6"> </span>Huffman<span class="_ _6"> </span>codes.</div><div class="t m1 x0 h4 y87 ff1 fs2 fc1 sc0 ls0 ws0">where<span class="_ _8"> </span><span class="ff5">f<span class="_ _d"></span><span class="ff8">(<span class="_ _4"></span><span class="ff5">w</span></span></span></div><div class="t m1 x4 hb yf9 ff7 fs6 fc1 sc0 ls0 ws0">i</div><div class="t m1 x6c h4 y87 ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _8"> </span><span class="ff1">i<span class="_ _4"></span>s<span class="_ _8"> </span>the<span class="_ _8"> </span>frequency<span class="_ _0"> </span>of<span class="_ _8"> </span>w<span class="_ _4"></span>o<span class="_ _2"></span>rd<span class="_ _8"> </span><span class="ff5">w</span></span></div><div class="t m1 x22 hb yf9 ff7 fs6 fc1 sc0 ls0 ws0">i</div><div class="t m1 x7 h4 y87 ff1 fs2 fc1 sc0 ls0 ws0">and<span class="_ _8"> </span><span class="ff5">t<span class="_ _0"> </span></span>is<span class="_ _8"> </span>a<span class="_ _0"> </span>chosen<span class="_ _8"> </span>threshold,<span class="_ _8"> </span>typically<span class="_ _8"> </span>a<span class="_ _5"></span>roun<span class="_ _2"></span>d<span class="_ _0"> </span><span class="ff8">10</span></div><div class="t m1 x37 hb y10 ffa fs6 fc1 sc0 ls0 ws0">−<span class="ff6">5</span></div><div class="t m1 x6d h4 y87 ff1 fs2 fc1 sc0 ls0 ws0">.</div><div class="t m1 x0 h4 yfa ff1 fs2 fc1 sc0 ls0 ws0">W<span class="_ _3"></span>e<span class="_ _0"> </span>ch<span class="_ _2"></span>ose<span class="_ _0"> </span>this<span class="_ _7"> </span>sub<span class="_ _2"></span>sampling<span class="_ _0"> </span>formula<span class="_ _0"> </span>because<span class="_ _0"> </span>it<span class="_ _0"> </span>a<span class="_ _5"></span>ggressively<span class="_ _7"> </span>subsamples<span class="_ _0"> </span>words<span class="_ _0"> </span>whose<span class="_ _0"> </span>f<span class="_ _5"></span>requen<span class="_ _2"></span>cy</div><div class="t m1 x0 h4 yfb ff1 fs2 fc1 sc0 ls0 ws0">is<span class="_ _7"> </span>greater<span class="_ _7"> </span>than<span class="_ _7"> </span><span class="ff5">t<span class="_ _7"> </span></span>w<span class="_ _5"></span>hile<span class="_ _7"> </span>preserving<span class="_ _7"> </span>the<span class="_ _7"> </span>ranking<span class="_ _7"> </span>of<span class="_ _9"> </span>th<span class="_ _2"></span>e<span class="_ _7"> </span>frequencie<span class="_ _2"></span>s.<span class="_ _1d"> </span>Although<span class="_ _7"> </span>this<span class="_ _7"> </span>subsampling<span class="_ _7"> </span>for<span class="_ _4"></span>-</div><div class="t m1 x0 h4 yfc ff1 fs2 fc1 sc0 ls0 ws0">mula was<span class="_ _6"> </span>chosen heuristically<span class="_ _4"></span>, we<span class="_ _6"> </span>foun<span class="_ _2"></span>d<span class="_ _6"> </span>it to work<span class="_ _6"> </span>well in practice.<span class="_ _9"> </span>It accelerates learning and e<span class="_ _4"></span>ven</div><div class="t m1 x0 h4 yfd ff1 fs2 fc1 sc0 ls0 ws0">signiﬁcantly improves t<span class="_ _5"></span>he accuracy of the learned vectors<span class="_ _6"> </span>of the rar<span class="_ _2"></span>e words,<span class="_ _6"> </span>as will be shown in the</div><div class="t m1 x0 h4 yfe ff1 fs2 fc1 sc0 ls0 ws0">following sections.</div><div class="t m1 x0 h6 y8e ff2 fs3 fc1 sc0 ls0 ws0">3<span class="_ _a"> </span>Empirical Results</div><div class="t m1 x0 h4 yff ff1 fs2 fc1 sc0 ls0 ws0">In<span class="_ _9"> </span>this<span class="_ _9"> </span>section<span class="_ _9"> </span>we<span class="_ _9"> </span>ev<span class="_ _4"></span>alu<span class="_ _2"></span>ate the<span class="_ _9"> </span>Hier<span class="_ _2"></span>archical<span class="_ _9"> </span>Softmax<span class="_ _9"> </span>(HS),<span class="_ _9"> </span>Noise<span class="_ _9"> </span>Contrastive Estimation,<span class="_ _9"> </span>Negativ<span class="_ _5"></span>e</div><div class="t m1 x0 h4 y49 ff1 fs2 fc1 sc0 ls0 ws0">Sampling,<span class="_ _6"> </span>and<span class="_ _6"> </span>s<span class="_ _5"></span>ubsampling<span class="_ _6"> </span>of<span class="_ _11"> </span>the<span class="_ _6"> </span>training<span class="_ _11"> </span>word<span class="_ _2"></span>s.<span class="_ _9"> </span>W<span class="_ _3"></span>e<span class="_ _6"> </span>used<span class="_ _11"> </span>the<span class="_ _6"> </span>analogical<span class="_ _11"> </span>r<span class="_ _2"></span>easoning<span class="_ _6"> </span>task</div><div class="t m1 x6e h15 y93 ff1 fs6 fc1 sc0 ls0 ws0">1</div><div class="t m1 x6f h4 y49 ff1 fs2 fc1 sc0 ls0 ws0">introdu<span class="_ _2"></span>ced</div><div class="t m1 x0 h4 y4a ff1 fs2 fc1 sc0 ls0 ws0">by Mikolov et<span class="_ _9"> </span>al. [<span class="_ _2"></span>8].<span class="_ _0"> </span>The task c<span class="_ _2"></span>onsists of<span class="_ _9"> </span>analog<span class="_ _2"></span>ies such as<span class="_ _9"> </span>“Germany” :<span class="_ _0"> </span>“<span class="_ _5"></span>Berlin”<span class="_ _9"> </span>::<span class="_ _7"> </span>“France”<span class="_ _9"> </span>:<span class="_ _7"> </span>?,</div><div class="t m1 x0 h4 y100 ff1 fs2 fc1 sc0 ls0 ws0">which<span class="_ _6"> </span>are<span class="_ _6"> </span>solved by<span class="_ _6"> </span>ﬁ<span class="_ _5"></span>nding a<span class="_ _6"> </span>v<span class="_ _5"></span>ector<span class="_ _6"> </span><span class="ff13">x<span class="_ _6"> </span></span>such that<span class="_ _6"> </span>vec(<span class="ff13">x</span>)<span class="_ _6"> </span>is<span class="_ _6"> </span>closest<span class="_ _6"> </span>to<span class="_ _6"> </span>vec(“Berlin”)<span class="_ _6"> </span>-<span class="_ _6"> </span>vec(“Germany”)</div><div class="t m1 x0 h4 y4c ff1 fs2 fc1 sc0 ls0 ws0">+ v<span class="_ _5"></span>ec(“France<span class="_ _2"></span>”)<span class="_ _6"> </span>according<span class="_ _6"> </span>to the<span class="_ _6"> </span>cosine distance<span class="_ _6"> </span>(we discard<span class="_ _6"> </span>the input<span class="_ _6"> </span>words from<span class="_ _6"> </span>the search).<span class="_ _9"> </span>This</div><div class="t m1 x0 h4 yda ff1 fs2 fc1 sc0 ls0 ws0">speciﬁc<span class="_ _7"> </span>example<span class="_ _9"> </span>is<span class="_ _7"> </span>co<span class="_ _2"></span>nsidered<span class="_ _7"> </span>to<span class="_ _7"> </span>ha<span class="_ _4"></span>ve<span class="_ _7"> </span>been<span class="_ _7"> </span>answered<span class="_ _7"> </span>correctly<span class="_ _9"> </span>if<span class="_ _7"> </span><span class="ff13">x<span class="_ _7"> </span></span>is<span class="_ _7"> </span>“Paris”.<span class="_ _1d"> </span>Th<span class="_ _2"></span>e<span class="_ _7"> </span>task<span class="_ _7"> </span>has<span class="_ _9"> </span>two</div><div class="t m1 x0 h4 y101 ff1 fs2 fc1 sc0 ls0 ws0">broad categories:<span class="_ _7"> </span>the syntactic an<span class="_ _2"></span>alogies (such as<span class="_ _9"> </span>“quick” :<span class="_ _7"> </span>“quickly<span class="_ _2"></span>” ::<span class="_ _7"> </span>“slo<span class="_ _5"></span>w” :<span class="_ _7"> </span>“slowly”) and the</div><div class="t m1 x0 h4 y102 ff1 fs2 fc1 sc0 ls0 ws0">semantic analogies, such as the country to capital city relationship.</div><div class="t m1 x0 h4 y50 ff1 fs2 fc1 sc0 ls0 ws0">For training the Skip<span class="_ _2"></span>-gram models, we have used a large dataset con<span class="_ _2"></span>sisting of various news articles</div><div class="t m1 x0 h4 y51 ff1 fs2 fc1 sc0 ls0 ws0">(an<span class="_ _7"> </span>internal<span class="_ _7"> </span>G<span class="_ _5"></span>oogle<span class="_ _7"> </span>dataset<span class="_ _9"> </span>with<span class="_ _7"> </span>on<span class="_ _2"></span>e<span class="_ _9"> </span>b<span class="_ _2"></span>illion<span class="_ _7"> </span>words).<span class="_ _b"> </span>W<span class="_ _4"></span>e<span class="_ _7"> </span>discarded<span class="_ _9"> </span>f<span class="_ _2"></span>rom<span class="_ _7"> </span>the<span class="_ _9"> </span>vocabulary<span class="_ _9"> </span>all<span class="_ _7"> </span>words</div><div class="t m1 x0 h4 y52 ff1 fs2 fc1 sc0 ls0 ws0">that<span class="_ _7"> </span>occurred<span class="_ _7"> </span>less<span class="_ _7"> </span>than<span class="_ _7"> </span>5<span class="_ _7"> </span>times<span class="_ _7"> </span>in<span class="_ _7"> </span>the<span class="_ _7"> </span>training<span class="_ _7"> </span>data,<span class="_ _7"> </span>wh<span class="_ _2"></span>ich<span class="_ _7"> </span>resulted<span class="_ _7"> </span>in<span class="_ _7"> </span>a<span class="_ _7"> </span>vocab<span class="_ _5"></span>ulary<span class="_ _7"> </span>of<span class="_ _7"> </span>size<span class="_ _7"> </span>692K.</div><div class="t m1 x0 h4 y53 ff1 fs2 fc1 sc0 ls0 ws0">The<span class="_ _9"> </span>perfo<span class="_ _2"></span>rmance<span class="_ _9"> </span>of<span class="_ _9"> </span>various Skip-g<span class="_ _2"></span>ram<span class="_ _9"> </span>models<span class="_ _9"> </span>on<span class="_ _9"> </span>the<span class="_ _9"> </span>word<span class="_ _9"> </span>an<span class="_ _2"></span>alogy test<span class="_ _7"> </span>set is<span class="_ _7"> </span>r<span class="_ _5"></span>eported<span class="_ _9"> </span>in<span class="_ _9"> </span>T<span class="_ _4"></span>able<span class="_ _9"> </span>1.</div><div class="t m1 x0 h4 ydd ff1 fs2 fc1 sc0 ls0 ws0">The<span class="_ _7"> </span>table<span class="_ _7"> </span>shows<span class="_ _7"> </span>that<span class="_ _7"> </span>Negati<span class="_ _4"></span>ve<span class="_ _7"> </span>Sampling<span class="_ _7"> </span>outpe<span class="_ _2"></span>rforms<span class="_ _7"> </span>the<span class="_ _7"> </span>Hierarchica<span class="_ _2"></span>l<span class="_ _7"> </span>S<span class="_ _5"></span>oftmax<span class="_ _7"> </span>on<span class="_ _0"> </span>t<span class="_ _4"></span>h<span class="_ _2"></span>e<span class="_ _7"> </span>analog<span class="_ _2"></span>ical</div><div class="t m1 x0 h4 ydf ff1 fs2 fc1 sc0 ls0 ws0">reasoning task,<span class="_ _6"> </span>and has<span class="_ _6"> </span>e<span class="_ _4"></span>ven slightly<span class="_ _6"> </span>better<span class="_ _6"> </span>perfor<span class="_ _2"></span>mance<span class="_ _6"> </span>than<span class="_ _6"> </span>the Noise<span class="_ _6"> </span>Contrasti<span class="_ _5"></span>ve<span class="_ _6"> </span>Estimation.<span class="_ _9"> </span>The</div><div class="t m1 x0 h4 ye0 ff1 fs2 fc1 sc0 ls0 ws0">subsampling<span class="_ _7"> </span>of<span class="_ _9"> </span>the<span class="_ _7"> </span>frequent<span class="_ _9"> </span>words<span class="_ _7"> </span>i<span class="_ _5"></span>mproves<span class="_ _9"> </span>the<span class="_ _7"> </span>training<span class="_ _9"> </span>speed<span class="_ _7"> </span>se<span class="_ _4"></span>veral<span class="_ _7"> </span>t<span class="_ _4"></span>im<span class="_ _2"></span>es<span class="_ _7"> </span>and<span class="_ _9"> </span>makes<span class="_ _7"> </span>t<span class="_ _5"></span>he<span class="_ _7"> </span>w<span class="_ _4"></span>o<span class="_ _2"></span>rd</div><div class="t m1 x0 h4 ye2 ff1 fs2 fc1 sc0 ls0 ws0">representatio<span class="_ _2"></span>ns<span class="_ _6"> </span>signiﬁcantly more accurate.</div><div class="t m1 x0 h4 y3a ff1 fs2 fc1 sc0 ls0 ws0">It<span class="_ _9"> </span>can<span class="_ _9"> </span>be<span class="_ _9"> </span>argu<span class="_ _2"></span>ed th<span class="_ _2"></span>at<span class="_ _9"> </span>the<span class="_ _9"> </span>linear<span class="_ _2"></span>ity of<span class="_ _9"> </span>th<span class="_ _2"></span>e<span class="_ _9"> </span>skip-g<span class="_ _2"></span>ram mo<span class="_ _2"></span>del<span class="_ _9"> </span>makes<span class="_ _9"> </span>its<span class="_ _9"> </span>vectors<span class="_ _9"> </span>more<span class="_ _9"> </span>suitable<span class="_ _9"> </span>fo<span class="_ _2"></span>r<span class="_ _9"> </span>such</div><div class="t m1 x0 h4 y103 ff1 fs2 fc1 sc0 ls0 ws0">linear<span class="_ _9"> </span>an<span class="_ _2"></span>alogical<span class="_ _9"> </span>reason<span class="_ _2"></span>ing,<span class="_ _9"> </span>but<span class="_ _9"> </span>the<span class="_ _7"> </span>results o<span class="_ _2"></span>f<span class="_ _9"> </span>Mikolov<span class="_ _9"> </span>et<span class="_ _9"> </span>al.<span class="_ _7"> </span>[8]<span class="_ _9"> </span>also<span class="_ _9"> </span>show<span class="_ _9"> </span>that<span class="_ _7"> </span>t<span class="_ _5"></span>he<span class="_ _9"> </span>vectors<span class="_ _7"> </span>l<span class="_ _5"></span>earned</div><div class="t m1 x0 h4 y104 ff1 fs2 fc1 sc0 ls0 ws0">by<span class="_ _9"> </span>the<span class="_ _9"> </span>standar<span class="_ _2"></span>d sigmoid<span class="_ _2"></span>al recu<span class="_ _2"></span>rrent<span class="_ _9"> </span>neural<span class="_ _9"> </span>networks<span class="_ _9"> </span>(which<span class="_ _9"> </span>are<span class="_ _9"> </span>highly<span class="_ _9"> </span>non-linear<span class="_ _2"></span>) improve on<span class="_ _9"> </span>this</div><div class="t m1 x0 h4 y105 ff1 fs2 fc1 sc0 ls0 ws0">task<span class="_ _6"> </span>signiﬁcantly<span class="_ _6"> </span>as<span class="_ _6"> </span>the<span class="_ _6"> </span>amount<span class="_ _6"> </span>of<span class="_ _6"> </span>the<span class="_ _11"> </span>tr<span class="_ _2"></span>aining<span class="_ _6"> </span>data<span class="_ _6"> </span>increases,<span class="_ _6"> </span>suggesting<span class="_ _6"> </span>that<span class="_ _6"> </span>non-linear<span class="_ _6"> </span>models<span class="_ _11"> </span>a<span class="_ _2"></span>lso</div><div class="t m1 x0 h4 y106 ff1 fs2 fc1 sc0 ls0 ws0">have<span class="_ _6"> </span>a preferenc<span class="_ _2"></span>e<span class="_ _6"> </span>for a linear structure of the word representations.</div><div class="t m1 x0 h6 y107 ff2 fs3 fc1 sc0 ls0 ws0">4<span class="_ _a"> </span>Learn<span class="_ _5"></span>ing Phrases</div><div class="t m1 x0 h4 ye9 ff1 fs2 fc1 sc0 ls0 ws0">As<span class="_ _7"> </span>discussed<span class="_ _9"> </span>earlier,<span class="_ _9"> </span>many<span class="_ _7"> </span>phrases<span class="_ _9"> </span>have<span class="_ _9"> </span>a<span class="_ _7"> </span>meaning<span class="_ _7"> </span>t<span class="_ _5"></span>hat<span class="_ _7"> </span>i<span class="_ _5"></span>s<span class="_ _7"> </span>not<span class="_ _9"> </span>a<span class="_ _7"> </span>simple<span class="_ _7"> </span>c<span class="_ _5"></span>omposition<span class="_ _7"> </span>of<span class="_ _9"> </span>the<span class="_ _7"> </span>mean-</div><div class="t m1 x0 h4 y61 ff1 fs2 fc1 sc0 ls0 ws0">ings<span class="_ _0"> </span>of<span class="_ _7"> </span>its<span class="_ _0"> </span>i<span class="_ _5"></span>ndividual<span class="_ _7"> </span>words.<span class="_ _10"> </span>T<span class="_ _1"></span>o<span class="_ _0"> </span>l<span class="_ _5"></span>earn<span class="_ _0"> </span>v<span class="_ _4"></span>ecto<span class="_ _2"></span>r<span class="_ _7"> </span>represen<span class="_ _2"></span>tation<span class="_ _7"> </span>for<span class="_ _0"> </span>phrases,<span class="_ _0"> </span>we<span class="_ _7"> </span>ﬁrst<span class="_ _0"> </span>ﬁnd<span class="_ _7"> </span>words<span class="_ _7"> </span>th<span class="_ _2"></span>at</div><div class="t m1 x0 h4 y108 ff1 fs2 fc1 sc0 ls0 ws0">appear frequently together<span class="_ _4"></span>, and<span class="_ _6"> </span>infrequ<span class="_ _2"></span>ently<span class="_ _6"> </span>in<span class="_ _6"> </span>other contexts.<span class="_ _9"> </span>For e<span class="_ _4"></span>x<span class="_ _2"></span>ample, “Ne<span class="_ _4"></span>w Y<span class="_ _1"></span>or<span class="_ _2"></span>k T<span class="_ _4"></span>imes” and</div><div class="t m1 x0 h4 y109 ff1 fs2 fc1 sc0 ls0 ws0">“T<span class="_ _3"></span>o<span class="_ _2"></span>ronto<span class="_ _9"> </span>Maple Lea<span class="_ _2"></span>fs”<span class="_ _9"> </span>are r<span class="_ _2"></span>eplaced<span class="_ _9"> </span>by<span class="_ _9"> </span>unique to<span class="_ _2"></span>kens in<span class="_ _9"> </span>the<span class="_ _9"> </span>tra<span class="_ _2"></span>ining<span class="_ _9"> </span>data,<span class="_ _9"> </span>while<span class="_ _9"> </span>a<span class="_ _9"> </span>bigram<span class="_ _9"> </span>“this<span class="_ _9"> </span>is”</div><div class="t m1 x0 h4 y10a ff1 fs2 fc1 sc0 ls0 ws0">will remain unchang<span class="_ _2"></span>ed.</div><div class="t m1 x2 h16 y10b ff1 fs8 fc1 sc0 ls0 ws0">1</div><div class="t m1 x40 hc y36 ff3 fs5 fc1 sc0 ls0 ws0">code.google.c<span class="_ _2"></span>om/p/word2vec<span class="_ _2"></span>/source/brows<span class="_ _2"></span>e/trunk/questions-<span class="_ _2"></span>w<span class="_ _2"></span>ords.txt</div><div class="t m1 x17 h4 y37 ff1 fs2 fc1 sc0 ls0 ws0">5</div><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,492.159,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:164.464000px;bottom:582.544000px;width:5.912000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf5" data-dest-detail='[5,"XYZ",124.275,59.6931,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:454.024000px;bottom:404.344000px;width:3.956000px;height:8.962000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,492.159,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:181.504000px;bottom:393.304000px;width:6.032000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf5" data-dest-detail='[5,"XYZ",144.631,594.612,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:495.064000px;bottom:288.784000px;width:5.912000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,492.159,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:354.544000px;bottom:216.904000px;width:5.912000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="code.google.com/p/word2vec/source/browse/trunk/questions-words.txt"><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,255);position:absolute;left:122.584000px;bottom:59.223800px;width:356.672000px;height:8.312500px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf6" class="pf w0 h0" data-page-no="6"><div class="pc pc6 w0 h0"><img class="bi x0 y3e w6 h17" alt="" src="bg6.png"/><div class="t m1 x15 ha yf1 ff1 fs5 fc1 sc0 ls0 ws0">Ne<span class="_ _5"></span>wspapers</div><div class="t m1 x70 ha yf2 ff1 fs5 fc1 sc0 ls0 ws0">Ne<span class="_ _5"></span>w Y<span class="_ _3"></span>ork<span class="_ _1e"> </span>Ne<span class="_ _5"></span>w Y<span class="_ _3"></span>ork Times<span class="_ _1f"> </span>Baltimore<span class="_ _13"> </span>Baltimore Sun</div><div class="t m1 x3d ha yf3 ff1 fs5 fc1 sc0 ls0 ws0">San Jose<span class="_ _20"> </span>San Jose Mercury Ne<span class="_ _5"></span>ws<span class="_ _21"> </span>Cincinnati<span class="_ _22"> </span>Cincinnati Enquirer</div><div class="t m1 x15 ha yce ff1 fs5 fc1 sc0 ls0 ws0">NHL T<span class="_ _4"></span>eams</div><div class="t m1 x10 ha y10c ff1 fs5 fc1 sc0 ls0 ws0">Boston<span class="_ _23"> </span>Boston Bruins<span class="_ _24"> </span>Montreal<span class="_ _21"> </span>Montreal<span class="_ _9"> </span>C<span class="_ _5"></span>anadiens</div><div class="t m1 x71 ha y10d ff1 fs5 fc1 sc0 ls0 ws0">Phoenix<span class="_ _25"> </span>Phoenix Coyotes<span class="_ _1a"> </span>Nashville<span class="_ _26"> </span>Nashville Predators</div><div class="t m1 x15 ha y10e ff1 fs5 fc1 sc0 ls0 ws0">NB<span class="_ _4"></span>A<span class="_ _9"> </span>T<span class="_ _3"></span>eams</div><div class="t m1 x10 ha y7c ff1 fs5 fc1 sc0 ls0 ws0">Detroit<span class="_ _27"> </span>Detroit Pistons<span class="_ _28"> </span>T<span class="_ _4"></span>oronto<span class="_ _14"> </span>T<span class="_ _3"></span>oronto R<span class="_ _2"></span>aptors</div><div class="t m1 x3d ha y7e ff1 fs5 fc1 sc0 ls0 ws0">Oakland<span class="_ _29"> </span>Golden State W<span class="_ _4"></span>arriors<span class="_ _2a"> </span>Memphis<span class="_ _2b"> </span>Memphis Grizzlies</div><div class="t m1 x56 ha y7f ff1 fs5 fc1 sc0 ls0 ws0">Airlines</div><div class="t m1 x72 ha y10f ff1 fs5 fc1 sc0 ls0 ws0">Austria<span class="_ _2c"> </span>Austrian Airlines<span class="_ _28"> </span>S<span class="_ _4"></span>pain<span class="_ _2d"> </span>Spainair</div><div class="t m1 x3d ha y110 ff1 fs5 fc1 sc0 ls0 ws0">Belgium<span class="_ _2e"> </span>Brussels Airlines<span class="_ _2f"> </span>Greece<span class="_ _30"> </span>Aegean Airlines</div><div class="t m1 x2d ha yca ff1 fs5 fc1 sc0 ls0 ws0">Compan<span class="_ _5"></span>y executi<span class="_ _4"></span>ves</div><div class="t m1 x3c ha y111 ff1 fs5 fc1 sc0 ls0 ws0">Stev<span class="_ _4"></span>e Ballmer<span class="_ _2d"> </span>Microsoft<span class="_ _2e"> </span>Larry Page<span class="_ _24"> </span>Google</div><div class="t m1 x16 ha y7 ff1 fs5 fc1 sc0 ls0 ws0">Samuel J. Palmisano<span class="_ _31"> </span>IBM<span class="_ _32"> </span>W<span class="_ _4"></span>erner<span class="_ _6"> </span>V<span class="_ _1"></span>ogels<span class="_ _30"> </span>Amazon</div><div class="t m1 x0 h4 ycc ff1 fs2 fc1 sc0 ls0 ws0">T<span class="_ _3"></span>ab<span class="_ _2"></span>le<span class="_ _6"> </span>2:<span class="_ _c"> </span>Examples<span class="_ _6"> </span>of<span class="_ _6"> </span>the analogical<span class="_ _11"> </span>r<span class="_ _2"></span>easoning<span class="_ _6"> </span>task<span class="_ _6"> </span>for<span class="_ _6"> </span>phrases<span class="_ _6"> </span>(the full<span class="_ _6"> </span>t<span class="_ _5"></span>est s<span class="_ _5"></span>et<span class="_ _6"> </span>has<span class="_ _6"> </span>3218<span class="_ _6"> </span>examples).</div><div class="t m1 x0 h4 y112 ff1 fs2 fc1 sc0 ls0 ws0">The goal is<span class="_ _9"> </span>to compu<span class="_ _2"></span>te the fourth phrase using the ﬁrst<span class="_ _9"> </span>three.<span class="_ _7"> </span>Our best model achieved an accuracy</div><div class="t m1 x0 h4 y113 ff1 fs2 fc1 sc0 ls0 ws0">of 72% on this dataset.</div><div class="t m1 x0 h4 yfd ff1 fs2 fc1 sc0 ls0 ws0">This<span class="_ _9"> </span>way<span class="_ _4"></span>, we<span class="_ _9"> </span>can<span class="_ _9"> </span>for<span class="_ _2"></span>m many<span class="_ _9"> </span>reasonable<span class="_ _9"> </span>phrases with<span class="_ _2"></span>out<span class="_ _9"> </span>greatly<span class="_ _9"> </span>increasing th<span class="_ _2"></span>e<span class="_ _9"> </span>size<span class="_ _9"> </span>of th<span class="_ _2"></span>e<span class="_ _9"> </span>vocab<span class="_ _5"></span>u-</div><div class="t m1 x0 h4 yfe ff1 fs2 fc1 sc0 ls0 ws0">lary; in<span class="_ _9"> </span>theo<span class="_ _2"></span>ry<span class="_ _4"></span>, we can<span class="_ _9"> </span>train th<span class="_ _2"></span>e Skip<span class="_ _2"></span>-gram model u<span class="_ _2"></span>sing all<span class="_ _9"> </span>n-gr<span class="_ _2"></span>ams, but that would be<span class="_ _9"> </span>too m<span class="_ _2"></span>emory</div><div class="t m1 x0 h4 y114 ff1 fs2 fc1 sc0 ls0 ws0">intensive. Many techniques<span class="_ _6"> </span>ha<span class="_ _5"></span>ve<span class="_ _6"> </span>been pre<span class="_ _4"></span>v<span class="_ _2"></span>iously<span class="_ _6"> </span>developed<span class="_ _11"> </span>to identify phrases<span class="_ _6"> </span>in the<span class="_ _6"> </span>text;<span class="_ _6"> </span>howe<span class="_ _4"></span>ver,</div><div class="t m1 x0 h4 y115 ff1 fs2 fc1 sc0 ls0 ws0">it<span class="_ _9"> </span>is<span class="_ _9"> </span>o<span class="_ _2"></span>ut<span class="_ _9"> </span>of<span class="_ _9"> </span>sco<span class="_ _2"></span>pe<span class="_ _9"> </span>of<span class="_ _9"> </span>our<span class="_ _9"> </span>work<span class="_ _9"> </span>to<span class="_ _7"> </span>compare th<span class="_ _2"></span>em.<span class="_ _8"> </span>W<span class="_ _1"></span>e<span class="_ _7"> </span>decided<span class="_ _9"> </span>to<span class="_ _9"> </span>use<span class="_ _9"> </span>a<span class="_ _9"> </span>simple<span class="_ _7"> </span>data-driv<span class="_ _5"></span>en appr<span class="_ _2"></span>oach,</div><div class="t m1 x0 h4 y116 ff1 fs2 fc1 sc0 ls0 ws0">where phrases are formed based on the unigra<span class="_ _2"></span>m<span class="_ _6"> </span>and bigram coun<span class="_ _2"></span>ts, using</div><div class="t m1 x63 h4 y48 ff1 fs2 fc1 sc0 ls0 ws0">score<span class="ff8">(<span class="ff5">w</span></span></div><div class="t m1 x20 hb yff ff7 fs6 fc1 sc0 ls0 ws0">i</div><div class="t m1 x52 hc y48 ff5 fs2 fc1 sc0 ls0 ws0">,<span class="_ _11"> </span>w</div><div class="t m1 x2d hb yff ff7 fs6 fc1 sc0 ls0 ws0">j</div><div class="t m1 x55 hc y48 ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _9"> </span>=</div><div class="t m1 x17 h4 y117 ff1 fs2 fc1 sc0 ls0 ws0">count<span class="ff8">(<span class="ff5">w</span></span></div><div class="t m1 x59 hb y118 ff7 fs6 fc1 sc0 ls0 ws0">i</div><div class="t m1 x6b hc y117 ff5 fs2 fc1 sc0 ls0 ws0">w</div><div class="t m1 x73 hb y118 ff7 fs6 fc1 sc0 ls0 ws0">j</div><div class="t m1 x14 hc y117 ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _6"> </span><span class="ffb">−<span class="_ _6"> </span><span class="ff5">δ</span></span></div><div class="t m1 x74 h4 y1b ff1 fs2 fc1 sc0 ls0 ws0">count<span class="ff8">(<span class="ff5">w</span></span></div><div class="t m1 x75 hb y93 ff7 fs6 fc1 sc0 ls0 ws0">i</div><div class="t m1 x31 h4 y1b ff8 fs2 fc1 sc0 ls0 ws0">)<span class="_ _6"> </span><span class="ffb">×<span class="_ _6"> </span><span class="ff1">cou<span class="_ _2"></span>nt</span></span>(<span class="ff5">w</span></div><div class="t m1 x3e hb y93 ff7 fs6 fc1 sc0 ls0 ws0">j</div><div class="t m1 x67 hc y1b ff8 fs2 fc1 sc0 ls0 ws0">)</div><div class="t m1 x5b h4 y48 ff5 fs2 fc1 sc0 ls0 ws0">.<span class="_ _33"> </span><span class="ff1">(6)</span></div><div class="t m1 x0 h4 y119 ff1 fs2 fc1 sc0 ls0 ws0">The<span class="_ _7"> </span><span class="ff5">δ<span class="_ _7"> </span></span>is<span class="_ _9"> </span>used<span class="_ _7"> </span>as<span class="_ _9"> </span>a<span class="_ _7"> </span>discounting<span class="_ _9"> </span>coefﬁcient<span class="_ _9"> </span>and<span class="_ _7"> </span>pre<span class="_ _4"></span>vents<span class="_ _9"> </span>to<span class="_ _2"></span>o<span class="_ _9"> </span>many<span class="_ _7"> </span>phrases<span class="_ _9"> </span>consisting<span class="_ _7"> </span>of<span class="_ _9"> </span>very<span class="_ _9"> </span>in<span class="_ _2"></span>fre-</div><div class="t m1 x0 h4 y100 ff1 fs2 fc1 sc0 ls0 ws0">quent<span class="_ _7"> </span>words<span class="_ _7"> </span>to<span class="_ _0"> </span>be<span class="_ _7"> </span>formed.<span class="_ _34"> </span>The<span class="_ _7"> </span>bigr<span class="_ _2"></span>ams<span class="_ _7"> </span>with<span class="_ _7"> </span>score<span class="_ _0"> </span>abov<span class="_ _5"></span>e<span class="_ _7"> </span>the<span class="_ _7"> </span>chosen<span class="_ _7"> </span>thr<span class="_ _2"></span>eshold<span class="_ _7"> </span>are<span class="_ _7"> </span>then<span class="_ _0"> </span>used<span class="_ _7"> </span>as</div><div class="t m1 x0 h4 y11a ff1 fs2 fc1 sc0 ls0 ws0">phrases.<span class="_ _7"> </span>T<span class="_ _3"></span>y<span class="_ _2"></span>pically<span class="_ _4"></span>, we run<span class="_ _9"> </span>2-4 passes over the training data with<span class="_ _9"> </span>decreasing thre<span class="_ _2"></span>shold value, allo<span class="_ _4"></span>w<span class="_ _2"></span>-</div><div class="t m1 x0 h4 yda ff1 fs2 fc1 sc0 ls0 ws0">ing longer<span class="_ _6"> </span>phrases that<span class="_ _6"> </span>consists of s<span class="_ _5"></span>ev<span class="_ _5"></span>eral words<span class="_ _6"> </span>to<span class="_ _6"> </span>be formed.<span class="_ _9"> </span>W<span class="_ _4"></span>e<span class="_ _6"> </span>ev<span class="_ _4"></span>alu<span class="_ _2"></span>ate<span class="_ _6"> </span>the quality of<span class="_ _6"> </span>the phrase</div><div class="t m1 x0 h4 y101 ff1 fs2 fc1 sc0 ls0 ws0">representatio<span class="_ _2"></span>ns<span class="_ _11"> </span>using a<span class="_ _11"> </span>n<span class="_ _2"></span>ew<span class="_ _11"> </span>an<span class="_ _2"></span>alogical<span class="_ _6"> </span>reasoning<span class="_ _6"> </span>task<span class="_ _11"> </span>th<span class="_ _2"></span>at<span class="_ _6"> </span>in<span class="_ _4"></span>volves<span class="_ _11"> </span>ph<span class="_ _2"></span>rases.<span class="_ _9"> </span>T<span class="_ _4"></span>able<span class="_ _6"> </span>2<span class="_ _6"> </span>s<span class="_ _5"></span>hows<span class="_ _11"> </span>exam<span class="_ _2"></span>ples</div><div class="t m1 x0 h4 y102 ff1 fs2 fc1 sc0 ls0 ws0">of the ﬁ<span class="_ _5"></span>ve categories<span class="_ _6"> </span>of analog<span class="_ _2"></span>ies used in this t<span class="_ _5"></span>ask.<span class="_ _7"> </span>This dataset is publicly a<span class="_ _4"></span>vailable on the web</div><div class="t m1 x76 h15 y11b ff1 fs6 fc1 sc0 ls0 ws0">2</div><div class="t m1 x77 h4 y102 ff1 fs2 fc1 sc0 ls0 ws0">.</div><div class="t m1 x0 h3 y11c ff2 fs2 fc1 sc0 ls0 ws0">4.1<span class="_ _12"> </span>Phrase Skip-Gram Results</div><div class="t m1 x0 h4 ya2 ff1 fs2 fc1 sc0 ls0 ws0">Starting<span class="_ _7"> </span>with<span class="_ _0"> </span>t<span class="_ _5"></span>he<span class="_ _7"> </span>same<span class="_ _0"> </span>ne<span class="_ _4"></span>ws<span class="_ _7"> </span>d<span class="_ _2"></span>ata<span class="_ _7"> </span>as<span class="_ _0"> </span>i<span class="_ _5"></span>n<span class="_ _7"> </span>the<span class="_ _0"> </span>pre<span class="_ _4"></span>viou<span class="_ _2"></span>s<span class="_ _7"> </span>experiments,<span class="_ _7"> </span>we<span class="_ _0"> </span>ﬁrst<span class="_ _7"> </span>constructed<span class="_ _7"> </span>the<span class="_ _7"> </span>ph<span class="_ _2"></span>rase</div><div class="t m1 x0 h4 ya3 ff1 fs2 fc1 sc0 ls0 ws0">based<span class="_ _1d"> </span>tr<span class="_ _2"></span>aining<span class="_ _1d"> </span>co<span class="_ _2"></span>rpus<span class="_ _c"> </span>a<span class="_ _4"></span>nd<span class="_ _c"> </span>then<span class="_ _1d"> </span>we<span class="_ _c"> </span>t<span class="_ _4"></span>rain<span class="_ _2"></span>ed<span class="_ _1d"> </span>several<span class="_ _1d"> </span>Skip-gram<span class="_ _c"> </span>m<span class="_ _4"></span>o<span class="_ _2"></span>dels<span class="_ _1d"> </span>using<span class="_ _c"> </span>dif<span class="_ _4"></span>fer<span class="_ _2"></span>ent<span class="_ _1d"> </span>hyper-</div><div class="t m1 x0 h4 y11d ff1 fs2 fc1 sc0 ls0 ws0">parameters.<span class="_ _0"> </span>As<span class="_ _9"> </span>befo<span class="_ _2"></span>re,<span class="_ _9"> </span>we u<span class="_ _2"></span>sed<span class="_ _9"> </span>vector<span class="_ _9"> </span>dimensionality<span class="_ _9"> </span>300 and<span class="_ _7"> </span>c<span class="_ _5"></span>ontext size<span class="_ _9"> </span>5.<span class="_ _8"> </span>This setting<span class="_ _9"> </span>alread<span class="_ _2"></span>y</div><div class="t m1 x0 h4 y11e ff1 fs2 fc1 sc0 ls0 ws0">achieves good<span class="_ _9"> </span>perfor<span class="_ _2"></span>mance on<span class="_ _9"> </span>the<span class="_ _9"> </span>phrase<span class="_ _9"> </span>dataset,<span class="_ _9"> </span>an<span class="_ _2"></span>d<span class="_ _9"> </span>allowed us<span class="_ _9"> </span>to<span class="_ _9"> </span>quickly<span class="_ _9"> </span>compa<span class="_ _2"></span>re the<span class="_ _9"> </span>Negative</div><div class="t m1 x0 h4 y11f ff1 fs2 fc1 sc0 ls0 ws0">Sampling and the Hierarc<span class="_ _2"></span>hical Softmax, both with and witho<span class="_ _2"></span>ut subsampling of the frequ<span class="_ _2"></span>ent tokens.</div><div class="t m1 x0 h4 y120 ff1 fs2 fc1 sc0 ls0 ws0">The results are summarized in T<span class="_ _3"></span>able<span class="_ _9"> </span>3.</div><div class="t m1 x0 h4 y121 ff1 fs2 fc1 sc0 ls0 ws0">The<span class="_ _7"> </span>results<span class="_ _9"> </span>show<span class="_ _9"> </span>that<span class="_ _7"> </span>while<span class="_ _9"> </span>Negative Sampling<span class="_ _7"> </span>achie<span class="_ _4"></span>ves<span class="_ _9"> </span>a<span class="_ _7"> </span>respectable<span class="_ _7"> </span>a<span class="_ _5"></span>ccuracy<span class="_ _9"> </span>even<span class="_ _9"> </span>with<span class="_ _7"> </span><span class="ff5">k<span class="_ _0"> </span><span class="ff8">=<span class="_ _0"> </span>5</span></span>,</div><div class="t m1 x0 h4 y122 ff1 fs2 fc1 sc0 ls0 ws0">using<span class="_ _9"> </span><span class="ff5">k<span class="_ _0"> </span><span class="ff8">=<span class="_ _0"> </span>15<span class="_ _7"> </span></span></span>achie<span class="_ _4"></span>ves<span class="_ _9"> </span>considera<span class="_ _2"></span>bly<span class="_ _9"> </span>better<span class="_ _9"> </span>per<span class="_ _2"></span>forman<span class="_ _2"></span>ce.<span class="_ _8"> </span>Surprisingly<span class="_ _4"></span>,<span class="_ _9"> </span>while<span class="_ _9"> </span>we<span class="_ _7"> </span>found<span class="_ _9"> </span>the<span class="_ _7"> </span>H<span class="_ _5"></span>ierar-</div><div class="t m1 x0 h4 y123 ff1 fs2 fc1 sc0 ls0 ws0">chical Softmax to<span class="_ _6"> </span>achieve<span class="_ _6"> </span>lo<span class="_ _4"></span>wer perfo<span class="_ _2"></span>rmance<span class="_ _6"> </span>when trained without s<span class="_ _5"></span>ubsamplin<span class="_ _2"></span>g,<span class="_ _6"> </span>it became the<span class="_ _6"> </span>best</div><div class="t m1 x0 h4 y124 ff1 fs2 fc1 sc0 ls0 ws0">perfor<span class="_ _2"></span>ming<span class="_ _9"> </span>m<span class="_ _2"></span>ethod<span class="_ _7"> </span>when<span class="_ _7"> </span>we<span class="_ _9"> </span>downsampled<span class="_ _7"> </span>t<span class="_ _5"></span>he<span class="_ _7"> </span>frequen<span class="_ _2"></span>t<span class="_ _9"> </span>word<span class="_ _2"></span>s.<span class="_ _1d"> </span>This<span class="_ _7"> </span>shows<span class="_ _9"> </span>that<span class="_ _7"> </span>the<span class="_ _7"> </span>subsampling</div><div class="t m1 x0 h4 y3c ff1 fs2 fc1 sc0 ls0 ws0">can result in faster training and can also improve<span class="_ _6"> </span>accuracy<span class="_ _4"></span>,<span class="_ _6"> </span>at least in some cases.</div><div class="t m1 x2 h16 y125 ff1 fs8 fc1 sc0 ls0 ws0">2</div><div class="t m1 x40 hc y126 ff3 fs5 fc1 sc0 ls0 ws0">code.google.c<span class="_ _2"></span>om/p/word2vec<span class="_ _2"></span>/source/brows<span class="_ _2"></span>e/trunk/questions-<span class="_ _2"></span>p<span class="_ _2"></span>hrases.txt</div><div class="t m1 x72 ha y3d ff1 fs5 fc1 sc0 ls0 ws0">Method<span class="_ _15"> </span>Dimensionality<span class="_ _a"> </span>No subsampling [%]<span class="_ _a"> </span><span class="ff10">10</span></div><div class="t m1 x67 h14 y5e ff11 fs8 fc1 sc0 ls0 ws0">−<span class="ff12">5</span></div><div class="t m1 x4c ha y3d ff1 fs5 fc1 sc0 ls0 ws0">subsampling [%]</div><div class="t m1 x10 ha yaa ff1 fs5 fc1 sc0 ls0 ws0">NEG-5<span class="_ _35"> </span>300<span class="_ _36"> </span>24<span class="_ _37"> </span>27</div><div class="t m1 x71 ha y127 ff1 fs5 fc1 sc0 ls0 ws0">NEG-15<span class="_ _24"> </span>3<span class="_ _4"></span>00<span class="_ _36"> </span>27<span class="_ _37"> </span>42</div><div class="t m1 x78 h13 yeb ff1 fs5 fc1 sc0 ls0 ws0">HS-Huffman<span class="_ _30"> </span>300<span class="_ _36"> </span>19<span class="_ _37"> </span><span class="ff2">47</span></div><div class="t m1 x0 h4 yaf ff1 fs2 fc1 sc0 ls0 ws0">T<span class="_ _3"></span>ab<span class="_ _2"></span>le<span class="_ _7"> </span>3:<span class="_ _12"> </span>Accuracies<span class="_ _7"> </span>o<span class="_ _2"></span>f<span class="_ _7"> </span>the<span class="_ _7"> </span>Skip-<span class="_ _2"></span>gram<span class="_ _7"> </span>models<span class="_ _7"> </span>on<span class="_ _7"> </span>the<span class="_ _7"> </span>p<span class="_ _2"></span>hrase<span class="_ _7"> </span>analog<span class="_ _2"></span>y<span class="_ _7"> </span>dataset.<span class="_ _c"> </span>The<span class="_ _7"> </span>mo<span class="_ _2"></span>dels<span class="_ _7"> </span>were</div><div class="t m1 x0 h4 y128 ff1 fs2 fc1 sc0 ls0 ws0">trained on approx<span class="_ _2"></span>imately<span class="_ _6"> </span>one billion words from the news<span class="_ _6"> </span>dataset.</div><div class="t m1 x17 h4 y37 ff1 fs2 fc1 sc0 ls0 ws0">6</div><a class="l" href="#pf6" data-dest-detail='[6,"XYZ",143.065,532.941,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:431.224000px;bottom:349.384000px;width:5.912000px;height:7.712000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf6" data-dest-detail='[6,"XYZ",124.275,158.944,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:488.584000px;bottom:338.344000px;width:3.956000px;height:8.962000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf6" data-dest-detail='[6,"XYZ",146.318,72.8222,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:253.504000px;bottom:238.384000px;width:5.912000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="code.google.com/p/word2vec/source/browse/trunk/questions-phrases.txt"><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,255);position:absolute;left:122.584000px;bottom:158.104000px;width:367.352000px;height:8.312000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf7" class="pf w0 h0" data-page-no="7"><div class="pc pc7 w0 h0"><img class="bi x0 y35 w7 h12" alt="" src="bg7.png"/><div class="t m1 x44 ha yf1 ff1 fs5 fc1 sc0 ls0 ws0">NEG-15 with <span class="ff10">10</span></div><div class="t m1 x7 h14 y129 ff11 fs8 fc1 sc0 ls0 ws0">−<span class="ff12">5</span></div><div class="t m1 x57 ha yf1 ff1 fs5 fc1 sc0 ls0 ws0">subsampling<span class="_ _a"> </span>HS with <span class="ff10">10</span></div><div class="t m1 xd h14 y129 ff11 fs8 fc1 sc0 ls0 ws0">−<span class="ff12">5</span></div><div class="t m1 xc ha yf1 ff1 fs5 fc1 sc0 ls0 ws0">subsampling</div><div class="t m1 x78 ha yf2 ff1 fs5 fc1 sc0 ls0 ws0">V<span class="_ _3"></span>asco de Gama<span class="_ _18"> </span>L<span class="_ _2"></span>ingsugur<span class="_ _38"> </span>Italian ex<span class="_ _5"></span>plorer</div><div class="t m1 x3d ha yf3 ff1 fs5 fc1 sc0 ls0 ws0">Lake Baikal<span class="_ _2e"> </span>Great Rift V<span class="_ _3"></span>alley<span class="_ _38"> </span>A<span class="_ _4"></span>ral Sea</div><div class="t m1 x71 ha yce ff1 fs5 fc1 sc0 ls0 ws0">Alan Bean<span class="_ _39"> </span>Rebbeca Naomi<span class="_ _3a"> </span>moonw<span class="_ _5"></span>alker</div><div class="t m1 x71 ha y12a ff1 fs5 fc1 sc0 ls0 ws0">Ionian Sea<span class="_ _3b"> </span>Ruegen<span class="_ _37"> </span>I<span class="_ _5"></span>onian Islands</div><div class="t m1 x70 ha y12b ff1 fs5 fc1 sc0 ls0 ws0">chess master<span class="_ _28"> </span>chess grandmaster<span class="_ _3c"> </span>Garry Kasparo<span class="_ _4"></span>v</div><div class="t m1 x79 h4 yd4 ff1 fs2 fc1 sc0 ls0 ws0">T<span class="_ _3"></span>ab<span class="_ _2"></span>le 4:<span class="_ _9"> </span>Ex<span class="_ _2"></span>amples of the closest entities to the given<span class="_ _6"> </span>short phrases, using tw<span class="_ _5"></span>o different models.</div><div class="t m1 x7a ha y12c ff1 fs5 fc1 sc0 ls0 ws0">Czech + currenc<span class="_ _5"></span>y<span class="_ _3d"> </span>V<span class="_ _4"></span>ietnam + capital<span class="_ _3e"> </span>German + airlines<span class="_ _3f"> </span>Russian + riv<span class="_ _4"></span>er<span class="_ _15"> </span>French + actress</div><div class="t m1 x7b ha y4 ff1 fs5 fc1 sc0 ls0 ws0">korun<span class="_ _5"></span>a<span class="_ _27"> </span>Hanoi<span class="_ _40"> </span>airline Lufthansa<span class="_ _41"> </span>Mosco<span class="_ _4"></span>w<span class="_ _20"> </span>Juliette<span class="_ _9"> </span>B<span class="_ _5"></span>inoche</div><div class="t m1 x7c ha y12d ff1 fs5 fc1 sc0 ls0 ws0">Check cro<span class="_ _4"></span>wn<span class="_ _22"> </span>Ho Chi Minh City<span class="_ _42"> </span>carrier Lufthansa<span class="_ _43"> </span>V<span class="_ _1"></span>olga River<span class="_ _1b"> </span>V<span class="_ _1"></span>anessa Paradis</div><div class="t m1 x40 ha yf7 ff1 fs5 fc1 sc0 ls0 ws0">Polish zolty<span class="_ _44"> </span>V<span class="_ _4"></span>iet Nam<span class="_ _1b"> </span>ﬂag<span class="_ _6"> </span>c<span class="_ _5"></span>arrier Lufthansa<span class="_ _2a"> </span>upri<span class="_ _4"></span>ver<span class="_ _2a"> </span>Charlotte Gainsbourg</div><div class="t m1 x7d ha y83 ff1 fs5 fc1 sc0 ls0 ws0">CTK<span class="_ _2e"> </span>Vietna<span class="_ _5"></span>mese<span class="_ _45"> </span>Lufthansa<span class="_ _17"> </span>Russia<span class="_ _17"> </span>Cecile De</div><div class="t m1 x0 h4 y40 ff1 fs2 fc1 sc0 ls0 ws0">T<span class="_ _3"></span>ab<span class="_ _2"></span>le<span class="_ _6"> </span>5:<span class="_ _9"> </span>V<span class="_ _3"></span>ector<span class="_ _6"> </span>compo<span class="_ _2"></span>sitionality<span class="_ _6"> </span>using<span class="_ _6"> </span>element-wise<span class="_ _6"> </span>addition.<span class="_ _9"> </span>Four<span class="_ _6"> </span>closest<span class="_ _6"> </span>tokens<span class="_ _6"> </span>to<span class="_ _6"> </span>the<span class="_ _6"> </span>s<span class="_ _5"></span>um of<span class="_ _6"> </span>tw<span class="_ _4"></span>o</div><div class="t m1 x0 h4 yf9 ff1 fs2 fc1 sc0 ls0 ws0">vectors are sho<span class="_ _4"></span>wn<span class="_ _2"></span>, using the best Skip-gram model.</div><div class="t m1 x0 h4 yd5 ff1 fs2 fc1 sc0 ls0 ws0">T<span class="_ _3"></span>o<span class="_ _9"> </span>maximize the accu<span class="_ _2"></span>racy on the phrase analo<span class="_ _2"></span>gy task, we incr<span class="_ _2"></span>eased the amou<span class="_ _2"></span>nt of the tr<span class="_ _2"></span>aining data</div><div class="t m1 x0 h4 y12e ff1 fs2 fc1 sc0 ls0 ws0">by<span class="_ _7"> </span>using<span class="_ _9"> </span>a<span class="_ _7"> </span>dataset<span class="_ _9"> </span>with<span class="_ _7"> </span>about<span class="_ _9"> </span>3<span class="_ _2"></span>3<span class="_ _7"> </span>billion<span class="_ _9"> </span>words.<span class="_ _b"> </span>W<span class="_ _3"></span>e<span class="_ _7"> </span>used<span class="_ _7"> </span>the<span class="_ _9"> </span>hierarc<span class="_ _2"></span>hical<span class="_ _9"> </span>softm<span class="_ _2"></span>ax,<span class="_ _7"> </span>dimensionality</div><div class="t m1 x0 h4 yc0 ff1 fs2 fc1 sc0 ls0 ws0">of<span class="_ _9"> </span>1000<span class="_ _2"></span>, an<span class="_ _2"></span>d th<span class="_ _2"></span>e<span class="_ _9"> </span>entire<span class="_ _9"> </span>sentence<span class="_ _9"> </span>for<span class="_ _9"> </span>the<span class="_ _9"> </span>context.<span class="_ _0"> </span>This<span class="_ _9"> </span>r<span class="_ _2"></span>esulted<span class="_ _9"> </span>in<span class="_ _9"> </span>a<span class="_ _9"> </span>mode<span class="_ _2"></span>l that<span class="_ _9"> </span>reach<span class="_ _2"></span>ed an<span class="_ _9"> </span>accu<span class="_ _2"></span>racy</div><div class="t m1 x0 h3 y114 ff1 fs2 fc1 sc0 ls0 ws0">of<span class="_ _9"> </span><span class="ff2">72%</span>.<span class="_ _8"> </span>W<span class="_ _3"></span>e<span class="_ _9"> </span>ach<span class="_ _2"></span>iev<span class="_ _4"></span>e<span class="_ _2"></span>d lower<span class="_ _9"> </span>accuracy<span class="_ _9"> </span>66%<span class="_ _9"> </span>when<span class="_ _9"> </span>we<span class="_ _7"> </span>reduced the<span class="_ _9"> </span>size<span class="_ _7"> </span>of the<span class="_ _9"> </span>tr<span class="_ _2"></span>aining<span class="_ _9"> </span>dataset<span class="_ _9"> </span>to<span class="_ _9"> </span>6B</div><div class="t m1 x0 h4 y115 ff1 fs2 fc1 sc0 ls0 ws0">words, which suggests that the large<span class="_ _6"> </span>amoun<span class="_ _2"></span>t of the training data is<span class="_ _6"> </span>crucial.</div><div class="t m1 x0 h4 y19 ff1 fs2 fc1 sc0 ls0 ws0">T<span class="_ _3"></span>o gain<span class="_ _6"> </span>further insight<span class="_ _6"> </span>into ho<span class="_ _5"></span>w<span class="_ _6"> </span>dif<span class="_ _5"></span>ferent<span class="_ _6"> </span>the representations<span class="_ _6"> </span>learned by<span class="_ _6"> </span>different<span class="_ _6"> </span>models<span class="_ _6"> </span>are,<span class="_ _6"> </span>we did</div><div class="t m1 x0 h4 y118 ff1 fs2 fc1 sc0 ls0 ws0">inspect manually the nearest neighb<span class="_ _2"></span>ours of infrequent phrases using v<span class="_ _5"></span>arious models.<span class="_ _7"> </span>In<span class="_ _6"> </span>T<span class="_ _4"></span>able 4, we</div><div class="t m1 x0 h4 y12f ff1 fs2 fc1 sc0 ls0 ws0">show<span class="_ _7"> </span>a<span class="_ _9"> </span>samp<span class="_ _2"></span>le<span class="_ _7"> </span>of<span class="_ _7"> </span>such<span class="_ _7"> </span>comparison.<span class="_ _1d"> </span>Consistently<span class="_ _7"> </span>with<span class="_ _7"> </span>the<span class="_ _7"> </span>previous<span class="_ _9"> </span>results,<span class="_ _0"> </span>i<span class="_ _5"></span>t<span class="_ _7"> </span>seems<span class="_ _7"> </span>that<span class="_ _7"> </span>the<span class="_ _7"> </span>best</div><div class="t m1 x0 h4 y1c ff1 fs2 fc1 sc0 ls0 ws0">representatio<span class="_ _2"></span>ns<span class="_ _6"> </span>of phrases are learned by a mod<span class="_ _2"></span>el with the<span class="_ _6"> </span>hierarch<span class="_ _2"></span>ical softmax and subsampling.</div><div class="t m1 x0 h6 y9a ff2 fs3 fc1 sc0 ls0 ws0">5<span class="_ _a"> </span>Additiv<span class="_ _5"></span>e Compositio<span class="_ _2"></span>nality</div><div class="t m1 x0 h4 y130 ff1 fs2 fc1 sc0 ls0 ws0">W<span class="_ _3"></span>e<span class="_ _9"> </span>demo<span class="_ _2"></span>nstrated that<span class="_ _9"> </span>the word<span class="_ _9"> </span>and p<span class="_ _2"></span>hrase rep<span class="_ _2"></span>resentations learned<span class="_ _9"> </span>by<span class="_ _9"> </span>the Skip-g<span class="_ _2"></span>ram mo<span class="_ _2"></span>del exhibit</div><div class="t m1 x0 h4 y9f ff1 fs2 fc1 sc0 ls0 ws0">a linear structure that makes it possible to perform precise analogical reasoning using simple vector</div><div class="t m1 x0 h4 ya1 ff1 fs2 fc1 sc0 ls0 ws0">arithmetics.<span class="_ _9"> </span>Inter<span class="_ _2"></span>estingly<span class="_ _4"></span>,<span class="_ _6"> </span>we<span class="_ _6"> </span>found<span class="_ _6"> </span>that<span class="_ _11"> </span>th<span class="_ _2"></span>e<span class="_ _6"> </span>Skip-gra<span class="_ _2"></span>m<span class="_ _11"> </span>rep<span class="_ _2"></span>resentations<span class="_ _6"> </span>e<span class="_ _5"></span>xhibit<span class="_ _6"> </span>another<span class="_ _6"> </span>kind<span class="_ _6"> </span>of<span class="_ _6"> </span>linear</div><div class="t m1 x0 h4 y11c ff1 fs2 fc1 sc0 ls0 ws0">structure<span class="_ _6"> </span>that makes<span class="_ _6"> </span>it<span class="_ _6"> </span>possible<span class="_ _6"> </span>to meaningfully<span class="_ _6"> </span>combine<span class="_ _6"> </span>words<span class="_ _6"> </span>by<span class="_ _6"> </span>an<span class="_ _6"> </span>element-w<span class="_ _2"></span>ise<span class="_ _6"> </span>addition<span class="_ _6"> </span>of<span class="_ _6"> </span>their</div><div class="t m1 x0 h4 y131 ff1 fs2 fc1 sc0 ls0 ws0">vector representations.<span class="_ _9"> </span>This phen<span class="_ _2"></span>omeno<span class="_ _2"></span>n<span class="_ _6"> </span>is illustrated in T<span class="_ _3"></span>able 5.</div><div class="t m1 x0 h4 y132 ff1 fs2 fc1 sc0 ls0 ws0">The additi<span class="_ _4"></span>ve property<span class="_ _6"> </span>of the<span class="_ _6"> </span>vectors<span class="_ _6"> </span>can be<span class="_ _6"> </span>explained<span class="_ _6"> </span>by inspecting<span class="_ _6"> </span>the training<span class="_ _6"> </span>objective. The word</div><div class="t m1 x0 h4 y133 ff1 fs2 fc1 sc0 ls0 ws0">vectors are<span class="_ _9"> </span>in<span class="_ _9"> </span>a linear<span class="_ _9"> </span>relation<span class="_ _2"></span>ship with<span class="_ _9"> </span>the<span class="_ _9"> </span>inputs to<span class="_ _9"> </span>the<span class="_ _9"> </span>softmax<span class="_ _9"> </span>nonlinea<span class="_ _2"></span>rity<span class="_ _4"></span>.<span class="_ _7"> </span>As<span class="_ _9"> </span>the<span class="_ _9"> </span>word vectors</div><div class="t m1 x0 h4 y134 ff1 fs2 fc1 sc0 ls0 ws0">are trained to predict the surro<span class="_ _2"></span>unding w<span class="_ _5"></span>ords in the sentence, the vectors can be seen as rep<span class="_ _2"></span>resenting</div><div class="t m1 x0 h4 y135 ff1 fs2 fc1 sc0 ls0 ws0">the<span class="_ _7"> </span>distribution<span class="_ _7"> </span>of<span class="_ _7"> </span>the<span class="_ _7"> </span>context<span class="_ _7"> </span>in<span class="_ _7"> </span>w<span class="_ _5"></span>hich<span class="_ _7"> </span>a<span class="_ _7"> </span>word<span class="_ _7"> </span>appears.<span class="_ _c"> </span>These<span class="_ _7"> </span>values<span class="_ _7"> </span>are<span class="_ _7"> </span>related<span class="_ _7"> </span>logarithmically</div><div class="t m1 x0 h4 y136 ff1 fs2 fc1 sc0 ls0 ws0">to<span class="_ _9"> </span>the<span class="_ _7"> </span>probabilities<span class="_ _9"> </span>compu<span class="_ _2"></span>ted b<span class="_ _2"></span>y<span class="_ _9"> </span>the<span class="_ _7"> </span>output<span class="_ _9"> </span>layer,<span class="_ _9"> </span>so<span class="_ _9"> </span>the<span class="_ _7"> </span>s<span class="_ _5"></span>um<span class="_ _9"> </span>o<span class="_ _2"></span>f<span class="_ _9"> </span>two<span class="_ _7"> </span>w<span class="_ _4"></span>or<span class="_ _2"></span>d<span class="_ _9"> </span>vectors<span class="_ _9"> </span>is<span class="_ _7"> </span>related<span class="_ _9"> </span>to<span class="_ _9"> </span>th<span class="_ _2"></span>e</div><div class="t m1 x0 h4 y137 ff1 fs2 fc1 sc0 ls0 ws0">produ<span class="_ _2"></span>ct of<span class="_ _9"> </span>the<span class="_ _9"> </span>two<span class="_ _9"> </span>context distributions.<span class="_ _0"> </span>Th<span class="_ _2"></span>e p<span class="_ _2"></span>roduct work<span class="_ _2"></span>s<span class="_ _9"> </span>here a<span class="_ _2"></span>s<span class="_ _9"> </span>the<span class="_ _9"> </span>AND<span class="_ _9"> </span>functio<span class="_ _2"></span>n:<span class="_ _7"> </span>words<span class="_ _9"> </span>that</div><div class="t m1 x0 h4 y138 ff1 fs2 fc1 sc0 ls0 ws0">are assigned high probabilities by both<span class="_ _6"> </span>word vectors<span class="_ _6"> </span>will have<span class="_ _6"> </span>high probability<span class="_ _4"></span>, and the<span class="_ _6"> </span>other words</div><div class="t m1 x0 h4 y139 ff1 fs2 fc1 sc0 ls0 ws0">will<span class="_ _9"> </span>have low prob<span class="_ _2"></span>ability<span class="_ _4"></span>.<span class="_ _0"> </span>Thus,<span class="_ _9"> </span>if<span class="_ _9"> </span>“V<span class="_ _1"></span>olga<span class="_ _9"> </span>Riv<span class="_ _5"></span>er”<span class="_ _9"> </span>appears<span class="_ _9"> </span>frequen<span class="_ _2"></span>tly in<span class="_ _9"> </span>the<span class="_ _9"> </span>same<span class="_ _9"> </span>sen<span class="_ _2"></span>tence<span class="_ _9"> </span>together</div><div class="t m1 x0 h4 y13a ff1 fs2 fc1 sc0 ls0 ws0">with<span class="_ _6"> </span>the w<span class="_ _4"></span>o<span class="_ _2"></span>rds<span class="_ _6"> </span>“Russian” and<span class="_ _6"> </span>“ri<span class="_ _4"></span>ver”<span class="_ _2"></span>,<span class="_ _6"> </span>the<span class="_ _6"> </span>sum<span class="_ _6"> </span>of<span class="_ _6"> </span>these tw<span class="_ _4"></span>o word<span class="_ _6"> </span>vectors<span class="_ _6"> </span>will<span class="_ _6"> </span>result<span class="_ _6"> </span>in<span class="_ _6"> </span>such<span class="_ _6"> </span>a feature</div><div class="t m1 x0 h4 y13b ff1 fs2 fc1 sc0 ls0 ws0">vector that is close to the v<span class="_ _5"></span>ector of “V<span class="_ _1"></span>olga Ri<span class="_ _4"></span>ver”.</div><div class="t m1 x0 h6 ya7 ff2 fs3 fc1 sc0 ls0 ws0">6<span class="_ _a"> </span>Comparison to Published W<span class="_ _4"></span>ord<span class="_ _9"> </span>Repr<span class="_ _4"></span>esentations</div><div class="t m1 x0 h4 y13c ff1 fs2 fc1 sc0 ls0 ws0">Many<span class="_ _9"> </span>a<span class="_ _2"></span>uthors<span class="_ _7"> </span>who<span class="_ _9"> </span>previously<span class="_ _7"> </span>w<span class="_ _4"></span>or<span class="_ _2"></span>ked<span class="_ _9"> </span>o<span class="_ _2"></span>n<span class="_ _7"> </span>the<span class="_ _7"> </span>neural<span class="_ _9"> </span>network<span class="_ _7"> </span>based<span class="_ _9"> </span>rep<span class="_ _2"></span>resentations<span class="_ _7"> </span>of<span class="_ _9"> </span>words<span class="_ _7"> </span>ha<span class="_ _4"></span>ve</div><div class="t m1 x0 h4 y13d ff1 fs2 fc1 sc0 ls0 ws0">published their<span class="_ _9"> </span>resulting mo<span class="_ _2"></span>dels for fur<span class="_ _2"></span>ther use a<span class="_ _2"></span>nd compar<span class="_ _2"></span>ison:<span class="_ _7"> </span>amongst the mo<span class="_ _2"></span>st well kn<span class="_ _2"></span>own au-</div><div class="t m1 x0 h4 y13e ff1 fs2 fc1 sc0 ls0 ws0">thors<span class="_ _9"> </span>are<span class="_ _9"> </span>Collober<span class="_ _2"></span>t<span class="_ _9"> </span>and<span class="_ _9"> </span>W<span class="_ _3"></span>eston<span class="_ _7"> </span>[2],<span class="_ _9"> </span>T<span class="_ _4"></span>urian<span class="_ _9"> </span>et<span class="_ _9"> </span>al.<span class="_ _7"> </span>[17<span class="_ _4"></span>],<span class="_ _7"> </span>and Mn<span class="_ _2"></span>ih<span class="_ _9"> </span>and<span class="_ _9"> </span>Hinton<span class="_ _9"> </span>[10].<span class="_ _8"> </span>W<span class="_ _3"></span>e<span class="_ _9"> </span>d<span class="_ _2"></span>ownloaded</div><div class="t m1 x0 h4 y13f ff1 fs2 fc1 sc0 ls0 ws0">their word vector<span class="_ _2"></span>s from th<span class="_ _2"></span>e web</div><div class="t m1 x51 h15 y64 ff1 fs6 fc1 sc0 ls0 ws0">3</div><div class="t m1 x1e h4 y13f ff1 fs2 fc1 sc0 ls0 ws0">.<span class="_ _0"> </span>M<span class="_ _5"></span>ikolov et al.<span class="_ _9"> </span>[8] have already evaluated these word repr<span class="_ _2"></span>esenta-</div><div class="t m1 x0 h4 y140 ff1 fs2 fc1 sc0 ls0 ws0">tions o<span class="_ _2"></span>n th<span class="_ _2"></span>e word<span class="_ _9"> </span>analog<span class="_ _2"></span>y task,<span class="_ _9"> </span>where the<span class="_ _9"> </span>Skip<span class="_ _2"></span>-gram mod<span class="_ _2"></span>els achieved the best<span class="_ _9"> </span>per<span class="_ _2"></span>forman<span class="_ _2"></span>ce with a</div><div class="t m1 x0 h4 y141 ff1 fs2 fc1 sc0 ls0 ws0">huge margin.</div><div class="t m1 x2 h16 y10b ff1 fs8 fc1 sc0 ls0 ws0">3</div><div class="t m1 x40 hc y36 ff3 fs5 fc1 sc0 ls0 ws0">http://metaop<span class="_ _2"></span>timize.com/pr<span class="_ _2"></span>ojects/wordre<span class="_ _2"></span>prs/</div><div class="t m1 x17 h4 y37 ff1 fs2 fc1 sc0 ls0 ws0">7</div><a class="l" href="#pf7" data-dest-detail='[7,"XYZ",151.979,625.447,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:480.904000px;bottom:420.784000px;width:6.032000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf7" data-dest-detail='[7,"XYZ",143.065,536.193,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:359.944000px;bottom:302.344000px;width:5.912000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,676.206,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:238.024000px;bottom:112.504000px;width:5.912000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,266.195,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:306.664000px;bottom:112.384000px;width:10.832000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,444.099,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:418.144000px;bottom:112.384000px;width:10.952000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf7" data-dest-detail='[7,"XYZ",124.275,59.6931,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:235.384000px;bottom:101.584000px;width:3.836000px;height:8.962000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,492.159,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:307.624000px;bottom:101.464000px;width:6.032000px;height:7.832000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="http://metaoptimize.com/projects/wordreprs/"><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,255);position:absolute;left:122.584000px;bottom:59.223800px;width:232.352000px;height:8.312500px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf8" class="pf w0 h0" data-page-no="8"><div class="pc pc8 w0 h0"><img class="bi x0 y35 w8 h18" alt="" src="bg8.png"/><div class="t m1 x6 ha yf1 ff1 fs5 fc1 sc0 ls0 ws0">Model<span class="_ _46"> </span>Redmond<span class="_ _36"> </span>H<span class="_ _4"></span>avel<span class="_ _47"> </span>ninjutsu<span class="_ _1f"> </span>g<span class="_ _5"></span>rafﬁti<span class="_ _48"> </span>capitulate</div><div class="t m1 x79 ha yf2 ff1 fs5 fc1 sc0 ls0 ws0">(training time)</div><div class="t m1 x7a ha y6c ff1 fs5 fc1 sc0 ls0 ws0">Collobert (50d)<span class="_ _2f"> </span>c<span class="_ _5"></span>onye<span class="_ _5"></span>rs<span class="_ _49"> </span>plauen<span class="_ _4a"> </span>reiki<span class="_ _20"> </span>c<span class="_ _4"></span>heesecake<span class="_ _42"> </span>abdicate</div><div class="t m1 x7c ha y142 ff1 fs5 fc1 sc0 ls0 ws0">(2 months)<span class="_ _17"> </span>lu<span class="_ _5"></span>bbock<span class="_ _4b"> </span>dzerzhinsk<span class="_ _4"></span>y<span class="_ _31"> </span>kohona<span class="_ _29"> </span>g<span class="_ _4"></span>ossip<span class="_ _14"> </span>accede</div><div class="t m1 x4d ha y143 ff1 fs5 fc1 sc0 ls0 ws0">keene<span class="_ _4c"> </span>osterreich<span class="_ _46"> </span>karate<span class="_ _4d"> </span>dioramas<span class="_ _1b"> </span>rearm</div><div class="t m1 x79 ha y3 ff1 fs5 fc1 sc0 ls0 ws0">T<span class="_ _4"></span>urian (200d)<span class="_ _4e"> </span>McCarthy<span class="_ _4f"> </span>Je<span class="_ _5"></span>well<span class="_ _50"> </span>-<span class="_ _25"> </span>gunﬁre<span class="_ _51"> </span>-</div><div class="t m1 x2 ha y144 ff1 fs5 fc1 sc0 ls0 ws0">(few<span class="_ _6"> </span>we<span class="_ _5"></span>eks)<span class="_ _17"> </span>Alston<span class="_ _52"> </span>Arzu<span class="_ _53"> </span>-<span class="_ _54"> </span>emotion<span class="_ _1c"> </span>-</div><div class="t m1 x7e ha y0 ff1 fs5 fc1 sc0 ls0 ws0">Cousins<span class="_ _3a"> </span>O<span class="_ _5"></span>vitz<span class="_ _55"> </span>-<span class="_ _1e"> </span>impun<span class="_ _5"></span>ity<span class="_ _29"> </span>-</div><div class="t m1 x2 ha y145 ff1 fs5 fc1 sc0 ls0 ws0">Mnih (100d)<span class="_ _28"> </span>Podhurst<span class="_ _4c"> </span>Pontif<span class="_ _4"></span>f<span class="_ _49"> </span>-<span class="_ _16"> </span>anaesthetics<span class="_ _56"> </span>Mav<span class="_ _4"></span>ericks</div><div class="t m1 x7f ha y80 ff1 fs5 fc1 sc0 ls0 ws0">(7 days)<span class="_ _46"> </span>Harlang<span class="_ _4f"> </span>P<span class="_ _4"></span>inochet<span class="_ _57"> </span>-<span class="_ _1e"> </span>monk<span class="_ _4"></span>eys<span class="_ _2b"> </span>planning</div><div class="t m1 x3 ha y146 ff1 fs5 fc1 sc0 ls0 ws0">Agarwal<span class="_ _58"> </span>Rodiono<span class="_ _5"></span>v<span class="_ _59"> </span>-<span class="_ _5a"> </span>Je<span class="_ _5"></span>ws<span class="_ _13"> </span>h<span class="_ _4"></span>esitated</div><div class="t m1 x2 ha y147 ff1 fs5 fc1 sc0 ls0 ws0">Skip-Phrase<span class="_ _13"> </span>Redm<span class="_ _5"></span>ond W<span class="_ _4"></span>ash.<span class="_ _2f"> </span>V<span class="_ _1"></span>aclav Ha<span class="_ _4"></span>vel<span class="_ _2c"> </span>ninja<span class="_ _30"> </span>spray paint<span class="_ _56"> </span>c<span class="_ _4"></span>apitulation</div><div class="t m1 x79 ha y148 ff1 fs5 fc1 sc0 ls0 ws0">(1000d, 1 day)<span class="_ _5b"> </span>Redmond W<span class="_ _4"></span>ashing<span class="_ _5"></span>ton<span class="_ _a"> </span>president V<span class="_ _3"></span>aclav Hav<span class="_ _4"></span>el<span class="_ _42"> </span>martial arts<span class="_ _5c"> </span>graﬁtti<span class="_ _2b"> </span>c<span class="_ _5"></span>apitulated</div><div class="t m1 x3 ha y111 ff1 fs5 fc1 sc0 ls0 ws0">Microsoft<span class="_ _35"> </span>V<span class="_ _3"></span>elvet Re<span class="_ _4"></span>volution<span class="_ _15"> </span>s<span class="_ _4"></span>wordsmanship<span class="_ _15"> </span>t<span class="_ _4"></span>aggers<span class="_ _5d"> </span>capitulating</div><div class="t m1 x0 h4 y149 ff1 fs2 fc1 sc0 ls0 ws0">T<span class="_ _3"></span>ab<span class="_ _2"></span>le 6:<span class="_ _9"> </span>Examp<span class="_ _2"></span>les<span class="_ _6"> </span>of the closest t<span class="_ _5"></span>okens<span class="_ _6"> </span>given<span class="_ _6"> </span>v<span class="_ _4"></span>a<span class="_ _2"></span>rious well known<span class="_ _11"> </span>mo<span class="_ _2"></span>dels and the<span class="_ _6"> </span>Skip-gram model</div><div class="t m1 x0 h4 y10 ff1 fs2 fc1 sc0 ls0 ws0">trained on phrases using over 30 billion training w<span class="_ _5"></span>ords.<span class="_ _7"> </span>An empty cell means that the word w<span class="_ _5"></span>as not</div><div class="t m1 x0 h4 y11 ff1 fs2 fc1 sc0 ls0 ws0">in the vocabulary<span class="_ _4"></span>.</div><div class="t m1 x0 h4 y14a ff1 fs2 fc1 sc0 ls0 ws0">T<span class="_ _3"></span>o<span class="_ _9"> </span>g<span class="_ _2"></span>iv<span class="_ _5"></span>e mo<span class="_ _2"></span>re in<span class="_ _2"></span>sight in<span class="_ _2"></span>to<span class="_ _9"> </span>the<span class="_ _9"> </span>difference of<span class="_ _9"> </span>the<span class="_ _9"> </span>qua<span class="_ _2"></span>lity of<span class="_ _9"> </span>th<span class="_ _2"></span>e lear<span class="_ _2"></span>ned<span class="_ _9"> </span>vectors, we<span class="_ _7"> </span>provide empirical</div><div class="t m1 x0 h4 y8b ff1 fs2 fc1 sc0 ls0 ws0">compariso<span class="_ _2"></span>n<span class="_ _11"> </span>by<span class="_ _6"> </span>sho<span class="_ _4"></span>win<span class="_ _2"></span>g<span class="_ _11"> </span>th<span class="_ _2"></span>e<span class="_ _6"> </span>nearest<span class="_ _11"> </span>neigh<span class="_ _2"></span>bour<span class="_ _2"></span>s<span class="_ _11"> </span>of<span class="_ _11"> </span>in<span class="_ _2"></span>freque<span class="_ _2"></span>nt<span class="_ _11"> </span>words<span class="_ _11"> </span>in T<span class="_ _3"></span>able<span class="_ _6"> </span>6. Th<span class="_ _2"></span>ese<span class="_ _6"> </span>e<span class="_ _4"></span>x<span class="_ _2"></span>amples<span class="_ _6"> </span>s<span class="_ _5"></span>how</div><div class="t m1 x0 h4 y8c ff1 fs2 fc1 sc0 ls0 ws0">that<span class="_ _9"> </span>the<span class="_ _9"> </span>big<span class="_ _9"> </span>Sk<span class="_ _2"></span>ip-gram<span class="_ _9"> </span>model<span class="_ _9"> </span>trained<span class="_ _9"> </span>on<span class="_ _9"> </span>a<span class="_ _7"> </span>lar<span class="_ _5"></span>ge co<span class="_ _2"></span>rpus<span class="_ _9"> </span>visibly<span class="_ _9"> </span>outpe<span class="_ _2"></span>rforms a<span class="_ _2"></span>ll<span class="_ _9"> </span>the<span class="_ _9"> </span>other<span class="_ _9"> </span>m<span class="_ _2"></span>odels in</div><div class="t m1 x0 h4 y8d ff1 fs2 fc1 sc0 ls0 ws0">the<span class="_ _9"> </span>qu<span class="_ _2"></span>ality<span class="_ _9"> </span>of<span class="_ _7"> </span>the lear<span class="_ _2"></span>ned<span class="_ _9"> </span>repr<span class="_ _2"></span>esentations.<span class="_ _8"> </span>This<span class="_ _7"> </span>can b<span class="_ _2"></span>e<span class="_ _9"> </span>attributed<span class="_ _9"> </span>in<span class="_ _7"> </span>part<span class="_ _9"> </span>to<span class="_ _9"> </span>the<span class="_ _7"> </span>f<span class="_ _5"></span>act<span class="_ _9"> </span>that<span class="_ _7"> </span>this m<span class="_ _2"></span>odel</div><div class="t m1 x0 h4 y8e ff1 fs2 fc1 sc0 ls0 ws0">has<span class="_ _9"> </span>been<span class="_ _9"> </span>tr<span class="_ _2"></span>ained<span class="_ _9"> </span>on<span class="_ _7"> </span>about 3<span class="_ _2"></span>0<span class="_ _9"> </span>billion<span class="_ _7"> </span>w<span class="_ _4"></span>ord<span class="_ _2"></span>s,<span class="_ _9"> </span>which<span class="_ _9"> </span>is<span class="_ _7"> </span>about<span class="_ _9"> </span>two<span class="_ _9"> </span>to<span class="_ _9"> </span>three<span class="_ _7"> </span>orders o<span class="_ _2"></span>f<span class="_ _9"> </span>magnitud<span class="_ _2"></span>e m<span class="_ _2"></span>ore</div><div class="t m1 x0 h4 y8f ff1 fs2 fc1 sc0 ls0 ws0">data<span class="_ _7"> </span>than<span class="_ _7"> </span>the<span class="_ _7"> </span>typ<span class="_ _2"></span>ical<span class="_ _7"> </span>size<span class="_ _7"> </span>used<span class="_ _7"> </span>in<span class="_ _7"> </span>the<span class="_ _7"> </span>prior<span class="_ _7"> </span>work.<span class="_ _c"> </span>Interesting<span class="_ _2"></span>ly<span class="_ _4"></span>,<span class="_ _7"> </span>although<span class="_ _7"> </span>the<span class="_ _7"> </span>training<span class="_ _7"> </span>set<span class="_ _7"> </span>is<span class="_ _0"> </span>m<span class="_ _5"></span>uch</div><div class="t m1 x0 h4 yd7 ff1 fs2 fc1 sc0 ls0 ws0">larger<span class="_ _4"></span>, the<span class="_ _6"> </span>training time of<span class="_ _6"> </span>the S<span class="_ _5"></span>kip-gr<span class="_ _2"></span>am model<span class="_ _6"> </span>is just<span class="_ _6"> </span>a fraction<span class="_ _6"> </span>of the time<span class="_ _6"> </span>complexity<span class="_ _6"> </span>required by</div><div class="t m1 x0 h4 y93 ff1 fs2 fc1 sc0 ls0 ws0">the previous model<span class="_ _6"> </span>architectu<span class="_ _2"></span>res.</div><div class="t m1 x0 h6 y14b ff2 fs3 fc1 sc0 ls0 ws0">7<span class="_ _a"> </span>Conclusion</div><div class="t m1 x0 h4 y14c ff1 fs2 fc1 sc0 ls0 ws0">This work has se<span class="_ _5"></span>veral key<span class="_ _6"> </span>contributions.<span class="_ _9"> </span>W<span class="_ _4"></span>e sho<span class="_ _4"></span>w how to train distributed representations of words</div><div class="t m1 x0 h4 y14d ff1 fs2 fc1 sc0 ls0 ws0">and<span class="_ _0"> </span>phrases<span class="_ _0"> </span>with<span class="_ _0"> </span>t<span class="_ _5"></span>he<span class="_ _0"> </span>Skip-gram<span class="_ _0"> </span>model<span class="_ _0"> </span>a<span class="_ _5"></span>nd<span class="_ _0"> </span>demonstrate<span class="_ _0"> </span>that<span class="_ _0"> </span>these<span class="_ _7"> </span>re<span class="_ _2"></span>presentation<span class="_ _2"></span>s<span class="_ _7"> </span>exhib<span class="_ _2"></span>it<span class="_ _7"> </span>lin<span class="_ _2"></span>ear</div><div class="t m1 x0 h4 y14e ff1 fs2 fc1 sc0 ls0 ws0">structure th<span class="_ _2"></span>at makes pr<span class="_ _2"></span>ecise analogic<span class="_ _2"></span>al reasoning possible.<span class="_ _0"> </span>The techniques intr<span class="_ _2"></span>oduced in<span class="_ _9"> </span>this pape<span class="_ _2"></span>r</div><div class="t m1 x0 h4 y14f ff1 fs2 fc1 sc0 ls0 ws0">can be used also for training the continuou<span class="_ _2"></span>s<span class="_ _6"> </span>bag-of<span class="_ _2"></span>-words<span class="_ _6"> </span>model introdu<span class="_ _2"></span>ced in<span class="_ _6"> </span>[8].</div><div class="t m1 x0 h4 y52 ff1 fs2 fc1 sc0 ls0 ws0">W<span class="_ _3"></span>e<span class="_ _9"> </span>successfully<span class="_ _9"> </span>trained<span class="_ _9"> </span>models<span class="_ _9"> </span>on several orders<span class="_ _9"> </span>of<span class="_ _9"> </span>magnitud<span class="_ _2"></span>e more data<span class="_ _9"> </span>than<span class="_ _9"> </span>the<span class="_ _9"> </span>previously pub-</div><div class="t m1 x0 h4 y53 ff1 fs2 fc1 sc0 ls0 ws0">lished<span class="_ _7"> </span>mod<span class="_ _2"></span>els,<span class="_ _7"> </span>than<span class="_ _2"></span>ks<span class="_ _7"> </span>to<span class="_ _7"> </span>the<span class="_ _7"> </span>com<span class="_ _2"></span>putation<span class="_ _2"></span>ally<span class="_ _7"> </span>ef<span class="_ _4"></span>ﬁcien<span class="_ _2"></span>t<span class="_ _7"> </span>model<span class="_ _7"> </span>architectu<span class="_ _2"></span>re.<span class="_ _c"> </span>This<span class="_ _7"> </span>results<span class="_ _7"> </span>in<span class="_ _7"> </span>a<span class="_ _0"> </span>great</div><div class="t m1 x0 h4 y150 ff1 fs2 fc1 sc0 ls0 ws0">improvement<span class="_ _9"> </span>in<span class="_ _9"> </span>th<span class="_ _2"></span>e<span class="_ _7"> </span>quality<span class="_ _9"> </span>of<span class="_ _7"> </span>t<span class="_ _4"></span>h<span class="_ _2"></span>e<span class="_ _7"> </span>l<span class="_ _4"></span>e<span class="_ _2"></span>arned<span class="_ _7"> </span>w<span class="_ _4"></span>or<span class="_ _2"></span>d<span class="_ _9"> </span>and<span class="_ _7"> </span>phrase<span class="_ _9"> </span>rep<span class="_ _2"></span>resentations,<span class="_ _7"> </span>es<span class="_ _5"></span>pecially<span class="_ _7"> </span>for<span class="_ _9"> </span>the<span class="_ _7"> </span>rare</div><div class="t m1 x0 h4 y151 ff1 fs2 fc1 sc0 ls0 ws0">entities.<span class="_ _c"> </span>W<span class="_ _3"></span>e<span class="_ _7"> </span>also<span class="_ _7"> </span>foun<span class="_ _2"></span>d<span class="_ _7"> </span>t<span class="_ _5"></span>hat<span class="_ _7"> </span>the<span class="_ _7"> </span>subsamplin<span class="_ _2"></span>g<span class="_ _7"> </span>of<span class="_ _7"> </span>the<span class="_ _7"> </span>frequent<span class="_ _7"> </span>w<span class="_ _5"></span>ords<span class="_ _7"> </span>results<span class="_ _7"> </span>in<span class="_ _7"> </span>both<span class="_ _7"> </span>faster<span class="_ _7"> </span>training</div><div class="t m1 x0 h4 y152 ff1 fs2 fc1 sc0 ls0 ws0">and<span class="_ _9"> </span>sign<span class="_ _2"></span>iﬁcantly<span class="_ _9"> </span>b<span class="_ _2"></span>etter<span class="_ _9"> </span>rep<span class="_ _2"></span>resentations<span class="_ _9"> </span>of<span class="_ _7"> </span>uncommon<span class="_ _9"> </span>words.<span class="_ _8"> </span>Ano<span class="_ _2"></span>ther<span class="_ _9"> </span>contr<span class="_ _2"></span>ibution o<span class="_ _2"></span>f<span class="_ _9"> </span>ou<span class="_ _2"></span>r<span class="_ _9"> </span>pap<span class="_ _2"></span>er<span class="_ _9"> </span>is</div><div class="t m1 x0 h4 y153 ff1 fs2 fc1 sc0 ls0 ws0">the Negati<span class="_ _4"></span>ve<span class="_ _6"> </span>sampling algorithm<span class="_ _2"></span>,<span class="_ _6"> </span>which is an<span class="_ _6"> </span>extremely simple<span class="_ _6"> </span>training method that<span class="_ _6"> </span>learns accurate</div><div class="t m1 x0 h4 y154 ff1 fs2 fc1 sc0 ls0 ws0">representatio<span class="_ _2"></span>ns<span class="_ _6"> </span>especially for freq<span class="_ _2"></span>uent w<span class="_ _4"></span>o<span class="_ _2"></span>rds.</div><div class="t m1 x0 h4 y155 ff1 fs2 fc1 sc0 ls0 ws0">The<span class="_ _7"> </span>choice<span class="_ _9"> </span>of<span class="_ _7"> </span>the<span class="_ _9"> </span>trainin<span class="_ _2"></span>g<span class="_ _9"> </span>algo<span class="_ _2"></span>rithm<span class="_ _9"> </span>a<span class="_ _2"></span>nd<span class="_ _7"> </span>the<span class="_ _9"> </span>hyper-param<span class="_ _2"></span>eter selection<span class="_ _7"> </span>is<span class="_ _7"> </span>a task<span class="_ _7"> </span>speciﬁc<span class="_ _7"> </span>decision,</div><div class="t m1 x0 h4 y156 ff1 fs2 fc1 sc0 ls0 ws0">as<span class="_ _7"> </span>we<span class="_ _9"> </span>f<span class="_ _2"></span>ound<span class="_ _7"> </span>that<span class="_ _9"> </span>different<span class="_ _7"> </span>problems<span class="_ _9"> </span>have<span class="_ _7"> </span>dif<span class="_ _4"></span>feren<span class="_ _2"></span>t<span class="_ _9"> </span>optima<span class="_ _2"></span>l<span class="_ _9"> </span>hy<span class="_ _2"></span>perpar<span class="_ _2"></span>ameter<span class="_ _9"> </span>con<span class="_ _2"></span>ﬁgurations.<span class="_ _1d"> </span>In<span class="_ _9"> </span>o<span class="_ _2"></span>ur</div><div class="t m1 x0 h4 y157 ff1 fs2 fc1 sc0 ls0 ws0">experiments,<span class="_ _0"> </span>the<span class="_ _0"> </span>most<span class="_ _0"> </span>crucial<span class="_ _0"> </span>decisions<span class="_ _7"> </span>that<span class="_ _0"> </span>affect<span class="_ _0"> </span>t<span class="_ _4"></span>h<span class="_ _2"></span>e<span class="_ _0"> </span>perform<span class="_ _2"></span>ance<span class="_ _7"> </span>are<span class="_ _0"> </span>the<span class="_ _0"> </span>choice<span class="_ _0"> </span>of<span class="_ _7"> </span>th<span class="_ _2"></span>e<span class="_ _0"> </span>model</div><div class="t m1 x0 h4 y158 ff1 fs2 fc1 sc0 ls0 ws0">architecture<span class="_ _2"></span>,<span class="_ _6"> </span>the size of the vectors, the subsampling rate, and the size of the training window<span class="_ _3"></span>.</div><div class="t m1 x0 h4 y159 ff1 fs2 fc1 sc0 ls0 ws0">A<span class="_ _9"> </span>very interesting<span class="_ _9"> </span>result<span class="_ _9"> </span>of<span class="_ _9"> </span>this<span class="_ _9"> </span>work is<span class="_ _9"> </span>that<span class="_ _9"> </span>the<span class="_ _9"> </span>word vecto<span class="_ _2"></span>rs can<span class="_ _9"> </span>be<span class="_ _9"> </span>somewhat meanin<span class="_ _2"></span>gfully com-</div><div class="t m1 x0 h4 y15a ff1 fs2 fc1 sc0 ls0 ws0">bined<span class="_ _7"> </span>using<span class="_ _9"> </span>just<span class="_ _7"> </span>simple<span class="_ _9"> </span>vector<span class="_ _7"> </span>addition.<span class="_ _b"> </span>Anoth<span class="_ _2"></span>er<span class="_ _7"> </span>a<span class="_ _5"></span>pproa<span class="_ _2"></span>ch<span class="_ _9"> </span>for<span class="_ _7"> </span>learning<span class="_ _9"> </span>rep<span class="_ _2"></span>resentations<span class="_ _7"> </span>of<span class="_ _9"> </span>phrases</div><div class="t m1 x0 h4 y15b ff1 fs2 fc1 sc0 ls0 ws0">presented in th<span class="_ _2"></span>is paper is to<span class="_ _9"> </span>simply repr<span class="_ _2"></span>esent the phrases with<span class="_ _9"> </span>a single token.<span class="_ _7"> </span>Combination of the<span class="_ _2"></span>se</div><div class="t m1 x0 h4 y15c ff1 fs2 fc1 sc0 ls0 ws0">two appr<span class="_ _2"></span>oaches gives a p<span class="_ _2"></span>owerful yet simple<span class="_ _9"> </span>way how to<span class="_ _9"> </span>represen<span class="_ _2"></span>t longer<span class="_ _9"> </span>pieces o<span class="_ _2"></span>f text,<span class="_ _9"> </span>while h<span class="_ _2"></span>av-</div><div class="t m1 x0 h4 y15d ff1 fs2 fc1 sc0 ls0 ws0">ing<span class="_ _6"> </span>minimal<span class="_ _6"> </span>computatio<span class="_ _2"></span>nal<span class="_ _6"> </span>complexity<span class="_ _4"></span>. Our w<span class="_ _4"></span>o<span class="_ _2"></span>rk<span class="_ _6"> </span>can<span class="_ _6"> </span>thus<span class="_ _6"> </span>be s<span class="_ _5"></span>een as<span class="_ _6"> </span>complementary<span class="_ _6"> </span>to<span class="_ _6"> </span>the<span class="_ _6"> </span>e<span class="_ _4"></span>x<span class="_ _2"></span>isting</div><div class="t m1 x0 h4 y15e ff1 fs2 fc1 sc0 ls0 ws0">approa<span class="_ _2"></span>ch<span class="_ _6"> </span>that attempts to repre<span class="_ _2"></span>sent phrases using recursi<span class="_ _4"></span>ve matrix-vector operations [16].</div><div class="t m1 x0 h4 y3e ff1 fs2 fc1 sc0 ls0 ws0">W<span class="_ _3"></span>e made<span class="_ _6"> </span>the code<span class="_ _6"> </span>for<span class="_ _6"> </span>training the<span class="_ _6"> </span>word<span class="_ _6"> </span>and<span class="_ _6"> </span>phrase<span class="_ _6"> </span>vectors<span class="_ _6"> </span>based<span class="_ _6"> </span>on the<span class="_ _6"> </span>techniqu<span class="_ _2"></span>es<span class="_ _6"> </span>described<span class="_ _6"> </span>in<span class="_ _6"> </span>this</div><div class="t m1 x0 h4 y15f ff1 fs2 fc1 sc0 ls0 ws0">paper av<span class="_ _4"></span>ailable as an open<span class="_ _2"></span>-source project</div><div class="t m1 x80 h15 y160 ff1 fs6 fc1 sc0 ls0 ws0">4</div><div class="t m1 x81 h4 y15f ff1 fs2 fc1 sc0 ls0 ws0">.</div><div class="t m1 x2 h16 y10b ff1 fs8 fc1 sc0 ls0 ws0">4</div><div class="t m1 x40 hc y36 ff3 fs5 fc1 sc0 ls0 ws0">code.google.c<span class="_ _2"></span>om/p/word2vec</div><div class="t m1 x17 h4 y37 ff1 fs2 fc1 sc0 ls0 ws0">8</div><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",143.306,541.854,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:406.144000px;bottom:473.224000px;width:5.912000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,492.159,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:424.624000px;bottom:317.104000px;width:5.912000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf9" data-dest-detail='[9,"XYZ",108.135,300.162,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,0);position:absolute;left:447.424000px;bottom:112.864000px;width:10.952000px;height:7.952000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",124.275,59.6931,null]'><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(255,0,0);position:absolute;left:270.784000px;bottom:85.143800px;width:3.836000px;height:8.962600px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="code.google.com/p/word2vec"><div class="d m2" style="border-width:1.000000px;border-style:solid;border-color:rgb(0,255,255);position:absolute;left:122.584000px;bottom:59.223800px;width:140.912000px;height:8.072500px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf9" class="pf w0 h0" data-page-no="9"><div class="pc pc9 w0 h0"><div class="t m1 x0 h6 y66 ff2 fs3 fc1 sc0 ls0 ws0">Refer<span class="_ _4"></span>ences</div><div class="t m1 x7a ha yf3 ff1 fs5 fc1 sc0 ls0 ws0">[1]<span class="_ _1d"> </span>Y<span class="_ _1"></span>oshua Bengio, R<span class="_ _e"></span>´<span class="_ _5e"></span>ejean Duch<span class="_ _5"></span>arme, Pascal V<span class="_ _4"></span>incent, and Ch<span class="_ _5"></span>ristian Jan<span class="_ _4"></span>vin.<span class="_ _7"> </span>A neural prob<span class="_ _5"></span>abilistic language</div><div class="t m1 x7f ha yce ff1 fs5 fc1 sc0 ls0 ws0">model.<span class="_ _7"> </span><span class="ff14">The J<span class="_ _4"></span>ournal of Machine Learning Resear<span class="_ _4"></span>ch<span class="ff1">, 3:1137–115<span class="_ _5"></span>5,<span class="_ _9"> </span>200<span class="_ _5"></span>3.</span></span></div><div class="t m1 x7a ha y77 ff1 fs5 fc1 sc0 ls0 ws0">[2]<span class="_ _1d"> </span>Ronan<span class="_ _9"> </span>Collobert<span class="_ _9"> </span>and<span class="_ _7"> </span>Ja<span class="_ _5"></span>son<span class="_ _9"> </span>W<span class="_ _4"></span>eston.<span class="_ _1d"> </span>A<span class="_ _7"> </span>uniﬁed<span class="_ _9"> </span>architecture<span class="_ _9"> </span>for<span class="_ _7"> </span>n<span class="_ _5"></span>atural<span class="_ _9"> </span>language<span class="_ _7"> </span>p<span class="_ _5"></span>rocessing:<span class="_ _8"> </span>d<span class="_ _5"></span>eep<span class="_ _9"> </span>neu-</div><div class="t m1 x7f ha y3 ff1 fs5 fc1 sc0 ls0 ws0">ral<span class="_ _9"> </span>networks<span class="_ _9"> </span>wit<span class="_ _2"></span>h<span class="_ _9"> </span>multitask<span class="_ _7"> </span>learn<span class="_ _5"></span>ing.<span class="_ _c"> </span>I<span class="_ _5"></span>n<span class="_ _9"> </span><span class="ff14">Proceed<span class="_ _5"></span>ings<span class="_ _7"> </span>o<span class="_ _4"></span>f<span class="_ _7"> </span>the<span class="_ _9"> </span>25th<span class="_ _7"> </span>in<span class="_ _5"></span>ternational<span class="_ _9"> </span>confer<span class="_ _5"></span>ence<span class="_ _9"> </span>on<span class="_ _7"> </span>Mac<span class="_ _5"></span>hine</span></div><div class="t m1 x7f ha y144 ff14 fs5 fc1 sc0 ls0 ws0">learning<span class="ff1">, pages 160–1<span class="_ _5"></span>67.<span class="_ _9"> </span>A<span class="_ _4"></span>CM, 2008.</span></div><div class="t m1 x7a ha y161 ff1 fs5 fc1 sc0 ls0 ws0">[3]<span class="_ _1d"> </span>Xa<span class="_ _5"></span>vier Glorot, Antoine Bordes,<span class="_ _9"> </span>a<span class="_ _5"></span>nd Y<span class="_ _4"></span>os<span class="_ _5"></span>hua Bengio.<span class="_ _7"> </span>Domain<span class="_ _9"> </span>ad<span class="_ _5"></span>aptation for l<span class="_ _2"></span>arge-scale sen<span class="_ _5"></span>timent classi-</div><div class="t m1 x7f ha y81 ff1 fs5 fc1 sc0 ls0 ws0">ﬁcation:<span class="_ _9"> </span>A deep learning approach.<span class="_ _7"> </span>In <span class="ff14">ICML</span>, 51<span class="_ _5"></span>3–520, 2011.</div><div class="t m1 x7a ha y162 ff1 fs5 fc1 sc0 ls0 ws0">[4]<span class="_ _1d"> </span>Michae<span class="_ _5"></span>l U Gutmann and Aapo<span class="_ _6"> </span>Hy<span class="_ _5"></span>v<span class="_ _2"></span>¨<span class="_ _5e"></span>arinen.<span class="_ _7"> </span>Noise-contrasti<span class="_ _5"></span>ve estimation<span class="_ _6"> </span>of<span class="_ _6"> </span>u<span class="_ _5"></span>nnormalized statistical mod-</div><div class="t m1 x7f ha y163 ff1 fs5 fc1 sc0 ls0 ws0">els,<span class="_ _6"> </span>with<span class="_ _11"> </span>applications<span class="_ _11"> </span>to natural<span class="_ _11"> </span>image statistics. <span class="ff14">The<span class="_ _11"> </span>Journa<span class="_ _5"></span>l of<span class="_ _11"> </span>Machine<span class="_ _11"> </span>Learning Resear<span class="_ _4"></span>ch<span class="ff1">,<span class="_ _11"> </span>13:307–361,</span></span></div><div class="t m1 x7f ha y164 ff1 fs5 fc1 sc0 ls0 ws0">2012.</div><div class="t m1 x7a ha y165 ff1 fs5 fc1 sc0 ls0 ws0">[5]<span class="_ _1d"> </span>T<span class="_ _3"></span>omas<span class="_ _9"> </span>Mik<span class="_ _4"></span>olov<span class="_ _4"></span>,<span class="_ _9"> </span>Stefan K<span class="_ _5"></span>ombrink,<span class="_ _9"> </span>Luk<span class="_ _5"></span>as<span class="_ _9"> </span>Bur<span class="_ _4"></span>get,<span class="_ _9"> </span>Jan Cernocky<span class="_ _4"></span>,<span class="_ _9"> </span>and Sanjee<span class="_ _5"></span>v<span class="_ _9"> </span>Khu<span class="_ _5"></span>danpur<span class="_ _4"></span>.<span class="_ _0"> </span>E<span class="_ _2"></span>xtensions<span class="_ _9"> </span>o<span class="_ _4"></span>f</div><div class="t m1 x7f ha y166 ff1 fs5 fc1 sc0 ls0 ws0">recurrent<span class="_ _9"> </span>neural<span class="_ _9"> </span>netw<span class="_ _5"></span>ork<span class="_ _9"> </span>language<span class="_ _9"> </span>model.<span class="_ _8"> </span>In<span class="_ _9"> </span><span class="ff14">Acoustics,<span class="_ _9"> </span>Speech<span class="_ _9"> </span>and<span class="_ _9"> </span>Signal<span class="_ _9"> </span>Pr<span class="_ _4"></span>ocessing<span class="_ _9"> </span>(ICASSP),<span class="_ _9"> </span>201<span class="_ _5"></span>1</span></div><div class="t m1 x7f ha y3f ff14 fs5 fc1 sc0 ls0 ws0">IEEE International Confer<span class="_ _4"></span>ence on<span class="ff1">, pages 5528–5531. IEE<span class="_ _2"></span>E, 2011.</span></div><div class="t m1 x7a ha y167 ff1 fs5 fc1 sc0 ls0 ws0">[6]<span class="_ _1d"> </span>T<span class="_ _3"></span>omas<span class="_ _9"> </span>Mikolo<span class="_ _5"></span>v<span class="_ _4"></span>,<span class="_ _9"> </span>Anoop<span class="_ _9"> </span>Deoras,<span class="_ _9"> </span>Daniel P<span class="_ _2"></span>ov<span class="_ _5"></span>ey<span class="_ _3"></span>,<span class="_ _9"> </span>L<span class="_ _2"></span>ukas<span class="_ _9"> </span>Bur<span class="_ _5"></span>get<span class="_ _9"> </span>and Jan<span class="_ _9"> </span>Cernocky<span class="_ _3"></span>.<span class="_ _b"> </span>St<span class="_ _2"></span>rategies for<span class="_ _9"> </span>T<span class="_ _5"></span>raining</div><div class="t m1 x7f ha y168 ff1 fs5 fc1 sc0 ls0 ws0">Large<span class="_ _11"> </span>S<span class="_ _2"></span>cale Neu<span class="_ _5"></span>ral Network<span class="_ _6"> </span>Lang<span class="_ _5"></span>uage Models.<span class="_ _9"> </span>In Proc.<span class="_ _11"> </span><span class="ff14">Automatic Spee<span class="_ _5"></span>ch Reco<span class="_ _5"></span>gnition and<span class="_ _6"> </span>Und<span class="_ _5"></span>erstand-</span></div><div class="t m1 x7f ha y169 ff14 fs5 fc1 sc0 ls0 ws0">ing<span class="ff1">, 2011.</span></div><div class="t m1 x7a ha y13 ff1 fs5 fc1 sc0 ls0 ws0">[7]<span class="_ _1d"> </span>T<span class="_ _3"></span>omas Mikolov<span class="_ _3"></span>.<span class="_ _0"> </span>Statistical Langu<span class="_ _5"></span>age Models Based on Neural<span class="_ _9"> </span>N<span class="_ _5"></span>etworks.<span class="_ _7"> </span><span class="ff14">PhD the<span class="_ _5"></span>sis, PhD Thesis, B<span class="_ _2"></span>rno</span></div><div class="t m1 x7f ha y42 ff14 fs5 fc1 sc0 ls0 ws0">University of T<span class="_ _3"></span>echnolo<span class="_ _4"></span>gy<span class="ff1">,<span class="_ _9"> </span>20<span class="_ _5"></span>12.</span></div><div class="t m1 x7a ha y16a ff1 fs5 fc1 sc0 ls0 ws0">[8]<span class="_ _1d"> </span>T<span class="_ _3"></span>omas Mikolov<span class="_ _3"></span>,<span class="_ _9"> </span>Kai<span class="_ _6"> </span>Che<span class="_ _5"></span>n, Greg Corrado, and Jef<span class="_ _4"></span>frey Dean.<span class="_ _7"> </span>Ef<span class="_ _4"></span>ﬁ<span class="_ _2"></span>cient estimation of w<span class="_ _4"></span>ord<span class="_ _9"> </span>rep<span class="_ _5"></span>resentations</div><div class="t m1 x7f ha yc6 ff1 fs5 fc1 sc0 ls0 ws0">in vector space<span class="_ _5"></span>.<span class="_ _7"> </span><span class="ff14">ICLR W<span class="_ _3"></span>orkshop<span class="ff1">,<span class="_ _9"> </span>2<span class="_ _4"></span>013.</span></span></div><div class="t m1 x7a ha y16b ff1 fs5 fc1 sc0 ls0 ws0">[9]<span class="_ _1d"> </span>T<span class="_ _3"></span>omas<span class="_ _7"> </span>M<span class="_ _5"></span>ikolo<span class="_ _4"></span>v<span class="_ _4"></span>,<span class="_ _7"> </span>W<span class="_ _4"></span>en-tau<span class="_ _9"> </span>Y<span class="_ _4"></span>ih<span class="_ _9"> </span>and<span class="_ _7"> </span>Ge<span class="_ _5"></span>offre<span class="_ _4"></span>y<span class="_ _7"> </span>Zweig.<span class="_ _1d"> </span>Linguistic<span class="_ _7"> </span>Re<span class="_ _4"></span>gularities<span class="_ _7"> </span>i<span class="_ _5"></span>n<span class="_ _9"> </span>Continuous<span class="_ _7"> </span>Spac<span class="_ _5"></span>e<span class="_ _9"> </span>W<span class="_ _4"></span>ord</div><div class="t m1 x7f ha y8e ff1 fs5 fc1 sc0 ls0 ws0">Representations.<span class="_ _7"> </span>In <span class="ff14">Pr<span class="_ _4"></span>oceedings of N<span class="_ _5"></span>AACL HL<span class="_ _4"></span>T<span class="_ _2"></span><span class="ff1">, 201<span class="_ _5"></span>3.</span></span></div><div class="t m1 x0 ha y16c ff1 fs5 fc1 sc0 ls0 ws0">[10]<span class="_ _b"> </span>Andriy<span class="_ _9"> </span>Mnih<span class="_ _9"> </span>and<span class="_ _9"> </span>Geoffre<span class="_ _4"></span>y<span class="_ _9"> </span>E<span class="_ _9"> </span>Hinton.<span class="_ _b"> </span>A<span class="_ _9"> </span>scalable<span class="_ _9"> </span>hierarch<span class="_ _5"></span>ical<span class="_ _9"> </span>distributed<span class="_ _9"> </span>lan<span class="_ _5"></span>guage<span class="_ _9"> </span>model.<span class="_ _b"> </span><span class="ff14">Advances<span class="_ _9"> </span>in</span></div><div class="t m1 x7f ha y48 ff14 fs5 fc1 sc0 ls0 ws0">neura<span class="_ _5"></span>l information pr<span class="_ _5"></span>ocessing systems<span class="ff1">, 21:1081–1<span class="_ _5"></span>088,<span class="_ _9"> </span>2<span class="_ _5"></span>009.</span></div><div class="t m1 x0 ha y95 ff1 fs5 fc1 sc0 ls0 ws0">[11]<span class="_ _b"> </span>Andriy<span class="_ _9"> </span>Mnih and<span class="_ _9"> </span>Y<span class="_ _3"></span>ee Whye<span class="_ _9"> </span>T<span class="_ _4"></span>eh.<span class="_ _0"> </span>A fast<span class="_ _9"> </span>a<span class="_ _5"></span>nd simple<span class="_ _9"> </span>algorithm for<span class="_ _9"> </span>training neural<span class="_ _9"> </span>p<span class="_ _5"></span>robabilistic<span class="_ _9"> </span>la<span class="_ _5"></span>nguage</div><div class="t m1 x7f ha y16d ff1 fs5 fc1 sc0 ls0 ws0">models.<span class="_ _7"> </span><span class="ff14">arXiv pr<span class="_ _4"></span>eprint arXiv:1206.6426<span class="ff1">, 2012.</span></span></div><div class="t m1 x0 ha y16e ff1 fs5 fc1 sc0 ls0 ws0">[12]<span class="_ _b"> </span>F<span class="_ _2"></span>rederic<span class="_ _9"> </span>M<span class="_ _5"></span>orin<span class="_ _9"> </span>and Y<span class="_ _4"></span>osh<span class="_ _5"></span>ua<span class="_ _9"> </span>Bengio.<span class="_ _8"> </span>Hierarchical probabilistic<span class="_ _9"> </span>neural<span class="_ _9"> </span>netw<span class="_ _5"></span>ork<span class="_ _9"> </span>langua<span class="_ _5"></span>ge<span class="_ _9"> </span>model.<span class="_ _8"> </span>In <span class="ff14">P<span class="_ _2"></span>r<span class="_ _4"></span>o-</span></div><div class="t m1 x7f ha y16f ff14 fs5 fc1 sc0 ls0 ws0">ceedings of the international workshop on artiﬁcial intelligence and statistics<span class="ff1">, pages 246–2<span class="_ _5"></span>52, 2005.</span></div><div class="t m1 x0 ha y170 ff1 fs5 fc1 sc0 ls0 ws0">[13]<span class="_ _b"> </span>David<span class="_ _7"> </span>E<span class="_ _7"> </span>Rumelhart,<span class="_ _0"> </span>Geoffre<span class="_ _5"></span>y<span class="_ _7"> </span>E<span class="_ _7"> </span>Hintont,<span class="_ _0"> </span>and<span class="_ _7"> </span>Ronald<span class="_ _7"> </span>J<span class="_ _7"> </span>Williams.<span class="_ _10"> </span>Learning<span class="_ _7"> </span>representations<span class="_ _0"> </span>b<span class="_ _4"></span>y<span class="_ _0"> </span>b<span class="_ _4"></span>ack-</div><div class="t m1 x7f ha y4e ff1 fs5 fc1 sc0 ls0 ws0">propagating errors.<span class="_ _7"> </span><span class="ff14">Natur<span class="_ _4"></span>e<span class="ff1">, 323(6088<span class="_ _5"></span>):533–536,<span class="_ _9"> </span>1<span class="_ _5"></span>986.</span></span></div><div class="t m1 x0 ha y22 ff1 fs5 fc1 sc0 ls0 ws0">[14]<span class="_ _b"> </span>Holger Schwenk.<span class="_ _7"> </span>Continuous space language models.<span class="_ _7"> </span><span class="ff14">Computer Speec<span class="_ _4"></span>h<span class="_ _9"> </span>an<span class="_ _5"></span>d Languag<span class="_ _4"></span>e<span class="ff1">,<span class="_ _9"> </span>vol.<span class="_ _6"> </span>21<span class="_ _5"></span>, 2007.</span></span></div><div class="t m1 x0 ha y171 ff1 fs5 fc1 sc0 ls0 ws0">[15]<span class="_ _b"> </span>Ri<span class="_ _2"></span>chard<span class="_ _9"> </span>Socher<span class="_ _4"></span>,<span class="_ _7"> </span>Clif<span class="_ _4"></span>f<span class="_ _9"> </span>C.<span class="_ _9"> </span>Lin,<span class="_ _7"> </span>Andre<span class="_ _4"></span>w<span class="_ _9"> </span>Y<span class="_ _3"></span>.<span class="_ _9"> </span>Ng,<span class="_ _9"> </span>and<span class="_ _7"> </span>Ch<span class="_ _5"></span>ristopher<span class="_ _9"> </span>D.<span class="_ _9"> </span>Manning.<span class="_ _1d"> </span>Parsing<span class="_ _9"> </span>natural<span class="_ _9"> </span>scenes<span class="_ _9"> </span>and</div><div class="t m1 x7f ha y172 ff1 fs5 fc1 sc0 ls0 ws0">natural language with recursi<span class="_ _5"></span>ve neu<span class="_ _5"></span>ral networks.<span class="_ _7"> </span>In <span class="ff14">Pr<span class="_ _4"></span>oceedings of the 26th Internationa<span class="_ _5"></span>l Conferen<span class="_ _5"></span>ce on</span></div><div class="t m1 x7f ha ydb ff14 fs5 fc1 sc0 ls0 ws0">Mach<span class="_ _5"></span>ine Learning (ICML<span class="_ _2"></span>)<span class="ff1">, v<span class="_ _4"></span>olume<span class="_ _9"> </span>2<span class="_ _5"></span>, 2011.</span></div><div class="t m1 x0 ha ya3 ff1 fs5 fc1 sc0 ls0 ws0">[16]<span class="_ _b"> </span>Ri<span class="_ _2"></span>chard Socher<span class="_ _5"></span>,<span class="_ _9"> </span>Brod<span class="_ _5"></span>y<span class="_ _9"> </span>H<span class="_ _5"></span>uv<span class="_ _4"></span>al,<span class="_ _9"> </span>Christopher D.<span class="_ _9"> </span>Man<span class="_ _5"></span>ning,<span class="_ _9"> </span>and Andre<span class="_ _5"></span>w<span class="_ _9"> </span>Y<span class="_ _1"></span>. Ng.<span class="_ _0"> </span>Semantic C<span class="_ _2"></span>ompositionality</div><div class="t m1 x7f ha y25 ff1 fs5 fc1 sc0 ls0 ws0">Through Recursi<span class="_ _5"></span>ve Matrix-V<span class="_ _1"></span>ector Spaces.<span class="_ _7"> </span>In <span class="ff14">Pr<span class="_ _4"></span>oceedings of the 201<span class="_ _5"></span>2 Confer<span class="_ _4"></span>ence on Empirical Methods</span></div><div class="t m1 x7f ha y173 ff14 fs5 fc1 sc0 ls0 ws0">in Natural Langua<span class="_ _4"></span>ge P<span class="_ _2"></span>r<span class="_ _4"></span>ocessing (EMNLP)<span class="ff1">, 2012.</span></div><div class="t m1 x0 ha y174 ff1 fs5 fc1 sc0 ls0 ws0">[17]<span class="_ _b"> </span>Joseph Turian, Le<span class="_ _4"></span>v<span class="_ _9"> </span>Ratino<span class="_ _4"></span>v<span class="_ _4"></span>, and Y<span class="_ _4"></span>osh<span class="_ _5"></span>ua Bengio.<span class="_ _7"> </span>W<span class="_ _4"></span>ord representations:<span class="_ _9"> </span>a simple and<span class="_ _9"> </span>g<span class="_ _4"></span>eneral<span class="_ _9"> </span>m<span class="_ _5"></span>ethod for</div><div class="t m1 x7f ha y120 ff1 fs5 fc1 sc0 ls0 ws0">semi-supervised<span class="_ _9"> </span>learning.<span class="_ _1d"> </span>In<span class="_ _9"> </span><span class="ff14">Pr<span class="_ _4"></span>oceedings<span class="_ _9"> </span>of<span class="_ _9"> </span>the<span class="_ _9"> </span>48th<span class="_ _7"> </span>Ann<span class="_ _5"></span>ual<span class="_ _9"> </span>Meeting<span class="_ _9"> </span>of<span class="_ _9"> </span>the<span class="_ _9"> </span>Association<span class="_ _9"> </span>for<span class="_ _9"> </span>Computa-</span></div><div class="t m1 x7f ha y3a ff14 fs5 fc1 sc0 ls0 ws0">tional Linguistics<span class="ff1">, pages 384–39<span class="_ _5"></span>4.<span class="_ _9"> </span>A<span class="_ _5"></span>ssociation for Computational Linguistics, 2010.</span></div><div class="t m1 x0 ha y29 ff1 fs5 fc1 sc0 ls0 ws0">[18]<span class="_ _b"> </span>P<span class="_ _2"></span>eter<span class="_ _9"> </span>D<span class="_ _5"></span>.<span class="_ _9"> </span>T<span class="_ _4"></span>urney<span class="_ _9"> </span>a<span class="_ _4"></span>nd<span class="_ _9"> </span>Patrick<span class="_ _9"> </span>P<span class="_ _4"></span>antel.<span class="_ _8"> </span>From<span class="_ _9"> </span>freque<span class="_ _5"></span>ncy<span class="_ _9"> </span>to meaning:<span class="_ _0"> </span>V<span class="_ _1"></span>ector<span class="_ _9"> </span>space models<span class="_ _9"> </span>of<span class="_ _9"> </span>semantics.<span class="_ _8"> </span>In</div><div class="t m1 x7f ha y175 ff14 fs5 fc1 sc0 ls0 ws0">J<span class="_ _5"></span>ournal of Artiﬁcial Intelligence Resear<span class="_ _4"></span>ch<span class="ff1">, 37:141-188, 2010.</span></div><div class="t m1 x0 ha y176 ff1 fs5 fc1 sc0 ls0 ws0">[19]<span class="_ _b"> </span>P<span class="_ _2"></span>eter D. T<span class="_ _4"></span>urney<span class="_ _3"></span>.<span class="_ _7"> </span>Distribu<span class="_ _5"></span>tional semantics<span class="_ _6"> </span>be<span class="_ _4"></span>yond words:<span class="_ _9"> </span>Supervised learning of<span class="_ _6"> </span>a<span class="_ _5"></span>nalogy and paraphrase.</div><div class="t m1 x7f ha ya5 ff1 fs5 fc1 sc0 ls0 ws0">In <span class="ff14">T<span class="_ _4"></span>ransactions of the Association for Computational Linguistics (T<span class="_ _4"></span>ACL)<span class="ff1">,<span class="_ _6"> </span>35<span class="_ _5"></span>3–366, 2013.</span></span></div><div class="t m1 x0 ha y5a ff1 fs5 fc1 sc0 ls0 ws0">[20]<span class="_ _b"> </span>Jason W<span class="_ _4"></span>eston,<span class="_ _11"> </span>S<span class="_ _2"></span>amy<span class="_ _6"> </span>Beng<span class="_ _5"></span>io, and Nico<span class="_ _5"></span>las Usun<span class="_ _5"></span>ier<span class="_ _4"></span>.<span class="_ _9"> </span>W<span class="_ _2"></span>sabie:<span class="_ _9"> </span>Scaling<span class="_ _11"> </span>up to<span class="_ _6"> </span>lar<span class="_ _4"></span>ge vo<span class="_ _5"></span>cabulary<span class="_ _11"> </span>i<span class="_ _2"></span>mage ann<span class="_ _5"></span>ota-</div><div class="t m1 x7f ha y15a ff1 fs5 fc1 sc0 ls0 ws0">tion. In <span class="ff14">Pr<span class="_ _4"></span>oceedings<span class="_ _11"> </span>of the<span class="_ _11"> </span>T<span class="_ _4"></span>wenty-Second<span class="_ _11"> </span>international jo<span class="_ _5"></span>int<span class="_ _6"> </span>co<span class="_ _5"></span>nfer<span class="_ _4"></span>ence on<span class="_ _11"> </span>Artiﬁcial<span class="_ _6"> </span>Intellig<span class="_ _5"></span>ence-V<span class="_ _3"></span>olume</span></div><div class="t m1 x7f ha y177 ff14 fs5 fc1 sc0 ls0 ws0">V<span class="_ _3"></span>olume Thr<span class="_ _4"></span>ee<span class="ff1">,<span class="_ _9"> </span>p<span class="_ _4"></span>ages 2764–2770. AAAI Press, 2011.</span></div><div class="t m1 x17 h4 y37 ff1 fs2 fc1 sc0 ls0 ws0">9</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
</div>
<div class="loading-indicator">
<img alt="" src="pdf2htmlEX-64x64.png">
</div>
</body>
</html>
