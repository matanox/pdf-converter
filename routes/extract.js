// Generated by CoffeeScript 1.4.0
var css, filterImages, filterNoText, html, isImage, model, output, soup, timer, util;

require("fs");

util = require("../util");

timer = require("../timer");

css = require("../css");

html = require("../html");

model = require("../model");

soup = require("../soup");

output = require("../output");

isImage = function(text) {
  return util.startsWith(text, "<img ");
};

filterImages = function(ourDivRepresentation) {
  var div, filtered, _i, _len;
  filtered = [];
  for (_i = 0, _len = ourDivRepresentation.length; _i < _len; _i++) {
    div = ourDivRepresentation[_i];
    if (!isImage(div.text)) {
      filtered.push(div);
    }
  }
  return filtered;
};

filterNoText = function(ourDivRepresentation) {
  var div, filtered, _i, _len;
  filtered = [];
  for (_i = 0, _len = ourDivRepresentation.length; _i < _len; _i++) {
    div = ourDivRepresentation[_i];
    if (!(div.text.length === 0)) {
      filtered.push(div);
    }
  }
  return filtered;
};

exports.go = function(req, res) {
  var div, divsAndStyles, name, outputHtml, path, plainText, rawHtml, rawRelevantDivs, realStyles, token, tokenizedDivs, tokens, _i, _j, _k, _len, _len1, _len2;
  timer.start('Extraction from html stage A');
  path = '../local-copies/' + 'html-converted/';
  name = req.query.name;
  rawHtml = fs.readFileSync(path + name + '/' + name + ".html").toString();
  realStyles = css.simpleFetchStyles(rawHtml, path + name + '/');
  rawRelevantDivs = html.removeOuterDivs(rawHtml);
  divsAndStyles = (function() {
    var _i, _len, _results;
    _results = [];
    for (_i = 0, _len = rawRelevantDivs.length; _i < _len; _i++) {
      div = rawRelevantDivs[_i];
      _results.push(html.representDiv(div));
    }
    return _results;
  })();
  divsAndStyles = filterImages(divsAndStyles);
  for (_i = 0, _len = divsAndStyles.length; _i < _len; _i++) {
    div = divsAndStyles[_i];
    html.stripSpanWrappers(div);
  }
  divsAndStyles = filterNoText(divsAndStyles);
  tokenizedDivs = (function() {
    var _j, _len1, _results;
    _results = [];
    for (_j = 0, _len1 = divsAndStyles.length; _j < _len1; _j++) {
      div = divsAndStyles[_j];
      _results.push(html.tokenize(div));
    }
    return _results;
  })();
  tokens = [];
  for (_j = 0, _len1 = tokenizedDivs.length; _j < _len1; _j++) {
    div = tokenizedDivs[_j];
    for (_k = 0, _len2 = div.length; _k < _len2; _k++) {
      token = div[_k];
      tokens.push(token);
    }
  }
  /*
    # Unite words that break across divs
    normalizedTokens = tokens.reduce(x, y) -> 
      if JSON.stringify(x.styles) !=== JSON.stringify(y.styles)
        console.log("In normalizing tokens: styles defer so token couple will not be normalized")
      else
        if not x.text[charAt(x.text.length-1)].test(/\s/) # if token text does *not* end with a space character
        	if y.text[charAt(0).test(/\s/)]                # and the next token text *does* end with a space char
        	  s
  */

  plainText = tokens.map(function(x) {
    return x.text;
  });
  plainText = plainText.reduce(function(x, y) {
    return x + ' ' + y;
  });
  console.log(plainText);
  timer.end('Extraction from html stage A');
  timer.start('Extraction from html stage B');
  outputHtml = soup.build("aaa");
  timer.end('Extraction from html stage B');
  return output.serveOutput(outputHtml, name, res);
};
