// Generated by CoffeeScript 1.4.0
var parseCssClasses, util;

util = require('./util');

exports.removeOuterDivs = function(string) {
  var regex;
  regex = new RegExp('<div((?!div).)*</div>', 'g');
  return string.match(regex);
};

parseCssClasses = function(xmlNode) {
  var cssClasses, cssClassesString, regex;
  regex = new RegExp("<div class=\".*?\"", 'g');
  cssClassesString = xmlNode.match(regex);
  cssClassesString = util.strip(cssClassesString[0], "<div class=\"", "\"");
  regex = new RegExp("\\b\\S+?\\b", 'g');
  cssClasses = cssClassesString.match(regex);
  return cssClasses;
};

exports.representDiv = function(xmlNode) {
  var styles, text;
  text = util.parseElementText(xmlNode);
  styles = parseCssClasses(xmlNode);
  return {
    text: text,
    styles: styles
  };
};

exports.stripSpanWrappers = function(div) {
  var spanBegin, spanEnd;
  spanBegin = new RegExp('<span.*?>', 'g');
  spanEnd = new RegExp('</span>', 'g');
  div.text = div.text.replace(spanBegin, '');
  return div.text = div.text.replace(spanEnd, '');
};

exports.mergeTokens = function(x, y) {
  var merged;
  console.log("Merging");
  merged = util.clone(x);
  merged.text = x.text + y.text;
  console.dir(x);
  console.dir(y);
  console.dir(merged);
  console.log("end merge");
  return merged;
};

exports.tokenize = function(string) {
  var filterEmptyString, splitByPrefixChar, splitBySuffixChar, token, tokenize, tokens, _i, _len;
  splitBySuffixChar = function(inputTokens) {
    var endsWithPunctuation, punctuation, text, token, tokens, _i, _len;
    punctuation = [',', ':', ';', '.', ')'];
    tokens = [];
    for (_i = 0, _len = inputTokens.length; _i < _len; _i++) {
      token = inputTokens[_i];
      switch (token.metaType) {
        case 'delimiter':
          tokens.push(token);
          break;
        case 'regular':
          text = token.text;
          endsWithPunctuation = util.endsWithAnyOf(text, punctuation);
          if (endsWithPunctuation && (text.length > 1)) {
            tokens.push({
              'metaType': 'regular',
              'text': text.slice(0, text.length - 1)
            });
            tokens.push({
              'metaType': 'regular',
              'text': text.slice(text.length - 1)
            });
          } else {
            tokens.push(token);
          }
          break;
        default:
          throw 'Invalid token meta-type encountered';
          util.logObject(token);
      }
    }
    return tokens;
  };
  splitByPrefixChar = function(inputTokens) {
    var punctuation, startsWithPunctuation, text, token, tokens, _i, _len;
    punctuation = ['('];
    tokens = [];
    for (_i = 0, _len = inputTokens.length; _i < _len; _i++) {
      token = inputTokens[_i];
      switch (token.metaType) {
        case 'delimiter':
          tokens.push(token);
          break;
        case 'regular':
          text = token.text;
          startsWithPunctuation = util.startsWithAnyOf(text, punctuation);
          if (startsWithPunctuation && (text.length > 1)) {
            tokens.push({
              'metaType': 'regular',
              'text': text.slice(0, 1)
            });
            tokens.push({
              'metaType': 'regular',
              'text': text.slice(1)
            });
          } else {
            tokens.push(token);
          }
          break;
        default:
          throw "Invalid token meta-type encountered";
          util.logObject(token);
      }
    }
    return tokens;
  };
  filterEmptyString = function(tokens) {
    var filtered, token, _i, _len;
    filtered = [];
    for (_i = 0, _len = tokens.length; _i < _len; _i++) {
      token = tokens[_i];
      if (token.length > 0) {
        filtered.push(token);
      }
    }
    return filtered;
  };
  tokenize = function(string) {
    var char, i, insideDelimiter, insideWord, tokens, word, _i, _ref;
    insideWord = false;
    insideDelimiter = false;
    tokens = [];
    if (string.length === 0) {
      return [];
    }
    for (i = _i = 0, _ref = string.length - 1; 0 <= _ref ? _i <= _ref : _i >= _ref; i = 0 <= _ref ? ++_i : --_i) {
      char = string.charAt(i);
      if (util.isAnySpaceChar(char)) {
        if (insideWord) {
          tokens.push({
            'metaType': 'regular',
            'text': word
          });
          insideWord = false;
        }
        if (!insideDelimiter) {
          tokens.push({
            'metaType': 'delimiter'
          });
          insideDelimiter = true;
        }
      } else {
        if (insideDelimiter) {
          insideDelimiter = false;
        }
        if (insideWord) {
          word = word.concat(char);
        } else {
          word = char;
          insideWord = true;
        }
      }
    }
    if (insideWord) {
      tokens.push({
        'metaType': 'regular',
        'text': word
      });
    }
    return tokens;
  };
  tokens = tokenize(string);
  tokens = splitBySuffixChar(tokens);
  tokens = splitByPrefixChar(tokens);
  for (_i = 0, _len = tokens.length; _i < _len; _i++) {
    token = tokens[_i];
    if (token.metaType === 'regular') {
      if (token.text.length === 0) {
        throw "error in tokenize";
      }
    }
  }
  return tokens;
};
