<!DOCTYPE html>
<!-- Created by pdf2htmlEX (https://github.com/coolwanglu/pdf2htmlex) -->
<html>
<head>
<meta charset="utf-8">
<meta name="generator" content="pdf2htmlEX">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<link rel="stylesheet" href="base.min.css"/>
<link rel="stylesheet" href="fancy.min.css"/>
<link rel="stylesheet" href="nihms363554.css"/>
<script src="compatibility.min.js"></script>
<script src="pdf2htmlEX.min.js"></script>
<script>
try{
  pdf2htmlEX.defaultViewer = new pdf2htmlEX.Viewer({});
}catch(e){}
</script>
<title></title>
</head>
<body>
<div id="sidebar">
<div id="outline">
</div>
</div>
<div id="page-container">
<div id="pf1" class="pf w0 h0" data-page-no="1"><div class="pc pc1 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bg1.png"/><div class="t m0 x1 h2 y1 ff1 fs0 fc0 sc0 ls0 ws0">EVENT SEGMENTATION</div><div class="t m0 x1 h3 y2 ff1 fs1 fc0 sc0 ls0 ws0">Jeffrey M. Zacks</div><div class="t m0 x2 h4 y3 ff2 fs2 fc0 sc0 ls0 ws0">i</div><div class="t m0 x3 h3 y2 ff2 fs1 fc0 sc0 ls0 ws0"> and <span class="ff1">Khena M. Swallow</span></div><div class="t m0 x1 h5 y4 ff2 fs1 fc0 sc0 ls0 ws0">Washington University in Saint Louis</div><div class="t m0 x1 h6 y5 ff1 fs3 fc0 sc0 ls0 ws0">Abstract</div><div class="t m0 x4 h7 y6 ff3 fs1 fc0 sc0 ls0 ws0">One way to understand something is to break it up into parts. New research indicates that</div><div class="t m0 x4 h7 y7 ff3 fs1 fc0 sc0 ls0 ws0">segmenting ongoing activity into meaningful events is a core component of ongoing perception,</div><div class="t m0 x4 h7 y8 ff3 fs1 fc0 sc0 ls0 ws0">with consequences for memory and learning. Behavioral and neuroimaging data suggest that event</div><div class="t m0 x4 h7 y9 ff3 fs1 fc0 sc0 ls0 ws0">segmentation is automatic and that people spontaneously segment activity into hierarchically</div><div class="t m0 x4 h7 ya ff3 fs1 fc0 sc0 ls0 ws0">organized parts and sub-parts. This segmentation depends on the bottom-up processing of sensory</div><div class="t m0 x4 h7 yb ff3 fs1 fc0 sc0 ls0 ws0">features such as movement, and on the top-down processing of conceptual features such as actors’</div><div class="t m0 x4 h7 yc ff3 fs1 fc0 sc0 ls0 ws0">goals. How people segment activity affects what they remember later; as a result, those who</div><div class="t m0 x4 h7 yd ff3 fs1 fc0 sc0 ls0 ws0">identify appropriate event boundaries during perception tend to remember more and learn more</div><div class="t m0 x4 h7 ye ff3 fs1 fc0 sc0 ls0 ws0">proficiently.</div><div class="t m0 x1 h3 yf ff1 fs1 fc0 sc0 ls0 ws0">Keywords</div><div class="t m0 x4 h7 y10 ff3 fs1 fc0 sc0 ls0 ws0">event perception; segmentation; motion; intentions</div><div class="t m0 x1 h6 y11 ff1 fs3 fc0 sc0 ls0 ws0">EVENT SEGMENTATION</div><div class="t m0 x5 h7 y12 ff3 fs1 fc0 sc0 ls0 ws0">Look at the scene depicted in Figure 1. Though most viewers will eventually figure out what</div><div class="t m0 x5 h7 y13 ff3 fs1 fc0 sc0 ls0 ws0">is shown, many will have an easier time understanding the alternative version shown in</div><div class="t m0 x5 h7 y14 ff3 fs1 fc0 sc0 ls0 ws0">Figure 2. What’s the difference? The first picture fractures the scene in a way that obscures</div><div class="t m0 x5 h7 y15 ff3 fs1 fc0 sc0 ls0 ws0">its natural part structure, whereas the second respects that structure. For quite a while</div><div class="t m0 x5 h7 y16 ff3 fs1 fc0 sc0 ls0 ws0">psychologists have known that in order to recognize or understand an object people often</div><div class="t m0 x5 h7 y17 ff3 fs1 fc0 sc0 ls0 ws0">segment it into its spatial parts (e.g., Biederman, 1987). A new body of research has shown</div><div class="t m0 x5 h7 y18 ff3 fs1 fc0 sc0 ls0 ws0">that just as segmenting in <span class="ff4">space</span> is important for understanding objects, segmenting in <span class="ff4">time</span> is</div><div class="t m0 x5 h7 y19 ff3 fs1 fc0 sc0 ls0 ws0">important for understanding events.</div><div class="t m0 x5 h7 y1a ff3 fs1 fc0 sc0 ls0 ws0">Event segmentation is the process by which people parse a continuous stream of activity into</div><div class="t m0 x5 h7 y1b ff3 fs1 fc0 sc0 ls0 ws0">meaningful events. Recent developments in perceptual psychology and cognitive</div><div class="t m0 x5 h7 y1c ff3 fs1 fc0 sc0 ls0 ws0">neuroscience have provided new insights into the role of event segmentation in human</div><div class="t m0 x5 h7 y1d ff3 fs1 fc0 sc0 ls0 ws0">cognition. We will review three. First, event segmentation appears to be an automatic,</div><div class="t m0 x5 h7 y1e ff3 fs1 fc0 sc0 ls0 ws0">ongoing component of human perception. Second, segmentation during perception scaffolds</div><div class="t m0 x5 h7 y1f ff3 fs1 fc0 sc0 ls0 ws0">later memory and learning. Finally, specialized neural mechanisms identify event</div><div class="t m0 x5 h7 y20 ff3 fs1 fc0 sc0 ls0 ws0">boundaries by tracking significant changes in physical and social features.</div><div class="t m0 x1 h6 y21 ff1 fs3 fc0 sc0 ls0 ws0">SEGMENTATION IS AUTOMATIC</div><div class="t m0 x5 h7 y22 ff3 fs1 fc0 sc0 ls0 ws0">Much of the research on event segmentation has used variants of a procedure developed by</div><div class="t m0 x5 h7 y23 ff3 fs1 fc0 sc0 ls0 ws0">Newtson (1976). In this procedure participants watch a movie of some activity and press a</div><div class="t m0 x5 h7 y24 ff3 fs1 fc0 sc0 ls0 ws0">button whenever—in their judgment—one meaningful event ends and another event begins.</div><div class="t m0 x5 h7 y25 ff3 fs1 fc0 sc0 ls0 ws0">This task produces event boundary judgments that are reliable across viewers and within</div><div class="t m0 x1 h8 y26 ff2 fs4 fc0 sc0 ls0 ws0">i</div><div class="t m0 x6 h4 y27 ff3 fs2 fc0 sc0 ls0 ws0"> Address correspondence to Jeffrey M. Zacks, Department of Psychology, Washington University, Saint Louis MO 63130.</div><div class="t m0 x1 h4 y28 ff3 fs2 fc0 sc0 ls0 ws0">jzacks@artsci.wustl.edu.</div><div class="t m0 x7 h9 y29 ff3 fs5 fc0 sc0 ls0 ws0">NIH Public Access</div><div class="t m0 x7 ha y2a ff5 fs0 fc0 sc0 ls0 ws0">Author Manuscript</div><div class="t m0 x7 hb y2b ff4 fs6 fc1 sc0 ls0 ws0">Curr Dir Psychol Sci<span class="ff3">. Author manuscript; available in PMC 2012 March 28.</span></div><div class="t m0 x1 h7 y2c ff6 fs1 fc0 sc0 ls0 ws0">Published in final edited form as:</div><div class="t m1 x8 h3 y2d ff6 fs7 fc0 sc0 ls0 ws0">Curr Dir Psychol Sci</div><div class="t m0 x9 h7 y2d ff6 fs1 fc0 sc0 ls0 ws0">. 2007 April ; 16(2): 80–84. doi:10.1111/j.1467-8721.2007.00480.x.</div><div class="t m2 xa hc y2e ff2 fs3 fc2 sc0 ls0 ws0">NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf2" class="pf w0 h0" data-page-no="2"><div class="pc pc2 w0 h0"><img class="bi x0 y0 w2 hd" alt="" src="bg2.png"/><div class="t m0 x5 h7 y2b ff3 fs1 fc0 sc0 ls0 ws0">viewers across time (Newtson, 1976; Speer, Swallow, &amp; Zacks, 2003). The boundaries they</div><div class="t m0 x5 h7 y2f ff3 fs1 fc0 sc0 ls0 ws0">identify tend to be readily nameable “chunks,” corresponding to subgoals an actor is</div><div class="t m0 x5 h7 y30 ff3 fs1 fc0 sc0 ls0 ws0">attempting to satisfy in order to fulfill the larger goal of the activity. For example,</div><div class="t m0 x5 h7 y31 ff3 fs1 fc0 sc0 ls0 ws0">boundaries in “putting up a tent” might be placed when the tent is staked out and when the</div><div class="t m0 x5 h7 y32 ff3 fs1 fc0 sc0 ls0 ws0">rain fly is attached (see Figure 3). Event boundaries are hierarchically structured, such that</div><div class="t m0 x5 h7 y33 ff3 fs1 fc0 sc0 ls0 ws0">fine-grained events are clustered into larger coarse-grained events. For example, observers</div><div class="t m0 x5 h7 y1 ff3 fs1 fc0 sc0 ls0 ws0">segmenting a movie of a woman making a bed tend to identify events such as removing</div><div class="t m0 x5 h7 y34 ff3 fs1 fc0 sc0 ls0 ws0">individual pillowcases and also to identify the removal of all the pillowcases as a larger</div><div class="t m0 x5 h7 y35 ff3 fs1 fc0 sc0 ls0 ws0">event (Zacks, Tversky, &amp; Iyer, 2001). The consistency and structure of these results suggest</div><div class="t m0 x5 h7 y36 ff3 fs1 fc0 sc0 ls0 ws0">that the Newtson procedure taps into ongoing naturally occurring perceptual processing. But</div><div class="t m0 x5 h7 y37 ff3 fs1 fc0 sc0 ls0 ws0">there is a problem: The task requires that observers attend to event boundaries and make</div><div class="t m0 x5 h7 y38 ff3 fs1 fc0 sc0 ls0 ws0">decisions about where they occur. Such task demands may change the nature of the</div><div class="t m0 x5 h7 y39 ff3 fs1 fc0 sc0 ls0 ws0">perceptual processing involved.</div><div class="t m0 x5 h7 y3a ff3 fs1 fc0 sc0 ls0 ws0">Stronger evidence that event segmentation is naturally ongoing comes from indirect</div><div class="t m0 x5 h7 y3b ff3 fs1 fc0 sc0 ls0 ws0">measures, particularly functional neuroimaging studies. In one experiment (Zacks et al.,</div><div class="t m0 x5 h7 y3c ff3 fs1 fc0 sc0 ls0 ws0">2001), participants viewed a series of movies of everyday activities (e.g. washing dishes,</div><div class="t m0 x5 h7 y3d ff3 fs1 fc0 sc0 ls0 ws0">fertilizing a houseplant) while changes in brain activity were recorded with functional MRI.</div><div class="t m0 x5 h7 y3e ff3 fs1 fc0 sc0 ls0 ws0">After first passively viewing the movies, participants segmented the same movies, twice, to</div><div class="t m0 x5 h7 y3f ff3 fs1 fc0 sc0 ls0 ws0">identify event boundaries at two temporal grains. <span class="ff4">Fine</span> boundaries marked the smallest</div><div class="t m0 x5 h7 y40 ff3 fs1 fc0 sc0 ls0 ws0">events the participants found natural and meaningful, and <span class="ff4">coarse</span> boundaries marked the</div><div class="t m0 x5 h7 y41 ff3 fs1 fc0 sc0 ls0 ws0">largest events they found natural and meaningful. These boundaries were then used as</div><div class="t m0 x5 h7 y42 ff3 fs1 fc0 sc0 ls0 ws0">markers to analyze the brain activity data from the initial passive viewing session. During</div><div class="t m0 x5 h7 y43 ff3 fs1 fc0 sc0 ls0 ws0">passive viewing, regions of posterior and frontal cortex showed transient increases in</div><div class="t m0 x5 h7 y44 ff3 fs1 fc0 sc0 ls0 ws0">activity that began several seconds before each event boundary and peaked several seconds</div><div class="t m0 x5 h7 y45 ff3 fs1 fc0 sc0 ls0 ws0">after the boundary. Responses were larger for coarse than fine boundaries. Because the</div><div class="t m0 x5 h7 y46 ff3 fs1 fc0 sc0 ls0 ws0">critical brain data were acquired before participants learned of the segmentation procedure,</div><div class="t m0 x5 h7 y47 ff3 fs1 fc0 sc0 ls0 ws0">these changes cannot be attributed to overt or covert performance of a laboratory-specific</div><div class="t m0 x5 h7 y48 ff3 fs1 fc0 sc0 ls0 ws0">task. These results strongly imply that brain processes correlated with event segmentation</div><div class="t m0 x5 h7 y49 ff3 fs1 fc0 sc0 ls0 ws0">are a normal part of ongoing perception.</div><div class="t m0 x5 h7 y4a ff3 fs1 fc0 sc0 ls0 ws0">The preceding data make a compelling case that event segmentation is automatic. However,</div><div class="t m0 x5 h7 y4b ff3 fs1 fc0 sc0 ls0 ws0">segmentation still may be affected by observers’ attention and goals. Indeed, there is</div><div class="t m0 x5 h7 y4c ff3 fs1 fc0 sc0 ls0 ws0">evidence that observers can adapt their performance of the button-pressing segmentation</div><div class="t m0 x5 h7 y4d ff3 fs1 fc0 sc0 ls0 ws0">task based on situational needs. For example, observers adjust the temporal grain of their</div><div class="t m0 x5 h7 y4e ff3 fs1 fc0 sc0 ls0 ws0">segmentation based on explicit instructions, the sort of information they are trying to learn</div><div class="t m0 x5 h7 y4f ff3 fs1 fc0 sc0 ls0 ws0">from a stimulus, and how much they know about the activity they are watching (see Zacks &amp;</div><div class="t m0 x5 h7 y50 ff3 fs1 fc0 sc0 ls0 ws0">Tversky, 2001 for a review). An important question for future research is whether these</div><div class="t m0 x5 h7 y51 ff3 fs1 fc0 sc0 ls0 ws0">variations in overt task-related behavior reflect changes in ongoing perception or changes in</div><div class="t m0 x5 h7 y52 ff3 fs1 fc0 sc0 ls0 ws0">the decision processes that are specific to the button-pressing task.</div><div class="t m0 x1 h6 y53 ff1 fs3 fc0 sc0 ls0 ws0">SEGMENTATION GUIDES MEMORY AND LEARNING</div><div class="t m0 x5 h7 y54 ff3 fs1 fc0 sc0 ls0 ws0">One important consequence of perceptual segmentation is that the resulting segments can</div><div class="t m0 x5 h7 y55 ff3 fs1 fc0 sc0 ls0 ws0">form the basis of memory and learning. When it comes to remembering the details of what</div><div class="t m0 x5 h7 y56 ff3 fs1 fc0 sc0 ls0 ws0">has recently happened, new data indicate that those individuals who are better able to</div><div class="t m0 x5 h7 y57 ff3 fs1 fc0 sc0 ls0 ws0">segment an activity into events are better able to remember it later (Zacks, Speer, Vettel, &amp;</div><div class="t m0 x5 h7 y58 ff3 fs1 fc0 sc0 ls0 ws0">Jacoby, 2006). In this study, older adults segmented movies of everyday events (e.g., setting</div><div class="t m0 x5 h7 y59 ff3 fs1 fc0 sc0 ls0 ws0">up a tent, planting a flower bed). Each person’s segmentation was compared to the</div><div class="t m0 x5 h7 y5a ff3 fs1 fc0 sc0 ls0 ws0">segmentation of the other observers to determine whether they identified event boundaries</div><div class="t m0 x5 h7 y5b ff3 fs1 fc0 sc0 ls0 ws0">that were similar to those of the others or placed their event boundaries in idiosyncratic</div><div class="t m0 x5 h7 y5c ff3 fs1 fc0 sc0 ls0 ws0">locations. Although there is no gold standard for establishing whether one has segmented a</div><div class="t m0 x5 h7 y5d ff3 fs1 fc0 sc0 ls0 ws0">movie correctly, observers generally agree on the locations of event boundaries. So, if a</div><div class="t m0 xb h4 y5e ff3 fs2 fc0 sc0 ls0 ws0">Zacks and Swallow<span class="_ _1"> </span>Page 2</div><div class="t m0 xc h4 y5f ff4 fs2 fc0 sc0 ls0 ws0">Curr Dir Psychol Sci<span class="ff3">. Author manuscript; available in PMC 2012 March 28.</span></div><div class="t m2 xa hc y60 ff2 fs3 fc2 sc0 ls0 ws0">NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf3" class="pf w0 h0" data-page-no="3"><div class="pc pc3 w0 h0"><img class="bi x0 y0 w2 hd" alt="" src="bg3.png"/><div class="t m0 x5 h7 y2b ff3 fs1 fc0 sc0 ls0 ws0">particular observer’s segmentation deviates from this norm, chances are something is amiss.</div><div class="t m0 x5 h7 y2f ff3 fs1 fc0 sc0 ls0 ws0">All participants later completed a test requiring them to discriminate still pictures taken from</div><div class="t m0 x5 h7 y30 ff3 fs1 fc0 sc0 ls0 ws0">the movies from similar pictures that were not from the movies. Those participants who</div><div class="t m0 x5 h7 y31 ff3 fs1 fc0 sc0 ls0 ws0">segmented “well” showed better memory for the visual contents. Importantly, this strong</div><div class="t m0 x5 h7 y32 ff3 fs1 fc0 sc0 ls0 ws0">relationship was observed above and beyond the effects of individual differences in</div><div class="t m0 x5 h7 y33 ff3 fs1 fc0 sc0 ls0 ws0">cognitive ability and the presence of senile dementia.</div><div class="t m0 x5 h7 y61 ff3 fs1 fc0 sc0 ls0 ws0">Segmenting an activity well is not simply a matter of identifying the right event boundaries;</div><div class="t m0 x5 h7 y62 ff3 fs1 fc0 sc0 ls0 ws0">it also requires tracking how sets of fine-grained events group together into larger</div><div class="t m0 x5 h7 y63 ff3 fs1 fc0 sc0 ls0 ws0">meaningful units. Recent studies suggest such grouping is important for learning new</div><div class="t m0 x5 h7 y64 ff3 fs1 fc0 sc0 ls0 ws0">activities (Hard, Lozano, &amp; Tversky, in press; Lozano, Hard, &amp; Tversky, in press). In these</div><div class="t m0 x5 h7 y65 ff3 fs1 fc0 sc0 ls0 ws0">studies participants watched movies demonstrating simple assembly tasks and segmented</div><div class="t m0 x5 h7 y66 ff3 fs1 fc0 sc0 ls0 ws0">them at both a fine and coarse grain. They then were asked to perform the assembly task</div><div class="t m0 x5 h7 y67 ff3 fs1 fc0 sc0 ls0 ws0">they had just watched. The experimenters analyzed the degree to which participants grouped</div><div class="t m0 x5 h7 y3a ff3 fs1 fc0 sc0 ls0 ws0">events into hierarchical units. A number of experimental manipulations affected the degree</div><div class="t m0 x5 h7 y3b ff3 fs1 fc0 sc0 ls0 ws0">of hierarchical segmentation, and in all cases segmenting hierarchically was associated with</div><div class="t m0 x5 h7 y3c ff3 fs1 fc0 sc0 ls0 ws0">better performance of the learned task. Together, these data suggest that event boundaries</div><div class="t m0 x5 h7 y3d ff3 fs1 fc0 sc0 ls0 ws0">form anchors for long-term memory, and that interventions that encourage people to identify</div><div class="t m0 x5 h7 y3e ff3 fs1 fc0 sc0 ls0 ws0">appropriate event boundaries can improve memory for what has happened and the learning</div><div class="t m0 x5 h7 y3f ff3 fs1 fc0 sc0 ls0 ws0">of new skills.</div><div class="t m0 x1 h6 y68 ff1 fs3 fc0 sc0 ls0 ws0">NEURAL AND INFORMATION PROCESSING MECHANISMS</div><div class="t m0 x5 h7 y69 ff3 fs1 fc0 sc0 ls0 ws0">The previous sections argue that event segmentation is an automatic component of normal</div><div class="t m0 x5 h7 y6a ff3 fs1 fc0 sc0 ls0 ws0">perception that shapes how people remember and learn. How does the brain do this</div><div class="t m0 x5 h7 y6b ff3 fs1 fc0 sc0 ls0 ws0">segmentation? Evidence indicates that the brain and mind track features of one’s</div><div class="t m0 x5 h7 y6c ff3 fs1 fc0 sc0 ls0 ws0">environment, and when a salient feature changes unpredictably an event boundary is</div><div class="t m0 x5 h7 y6d ff3 fs1 fc0 sc0 ls0 ws0">perceived (Zacks, Speer, Swallow, Braver, &amp; Reynolds, in press). The critical features may</div><div class="t m0 x5 h7 y6e ff3 fs1 fc0 sc0 ls0 ws0">include sensory features, such as color, sound, and movement, and conceptual features, such</div><div class="t m0 x5 h7 y6f ff3 fs1 fc0 sc0 ls0 ws0">as cause-and-effect interactions and actors’ goals. Sensory features likely are processed in a</div><div class="t m0 x5 h7 y70 ff3 fs1 fc0 sc0 ls0 ws0">primarily bottom-up fashion, where the nature of the processing is driven primarily by</div><div class="t m0 x5 h7 y71 ff3 fs1 fc0 sc0 ls0 ws0">perceptual input. Processing conceptual features, however, likely relies on top-down</div><div class="t m0 x5 h7 y72 ff3 fs1 fc0 sc0 ls0 ws0">processing that integrates an observer’s representation of the current event with previously</div><div class="t m0 x5 h7 y73 ff3 fs1 fc0 sc0 ls0 ws0">stored knowledge. For example, segmenting events based on an actor’s goals requires</div><div class="t m0 x5 h7 y74 ff3 fs1 fc0 sc0 ls0 ws0">maintaining a representation of those goals over time, and often will depend on prior</div><div class="t m0 x5 h7 y75 ff3 fs1 fc0 sc0 ls0 ws0">knowledge about the actor’s dispositions and abilities.</div><div class="t m0 x1 h3 y76 ff1 fs1 fc0 sc0 ls0 ws0">Sensory Features: The Movement Of Objects and People</div><div class="t m0 x5 h7 y77 ff3 fs1 fc0 sc0 ls0 ws0">One hint at the sensory features that are important for event segmentation came from the</div><div class="t m0 x5 h7 y78 ff3 fs1 fc0 sc0 ls0 ws0">neuroimaging study described previously (Zacks et al., 2001). In that study, the most active</div><div class="t m0 x5 h7 y79 ff3 fs1 fc0 sc0 ls0 ws0">sites of transient brain responses at event boundaries appeared to be in visual processing</div><div class="t m0 x5 h7 y53 ff3 fs1 fc0 sc0 ls0 ws0">areas known to process movement information. These areas collectively are called the</div><div class="t m0 x5 h7 y7a ff3 fs1 fc0 sc0 ls0 ws0">human MT complex (MT+), because they are thought to be homologs of motion-sensitive</div><div class="t m0 x5 h7 y7b ff3 fs1 fc0 sc0 ls0 ws0">areas in the medial temporal cortex of the macaque monkey (hence MT). A follow-up to the</div><div class="t m0 x5 h7 y7c ff3 fs1 fc0 sc0 ls0 ws0">Zacks et al. (2001) study identified MT+ in individual observers and confirmed that the</div><div class="t m0 x5 h7 y7d ff3 fs1 fc0 sc0 ls0 ws0">areas activated by event boundaries did include this area (Speer, Swallow, &amp; Zacks, 2003),</div><div class="t m0 x5 h7 y7e ff3 fs1 fc0 sc0 ls0 ws0">suggesting that people use movement cues to identify those boundaries. These results</div><div class="t m0 x5 h7 y7f ff3 fs1 fc0 sc0 ls0 ws0">motivated recent experiments exploring the quantitative relationship between movement</div><div class="t m0 x5 h7 y80 ff3 fs1 fc0 sc0 ls0 ws0">features and event segmentation.</div><div class="t m0 x5 h7 y81 ff3 fs1 fc0 sc0 ls0 ws0">In one set of experiments (Zacks, 2004), participants viewed simple animations depicting</div><div class="t m0 x5 h7 y82 ff3 fs1 fc0 sc0 ls0 ws0">two objects moving around the screen and segmented them to identify fine or coarse event</div><div class="t m0 x5 h7 y83 ff3 fs1 fc0 sc0 ls0 ws0">boundaries. The animations were generated either by asking people to play a video game in</div><div class="t m0 xb h4 y5e ff3 fs2 fc0 sc0 ls0 ws0">Zacks and Swallow<span class="_ _1"> </span>Page 3</div><div class="t m0 xc h4 y5f ff4 fs2 fc0 sc0 ls0 ws0">Curr Dir Psychol Sci<span class="ff3">. Author manuscript; available in PMC 2012 March 28.</span></div><div class="t m2 xa hc y60 ff2 fs3 fc2 sc0 ls0 ws0">NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf4" class="pf w0 h0" data-page-no="4"><div class="pc pc4 w0 h0"><img class="bi x0 y0 w2 hd" alt="" src="bg4.png"/><div class="t m0 x5 h7 y2b ff3 fs1 fc0 sc0 ls0 ws0">which one player controlled each object and tried to achieve some goal (e.g., chase the other</div><div class="t m0 x5 h7 y2f ff3 fs1 fc0 sc0 ls0 ws0">object and catch it), or by a random algorithm that produced animations with similar</div><div class="t m0 x5 h7 y30 ff3 fs1 fc0 sc0 ls0 ws0">velocities and accelerations. The animations were analyzed to quantify movement features</div><div class="t m0 x5 h7 y31 ff3 fs1 fc0 sc0 ls0 ws0">such as the speed and acceleration of each object. In all experimental conditions people</div><div class="t m0 x5 h7 y32 ff3 fs1 fc0 sc0 ls0 ws0">tended to segment at points when movement features changed—for example, when objects</div><div class="t m0 x5 h7 y33 ff3 fs1 fc0 sc0 ls0 ws0">were accelerating quickly, or when they reached a point of being maximally close to each</div><div class="t m0 x5 h7 y1 ff3 fs1 fc0 sc0 ls0 ws0">other and turned away. (See also Hard, Lozano, &amp; Tversky, in press). Thus, movement</div><div class="t m0 x5 h7 y34 ff3 fs1 fc0 sc0 ls0 ws0">changes are strongly related to event segmentation.</div><div class="t m0 x5 h7 y63 ff3 fs1 fc0 sc0 ls0 ws0">If the processing of movement information in MT+ contributes to the segmentation of</div><div class="t m0 x5 h7 y64 ff3 fs1 fc0 sc0 ls0 ws0">activity into events, then one should expect MT+ to track both movement information and</div><div class="t m0 x5 h7 y65 ff3 fs1 fc0 sc0 ls0 ws0">event boundary locations when people view animations such as these. A recent</div><div class="t m0 x5 h7 y66 ff3 fs1 fc0 sc0 ls0 ws0">neuroimaging study indicates that this is the case (Zacks, Swallow, Vettel, &amp; McAvoy,</div><div class="t m0 x5 h7 y67 ff3 fs1 fc0 sc0 ls0 ws0">2006). In this experiment participants viewed simple animations while brain activity was</div><div class="t m0 x5 h7 y3a ff3 fs1 fc0 sc0 ls0 ws0">recorded. Separate scans were used to identify MT+ in individual observers. Activity in MT</div><div class="t m0 x5 h7 y3b ff3 fs1 fc0 sc0 ls0 ws0">+ increased as the velocity of the objects increased and also at event boundaries. Thus, the</div><div class="t m0 x5 h7 y3c ff3 fs1 fc0 sc0 ls0 ws0">processing of movement information appears to be well situated to play a causal role in the</div><div class="t m0 x5 h7 y3d ff3 fs1 fc0 sc0 ls0 ws0">detection of event boundaries.</div><div class="t m0 x1 h3 y3f ff1 fs1 fc0 sc0 ls0 ws0">Conceptual Features: Actors’ Goals</div><div class="t m0 x5 h7 y84 ff3 fs1 fc0 sc0 ls0 ws0">Although movement features account for a substantial part of where people segment</div><div class="t m0 x5 h7 y85 ff3 fs1 fc0 sc0 ls0 ws0">activity, they are not the whole story. Movement is more strongly tied to segmentation when</div><div class="t m0 x5 h7 y86 ff3 fs1 fc0 sc0 ls0 ws0">viewers identify fine-grained units or segment random animations than when they identify</div><div class="t m0 x5 h7 y87 ff3 fs1 fc0 sc0 ls0 ws0">coarse-grained units or segment animations depicting intentional activity (Zacks, 2004).</div><div class="t m0 x5 h7 y88 ff3 fs1 fc0 sc0 ls0 ws0">This suggests that people depend on other sources of information, such as inferences about</div><div class="t m0 x5 h7 y89 ff3 fs1 fc0 sc0 ls0 ws0">actors’ intentions and goals, to understand the larger structure of activity. One piece of direct</div><div class="t m0 x5 h7 y8a ff3 fs1 fc0 sc0 ls0 ws0">evidence for the importance of goals in event segmentation comes from infant perception</div><div class="t m0 x5 h7 y8b ff3 fs1 fc0 sc0 ls0 ws0">(Baldwin, Baird, Saylor, &amp; Clark, 2001). In this study, infants were familiarized with one of</div><div class="t m0 x5 h7 y8c ff3 fs1 fc0 sc0 ls0 ws0">two movies depicting a woman cleaning a kitchen. Each movie depicted a salient goal-</div><div class="t m0 x5 h7 y8d ff3 fs1 fc0 sc0 ls0 ws0">directed action (e.g., replacing a fallen dishtowel or storing an ice cream container in the</div><div class="t m0 x5 h7 y8e ff3 fs1 fc0 sc0 ls0 ws0">freezer). After the familiarization phase, infants were presented with excerpts with one-</div><div class="t m0 x5 h7 y8f ff3 fs1 fc0 sc0 ls0 ws0">second pauses inserted into the movie. The pauses were placed either at the moment when</div><div class="t m0 x5 h7 y90 ff3 fs1 fc0 sc0 ls0 ws0">the woman achieved the action’s goal, or several seconds before. The infants looked longer</div><div class="t m0 x5 h7 y91 ff3 fs1 fc0 sc0 ls0 ws0">at the excerpts when the pauses were placed before the goal completions, suggesting that</div><div class="t m0 x5 h7 y92 ff3 fs1 fc0 sc0 ls0 ws0">they found those more disruptive.</div><div class="t m0 x5 h7 y93 ff3 fs1 fc0 sc0 ls0 ws0">Another piece of evidence for the importance of goals comes from a neuroimaging study of</div><div class="t m0 x5 h7 y94 ff3 fs1 fc0 sc0 ls0 ws0">events in texts (Speer, Reynolds, &amp; Zacks, in press). In this experiment participants read</div><div class="t m0 x5 h7 y95 ff3 fs1 fc0 sc0 ls0 ws0">narrative texts describing the activities of a small boy while brain activity was recorded, and</div><div class="t m0 x5 h7 y96 ff3 fs1 fc0 sc0 ls0 ws0">then segmented the texts into events. The narratives were coded to localize changes in a</div><div class="t m0 x5 h7 y97 ff3 fs1 fc0 sc0 ls0 ws0">number of features, including changes in the characters’ spatial locations and in the</div><div class="t m0 x5 h7 y98 ff3 fs1 fc0 sc0 ls0 ws0">characters’ goals. Event boundaries in the narratives were associated with brief increases in</div><div class="t m0 x5 h7 y99 ff3 fs1 fc0 sc0 ls0 ws0">brain activity that were similar in timing and location to those for live-action movies. Many</div><div class="t m0 x5 h7 y9a ff3 fs1 fc0 sc0 ls0 ws0">of these areas also responded to changes in the narrative features—and the brain responses</div><div class="t m0 x5 h7 y9b ff3 fs1 fc0 sc0 ls0 ws0">to event boundaries could be entirely accounted for by the responses to the narrative</div><div class="t m0 x5 h7 y9c ff3 fs1 fc0 sc0 ls0 ws0">features. This suggests that both physical movement features (changes in location) and</div><div class="t m0 x5 h7 y9d ff3 fs1 fc0 sc0 ls0 ws0">changes in actors’ goals play important roles in the segmentation of activity into events.</div><div class="t m0 x5 h7 y80 ff3 fs1 fc0 sc0 ls0 ws0">These studies begin to provide the database for a mechanistic account of how observers</div><div class="t m0 x5 h7 y9e ff3 fs1 fc0 sc0 ls0 ws0">segment ongoing activity into events. However, the available data afford only the barest</div><div class="t m0 x5 h7 y9f ff3 fs1 fc0 sc0 ls0 ws0">outlines of such an account. We regard the detailed characterization of the relation between</div><div class="t m0 x5 h7 ya0 ff3 fs1 fc0 sc0 ls0 ws0">bottom-up and top-down processing in event segmentation as one important goal for future</div><div class="t m0 x5 h7 ya1 ff3 fs1 fc0 sc0 ls0 ws0">research. Further, we believe that a number of little-studied features, from purely sensory to</div><div class="t m0 xb h4 y5e ff3 fs2 fc0 sc0 ls0 ws0">Zacks and Swallow<span class="_ _1"> </span>Page 4</div><div class="t m0 xc h4 y5f ff4 fs2 fc0 sc0 ls0 ws0">Curr Dir Psychol Sci<span class="ff3">. Author manuscript; available in PMC 2012 March 28.</span></div><div class="t m2 xa hc y60 ff2 fs3 fc2 sc0 ls0 ws0">NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf5" class="pf w0 h0" data-page-no="5"><div class="pc pc5 w0 h0"><img class="bi x0 y0 w2 hd" alt="" src="bg5.png"/><div class="t m0 x5 h7 y2b ff3 fs1 fc0 sc0 ls0 ws0">purely conceptual, must be important for event segmentation. Toward the sensory end are</div><div class="t m0 x5 h7 y2f ff3 fs1 fc0 sc0 ls0 ws0">features such as sound, lighting, and contact between actors and objects. Toward the</div><div class="t m0 x5 h7 y30 ff3 fs1 fc0 sc0 ls0 ws0">conceptual end are features such as goals and social conventions. In the middle are features</div><div class="t m0 x5 h7 y31 ff3 fs1 fc0 sc0 ls0 ws0">such as statistical dependencies amongst events. The systematic exploration of these bases</div><div class="t m0 x5 h7 y32 ff3 fs1 fc0 sc0 ls0 ws0">for segmentation is a second important research goal.</div><div class="t m0 x1 h6 ya2 ff1 fs3 fc0 sc0 ls0 ws0">IN THE COURSE OF EVENTS</div><div class="t m0 x5 h7 ya3 ff3 fs1 fc0 sc0 ls0 ws0">The previous sections have reviewed recent evidence supporting three conclusions about</div><div class="t m0 x5 h7 ya4 ff3 fs1 fc0 sc0 ls0 ws0">event perception. First, event segmentation is an automatic component of ongoing</div><div class="t m0 x5 h7 ya5 ff3 fs1 fc0 sc0 ls0 ws0">perceptual processing. Second, how people segment activity online has significant effects on</div><div class="t m0 x5 h7 ya6 ff3 fs1 fc0 sc0 ls0 ws0">how they remember it later: Events form the units of memory encoding, so identifying the</div><div class="t m0 x5 h7 ya7 ff3 fs1 fc0 sc0 ls0 ws0">right events leads to good memory and learning but identifying the wrong events leads to</div><div class="t m0 x5 h7 y6 ff3 fs1 fc0 sc0 ls0 ws0">poor memory and learning. Finally, there are specialized neural systems that process</div><div class="t m0 x5 h7 y7 ff3 fs1 fc0 sc0 ls0 ws0">features including movement and goals in order to use changes in those features to identify</div><div class="t m0 x5 h7 y8 ff3 fs1 fc0 sc0 ls0 ws0">event boundaries. These findings have implications for education and for clinical practice.</div><div class="t m0 x5 h7 y9 ff3 fs1 fc0 sc0 ls0 ws0">For education, they suggest that interventions that help people appropriately segment events</div><div class="t m0 x5 h7 ya ff3 fs1 fc0 sc0 ls0 ws0">will help them remember and learn from those events (see Segmentation Guides Learning</div><div class="t m0 x5 h7 yb ff3 fs1 fc0 sc0 ls0 ws0">and Memory, above). For clinical practice, these findings suggest that some cognitive</div><div class="t m0 x5 h7 yc ff3 fs1 fc0 sc0 ls0 ws0">deficits may reflect impaired event segmentation. A small number of studies indicate that</div><div class="t m0 x5 h7 yd ff3 fs1 fc0 sc0 ls0 ws0">event segmentation is impaired in patients with lesions to prefrontal cortex, schizophrenia,</div><div class="t m0 x5 h7 ye ff3 fs1 fc0 sc0 ls0 ws0">and mild Alzheimer-type dementia (see Zacks, Speer, Swallow, Braver, &amp; Reynolds, in</div><div class="t m0 x5 h7 ya8 ff3 fs1 fc0 sc0 ls0 ws0">press for a review). As discussed previously, the last of these studies established a link</div><div class="t m0 x5 h7 ya9 ff3 fs1 fc0 sc0 ls0 ws0">between event segmentation and later memory, raising the possibility that it may be possible</div><div class="t m0 x5 h7 yaa ff3 fs1 fc0 sc0 ls0 ws0">to remediate some memory deficits by improving segmentation.</div><div class="t m0 x5 h7 y6c ff3 fs1 fc0 sc0 ls0 ws0">Segmentation is a powerful perceptual operation. By reducing a continuous flux of activity</div><div class="t m0 x5 h7 y6d ff3 fs1 fc0 sc0 ls0 ws0">to a modest number of discrete events a perceiver can achieve terrific economy of</div><div class="t m0 x5 h7 y6e ff3 fs1 fc0 sc0 ls0 ws0">representation for perception and later memory. Segmentation not only is economical—it</div><div class="t m0 x5 h7 y6f ff3 fs1 fc0 sc0 ls0 ws0">also allows one to think about different things in relation to each other, generatively, which</div><div class="t m0 x5 h7 y70 ff3 fs1 fc0 sc0 ls0 ws0">is notoriously difficult with continuous, unsegmented representations. For this reason,</div><div class="t m0 x5 h7 y71 ff3 fs1 fc0 sc0 ls0 ws0">people generally perceive space as consisting not of continuous gradations of color and</div><div class="t m0 x5 h7 y72 ff3 fs1 fc0 sc0 ls0 ws0">texture but of spatially coherent objects. The same holds in time: Just as much as our</div><div class="t m0 x5 h7 y73 ff3 fs1 fc0 sc0 ls0 ws0">everyday perceptual world is made up of objects, it is made up of events.</div><div class="t m0 x1 h6 yab ff1 fs3 fc0 sc0 ls0 ws0">Acknowledgments</div><div class="t m0 x5 h4 yac ff3 fs2 fc0 sc0 ls0 ws0">Preparation of this article was supported by National Institute of Mental Health Grant MH70674.</div><div class="t m0 x1 h6 yad ff1 fs3 fc0 sc0 ls0 ws0">REFERENCES</div><div class="t m0 x5 he y1c ff3 fs8 fc0 sc0 ls0 ws0">Baldwin DA, Baird JA, Saylor MM, Clark MA. Infants parse dynamic action. Child Development.</div><div class="t m0 xd he y98 ff3 fs8 fc0 sc0 ls0 ws0">2001; 72(3):708–717. [PubMed: 11405577]</div><div class="t m0 x5 he y1e ff3 fs8 fc0 sc0 ls0 ws0">Biederman I. Recognition-by-components: A theory of human image understanding. Psychological</div><div class="t m0 xd he y9a ff3 fs8 fc0 sc0 ls0 ws0">Review. 1987; 94(2):115–117. [PubMed: 3575582]</div><div class="t m0 x5 he y20 ff3 fs8 fc0 sc0 ls0 ws0">Hard BM, Lozano SC, Tversky B. Hierarchical encoding of behavior: Translating perception into</div><div class="t m0 xd he y9c ff3 fs8 fc0 sc0 ls0 ws0">action. Journal of Experimental Psychology: General. (in press).</div><div class="t m0 x5 he yae ff3 fs8 fc0 sc0 ls0 ws0">Lozano SC, Hard BM, Tversky B. Perspective-taking promotes action understanding and learning.</div><div class="t m0 xd he yaf ff3 fs8 fc0 sc0 ls0 ws0">Journal of Experimental Psychology: Human Perception &amp; Performance. (in press).</div><div class="t m0 x5 he yb0 ff3 fs8 fc0 sc0 ls0 ws0">Newtson, D. Foundations of attribution: the perception of ongoing behavior. In: Harvey, JH.; Ickes,</div><div class="t m0 xd he yb1 ff3 fs8 fc0 sc0 ls0 ws0">WJ.; Kidd, RF., editors. New directions in attribution research. Hillsdale, New Jersey: Lawrence</div><div class="t m0 xd he yb2 ff3 fs8 fc0 sc0 ls0 ws0">Erlbaum Associates; 1976. p. 223-248.</div><div class="t m0 x5 he yb3 ff3 fs8 fc0 sc0 ls0 ws0">Speer NK, Reynolds JR, Zacks JM. Human brain activity time-locked to narrative event boundaries.</div><div class="t m0 xd he yb4 ff3 fs8 fc0 sc0 ls0 ws0">Psychological Science. (in press).</div><div class="t m0 xb h4 y5e ff3 fs2 fc0 sc0 ls0 ws0">Zacks and Swallow<span class="_ _1"> </span>Page 5</div><div class="t m0 xc h4 y5f ff4 fs2 fc0 sc0 ls0 ws0">Curr Dir Psychol Sci<span class="ff3">. Author manuscript; available in PMC 2012 March 28.</span></div><div class="t m2 xa hc y60 ff2 fs3 fc2 sc0 ls0 ws0">NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf6" class="pf w0 h0" data-page-no="6"><div class="pc pc6 w0 h0"><img class="bi x0 y0 w2 hd" alt="" src="bg6.png"/><div class="t m0 x5 he y2b ff3 fs8 fc0 sc0 ls0 ws0">Speer NK, Swallow KM, Zacks JM. Activation of human motion processing areas during event</div><div class="t m0 xd he yb5 ff3 fs8 fc0 sc0 ls0 ws0">perception. Cognitive, Affective &amp; Behavioral Neuroscience. 2003; 3(4):335–345.</div><div class="t m0 x5 he yb6 ff3 fs8 fc0 sc0 ls0 ws0">Zacks JM. Using movement and intentions to understand simple events. Cognitive Science. 2004;</div><div class="t m0 xd he yb7 ff3 fs8 fc0 sc0 ls0 ws0">28(6):979–1008.</div><div class="t m0 x5 he yb8 ff3 fs8 fc0 sc0 ls0 ws0">Zacks JM, Braver TS, Sheridan MA, Donaldson DI, Snyder AZ, Ollinger JM, et al. Human brain</div><div class="t m0 xd he yb9 ff3 fs8 fc0 sc0 ls0 ws0">activity time-locked to perceptual event boundaries. Nature Neuroscience. 2001; 4(6):651–655.</div><div class="t m0 x5 he y1 ff3 fs8 fc0 sc0 ls0 ws0">Zacks JM, Speer NK, Swallow KM, Braver TS, Reynolds JR. Event perception: A mind/brain</div><div class="t m0 xe he y61 ff3 fs8 fc0 sc0 ls0 ws0">perspective. Psychological Bulletin. (in press).</div><div class="t m0 x5 he y3 ff3 fs8 fc0 sc0 ls0 ws0">Zacks JM, Speer NK, Vettel JM, Jacoby LL. Event understanding and memory in healthy aging and</div><div class="t m0 xe he y63 ff3 fs8 fc0 sc0 ls0 ws0">dementia of the Alzheimer type. Psychology &amp; Aging. 2006; 21(3):466–482. [PubMed: 16953710]</div><div class="t m0 x5 he yba ff3 fs8 fc0 sc0 ls0 ws0">Zacks JM, Swallow KM, Vettel JM, McAvoy MP. Visual movement and the neural correlates of event</div><div class="t m0 xe he y65 ff3 fs8 fc0 sc0 ls0 ws0">perception. Brain Research. 2006; 1076(1):150–162. [PubMed: 16473338]</div><div class="t m0 x5 he ybb ff3 fs8 fc0 sc0 ls0 ws0">Zacks JM, Tversky B. Event structure in perception and conception. Psychological Bulletin. 2001;</div><div class="t m0 xe he y67 ff3 fs8 fc0 sc0 ls0 ws0">127(1):3–21. [PubMed: 11271755]</div><div class="t m0 x5 he ybc ff3 fs8 fc0 sc0 ls0 ws0">Zacks JM, Tversky B, Iyer G. Perceiving, remembering, and communicating structure in events.</div><div class="t m0 xe he y3b ff3 fs8 fc0 sc0 ls0 ws0">Journal of Experimental Psychology: General. 2001; 130(1):29–58. [PubMed: 11293458]</div><div class="t m0 x1 h6 ybd ff1 fs3 fc0 sc0 ls0 ws0">RECOMMENDED READINGS</div><div class="t m0 x5 he ybe ff3 fs8 fc0 sc0 ls0 ws0">Baldwin, DA.; Baird, JA. Action analysis: A gateway to intentional inference. In: Rochat, P., editor.</div><div class="t m0 xe he ybf ff3 fs8 fc0 sc0 ls0 ws0">Early social cognition. Hillsdale, NJ: Lawrence Erlbaum Associates; 1999. p. 215-240.</div><div class="t m0 x5 he yc0 ff3 fs8 fc0 sc0 ls0 ws0">Newtson D. 1976 See references.</div><div class="t m0 x5 he ya8 ff3 fs8 fc0 sc0 ls0 ws0">Zacks JM, Braver TS, Sheridan MA, Donaldson DI, Snyder AZ, Ollinger JM, et al. 2001 See</div><div class="t m0 xe he yc1 ff3 fs8 fc0 sc0 ls0 ws0">references.</div><div class="t m0 x5 he yf ff3 fs8 fc0 sc0 ls0 ws0">Zacks JM, Speer NK, Swallow KM, Braver TS. (in press). See references.</div><div class="t m0 x5 he yc2 ff3 fs8 fc0 sc0 ls0 ws0">Zacks JM, Tversky B. 2001 See references.</div><div class="t m0 xb h4 y5e ff3 fs2 fc0 sc0 ls0 ws0">Zacks and Swallow<span class="_ _1"> </span>Page 6</div><div class="t m0 xc h4 y5f ff4 fs2 fc0 sc0 ls0 ws0">Curr Dir Psychol Sci<span class="ff3">. Author manuscript; available in PMC 2012 March 28.</span></div><div class="t m2 xa hc y60 ff2 fs3 fc2 sc0 ls0 ws0">NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf7" class="pf w0 h0" data-page-no="7"><div class="pc pc7 w0 h0"><img class="bi x0 y0 w3 hd" alt="" src="bg7.png"/><div class="t m0 x5 hf y73 ff5 fs8 fc0 sc0 ls0 ws0">Figure 1.</div><div class="t m0 x5 h7 yc3 ff3 fs1 fc0 sc0 ls0 ws0">How easily can you describe this scene? This may be difficult since it is broken up in a way</div><div class="t m0 x5 h7 yc4 ff3 fs1 fc0 sc0 ls0 ws0">that obscures its natural part structure.</div><div class="t m0 xb h4 y5e ff3 fs2 fc0 sc0 ls0 ws0">Zacks and Swallow<span class="_ _1"> </span>Page 7</div><div class="t m0 xc h4 y5f ff4 fs2 fc0 sc0 ls0 ws0">Curr Dir Psychol Sci<span class="ff3">. Author manuscript; available in PMC 2012 March 28.</span></div><div class="t m2 xa hc y60 ff2 fs3 fc2 sc0 ls0 ws0">NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf8" class="pf w0 h0" data-page-no="8"><div class="pc pc8 w0 h0"><img class="bi x0 y0 w3 hd" alt="" src="bg8.png"/><div class="t m0 x5 hf yc5 ff5 fs8 fc0 sc0 ls0 ws0">Figure 2.</div><div class="t m0 x5 h7 y74 ff3 fs1 fc0 sc0 ls0 ws0">This version may be easier to recognize. Though the scene is still broken up, the natural</div><div class="t m0 x5 h7 y75 ff3 fs1 fc0 sc0 ls0 ws0">parts are preserved.</div><div class="t m0 xb h4 y5e ff3 fs2 fc0 sc0 ls0 ws0">Zacks and Swallow<span class="_ _1"> </span>Page 8</div><div class="t m0 xc h4 y5f ff4 fs2 fc0 sc0 ls0 ws0">Curr Dir Psychol Sci<span class="ff3">. Author manuscript; available in PMC 2012 March 28.</span></div><div class="t m2 xa hc y60 ff2 fs3 fc2 sc0 ls0 ws0">NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
<div id="pf9" class="pf w0 h0" data-page-no="9"><div class="pc pc9 w0 h0"><img class="bi x0 y0 w3 hd" alt="" src="bg9.png"/><div class="t m0 x5 hf yc6 ff5 fs8 fc0 sc0 ls0 ws0">Figure 3.</div><div class="t m0 x5 h7 ye ff3 fs1 fc0 sc0 ls0 ws0">Example of event boundaries. These frames show the six coarse-grained event boundaries</div><div class="t m0 x5 h7 ya8 ff3 fs1 fc0 sc0 ls0 ws0">selected most frequently by a group of younger and older adults (Zacks, Speer, Vettel, &amp;</div><div class="t m0 x5 h7 ya9 ff3 fs1 fc0 sc0 ls0 ws0">Jacoby, 2006, exp. 2). These boundaries marked the ends of events that could be described</div><div class="t m0 x5 h7 yf ff3 fs1 fc0 sc0 ls0 ws0">as: 1) Put down the tent. 2) Spread it out. 3) Insert the front tent pole. 4) Stake out the ends</div><div class="t m0 x5 h7 yc7 ff3 fs1 fc0 sc0 ls0 ws0">of the tent. 5) Stake out the sides. 6) Attach the rain fly. [Boundaries were identified by</div><div class="t m0 x5 h7 yc8 ff3 fs1 fc0 sc0 ls0 ws0">estimating the continuous probability of segmentation over time using a gaussian smoothing</div><div class="t m0 x5 h7 yc9 ff3 fs1 fc0 sc0 ls0 ws0">kernel, bandwidth = 5 s, and selecting the six highest local maxima in the resulting</div><div class="t m0 x5 h7 y11 ff3 fs1 fc0 sc0 ls0 ws0">probability distribution.]</div><div class="t m0 xb h4 y5e ff3 fs2 fc0 sc0 ls0 ws0">Zacks and Swallow<span class="_ _1"> </span>Page 9</div><div class="t m0 xc h4 y5f ff4 fs2 fc0 sc0 ls0 ws0">Curr Dir Psychol Sci<span class="ff3">. Author manuscript; available in PMC 2012 March 28.</span></div><div class="t m2 xa hc y60 ff2 fs3 fc2 sc0 ls0 ws0">NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript<span class="_ _0"> </span>NIH-PA Author Manuscript</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
</div>
<div class="loading-indicator">
<img alt="" src="pdf2htmlEX-64x64.png">
</div>
</body>
</html>
